{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de Imágenes en CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para experimentar con el reconocimiento de imágenes y la clasificación se estudia el dataset *CIFAR10*, el cual contiene 60.000 imagenes de 32 $\\times$ 32 (pixeles), donde cada imagen pertenece a una de las diez clases, clasificación excluyente (gato, perro, rana, caballo, pájaro, ciervo, avión, automóvil, camión y barco). Los datos vienen estructurado en un formato RGB, donde cada imagen (fila del dataset) corresponde a 3072 características, dividido en los 3 canales de RGB (1024 cada uno) correspondiente a cada imagen.  \n",
    "Los datos vienen separados en datos de entrenamiento y de pruebas, para un estudio eficiente con las técnicas *redes neuronales*, *arboles* y *SVM*, analizando las distintas representaciones de imágenes viendo su efecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59  43  50 ..., 140  84  72]\n",
      " [154 126 105 ..., 139 142 144]\n",
      " [255 253 253 ...,  83  83  84]\n",
      " ..., \n",
      " [ 71  60  74 ...,  68  69  68]\n",
      " [250 254 211 ..., 215 255 254]\n",
      " [ 62  61  60 ..., 130 130 131]]\n",
      "min value 0\n",
      "max value 255\n",
      "[[  59.   43.   50. ...,  158.  152.  148.]\n",
      " [   0.   18.   51. ...,  119.  122.   25.]\n",
      " [  49.   83.  110. ...,  109.   33.   38.]\n",
      " ..., \n",
      " [ 160.   56.   53. ...,   58.   34.  131.]\n",
      " [  97.   83.  177. ...,  103.  170.  216.]\n",
      " [ 123.    0.    0. ...,    0.    0.    0.]]\n",
      "[[  59.   43.   50. ...,  158.  152.  148.]\n",
      " [   0.   18.   51. ...,  119.  122.   25.]\n",
      " [  49.   83.  110. ...,  109.   33.   38.]\n",
      " ..., \n",
      " [ 160.   56.   53. ...,   58.   34.  131.]\n",
      " [  97.   83.  177. ...,  103.  170.  216.]\n",
      " [ 123.    0.    0. ...,    0.    0.    0.]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3e4539068318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanal_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mmatriz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanal_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanal_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanal_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmatriz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/matrixlib/defmatrix.pyc\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(subtype, data, dtype, copy)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mintype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mintype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mintype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "dict1 = unpickle(\"datasets/data_batch_1\")\n",
    "X = dict1[\"data\"]\n",
    "print X\n",
    "print \"min value\" ,min(X[0])\n",
    "print \"max value\" ,max(X[0])\n",
    "\n",
    "label_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "aux = X[0].copy()\n",
    "canal_r = np.zeros((32,32))\n",
    "j = 0\n",
    "i= 0\n",
    "for k in range(1024):\n",
    "    if i < 32:\n",
    "        canal_r[j][i] = aux[k]\n",
    "        i+=1\n",
    "    else:\n",
    "        j+=1\n",
    "        i = 0\n",
    "print canal_r\n",
    "\n",
    "canal_g = np.zeros((32,32))\n",
    "j = 0\n",
    "i= 0\n",
    "for k in range(1024,2048):\n",
    "    if i < 32:\n",
    "        canal_g[j][i] = aux[k]\n",
    "        i+=1\n",
    "    else:\n",
    "        j+=1\n",
    "        i = 0\n",
    "\n",
    "canal_b = np.zeros((32,32))\n",
    "j = 0\n",
    "i= 0\n",
    "for k in range(2048,3072):\n",
    "    if i < 32:\n",
    "        canal_b[j][i] = aux[k]\n",
    "        i+=1\n",
    "    else:\n",
    "        j+=1\n",
    "        i = 0\n",
    "print np.asarray(canal_r)\n",
    "matriz = np.matrix(np.asarray(canal_r),np.asarray(canal_g),np.asarray(canal_b))\n",
    "print matriz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(canal_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ve en lo anterior cada pixel de cada imágen tiene un rango en el qu varía entre 0 y 255, siendo 0 la intensidad mínima del pixel en ese canal y 255 la intensidad máxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[152 152 148 ..., 136 130 128]\n",
      " [ 42  40  25 ..., 137 153 127]\n",
      " [155 151 155 ...,  91  76  74]\n",
      " ..., \n",
      " [151 161 171 ..., 144 138 132]\n",
      " [ 22  24  41 ..., 142 147 139]\n",
      " [255 255 255 ..., 156 167 170]]\n",
      "Training set shape:  (42567, 3072)\n",
      "Validation set shape:  (7433, 3072)\n",
      "Test set shape:  (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import imread\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_CIFAR_one(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        datadict = pickle.load(f)\n",
    "        X = datadict[\"data\"]\n",
    "        Y = datadict[\"labels\"]\n",
    "        return X, np.array(Y)\n",
    "\n",
    "def load_CIFAR10(PATH):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(PATH, \"data_batch_%d\" % (b, ))\n",
    "        X, Y = load_CIFAR_one(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    \n",
    "    Xte, Yte = load_CIFAR_one(os.path.join(PATH, \"test_batch\"))\n",
    "    \n",
    "    #adding Xval\n",
    "    index = np.arange(np.shape(Xtr)[0]) #filas \n",
    "    np.random.shuffle(index) #permutan las filas\n",
    "    X = Xtr[index, :] #matriz permutada\n",
    "    Y = Ytr[index]\n",
    "\n",
    "    #l =  np.random.randint(1000,10000) #entrego 7433\n",
    "    n = Xtr.shape[0]\n",
    "    l = 7433\n",
    "    \n",
    "    Xval,Xtr = np.split(X,[l])\n",
    "    Yval,Ytr = np.split(Y,[l])\n",
    "    \n",
    "    return Xtr, Ytr, Xte, Yte,Xval,Yval\n",
    "\n",
    "X_train,Y_train, X_test,Y_test, X_val,Y_val = load_CIFAR10('datasets/')\n",
    "\n",
    "print X_train\n",
    "print 'Training set shape: ',X_train.shape\n",
    "print 'Validation set shape: ',X_val.shape\n",
    "print 'Test set shape: ',X_test.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se construye una funcion que carga los bloques de entrenamiento, de pruebas y de validacion del dataset en las matrices $X_{train}$, $Y_{train}$, $X_{test}$, $Y_{test}$ y $X_{val}$, $Y_{val}$ respectivamente. Las filas de estas matrices representan cada imagen del dataset, siendo los valores de la fila valores enteros de 0 a 255, que representan los valores de los colores que vienen por los canales *R*,*G* y *B*.\n",
    "\n",
    "Se puede observar que la matriz $X_{train}$ posee 42567 filas, es decir, 42567 imagenes de entrenamiento. Por otro lado $X_{val}$ posee 7433 imagenes de validacion y $X_{test}$ 10000 imagenes de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 4 3 ..., 9 8 1]\n",
      "[7 8 6 ..., 4 9 5]\n"
     ]
    }
   ],
   "source": [
    "print Y_train\n",
    "print Y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.22652595 -0.23547842 -0.23478773 ..., -1.35456215 -1.2726719\n",
      "  -1.23281747]\n",
      " [ 0.52309228  0.52469012  0.51379339 ..., -0.67515192 -0.62735892\n",
      "  -0.67207938]\n",
      " [ 0.60486881  0.4279414   0.80490827 ...,  1.5946959   1.53904893\n",
      "   1.54056283]\n",
      " ..., \n",
      " [-1.18058552 -1.18914442 -1.20517067 ..., -1.53985585 -1.53387001\n",
      "  -1.50560898]\n",
      " [-1.38502685 -1.35499937 -0.90019317 ...,  0.08146402  0.01795406\n",
      "  -0.1871167 ]\n",
      " [ 0.11420961  0.19298021  0.25040373 ..., -0.16559425 -0.1049627\n",
      "  -0.1871167 ]]\n",
      "[[ 0.44705882  0.44313725  0.44705882 ...,  0.10196078  0.12156863\n",
      "   0.12941176]\n",
      " [ 0.6627451   0.65882353  0.65882353 ...,  0.2745098   0.28627451\n",
      "   0.2745098 ]\n",
      " [ 0.68627451  0.63137255  0.74117647 ...,  0.85098039  0.83921569\n",
      "   0.84705882]\n",
      " ..., \n",
      " [ 0.17254902  0.17254902  0.17254902 ...,  0.05490196  0.05490196\n",
      "   0.05882353]\n",
      " [ 0.11372549  0.1254902   0.25882353 ...,  0.46666667  0.45098039  0.4       ]\n",
      " [ 0.54509804  0.56470588  0.58431373 ...,  0.40392157  0.41960784  0.4       ]]\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [1 1 1 ..., 0 0 0]\n",
      " [1 1 1 ..., 1 1 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [1 1 1 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Escalar y centrar datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "def scaler_t(X,Xv,Xt,scaler_type):\n",
    "    if scaler_type == \"standar\":\n",
    "        scaler= StandardScaler(with_std=True).fit(X)\n",
    "        return scaler.transform(X), scaler.transform(Xv), scaler.transform(Xt)\n",
    "    elif scaler_type == \"int_max\":\n",
    "        aux = [ X/255.0, Xv/255.0, Xt/255.0 ]\n",
    "        newX = aux[0].copy()\n",
    "        newXv = aux[1].copy()\n",
    "        newXt = aux[2].copy()\n",
    "        #newX[ newX <0.2] = 1\n",
    "        #newX[ newX > 0.8] = 0\n",
    "        #newXv[ newXv <0.2] = 1\n",
    "        #newXv[ newXv > 0.8] = 0\n",
    "        #newXt[ newXt <0.2] = 1\n",
    "        #newXt[ newXt > 0.8] = 0\n",
    "        return newX,newXv,newXt\n",
    "    elif scaler_type == \"zeros_ones\":\n",
    "        newX = X.copy()\n",
    "        newXv = Xv.copy()\n",
    "        newXt = Xt.copy()\n",
    "        newX[ newX <128] = 0\n",
    "        newX[ newX > 127] = 1\n",
    "        newXv[ newXv <128] = 0\n",
    "        newXv[ newXv > 127] = 1\n",
    "        newXt[ newXt < 128] = 0\n",
    "        newXt[ newXt > 127] = 1\n",
    "        return newX,newXv,newXt\n",
    "    else: #otro\n",
    "        return X*0.5\n",
    "\n",
    "X,Xv,Xt = scaler_t(X_train,X_val,X_test,\"standar\")\n",
    "print X\n",
    "\n",
    "X,Xv,Xt = scaler_t(X_train,X_val,X_test,\"int_max\")\n",
    "print X\n",
    "\n",
    "X,Xv,Xt = scaler_t(X_train,X_val,X_test,\"zeros_ones\")\n",
    "print X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta seccion se escalan las imagenes, para poder trabajarlas de forma apropiada. Este escalamiento se realiza en base a la intensidad maxima de los pixeles de las imagenes y se procede a centrar y estandarizar normalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) ANN - analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para representacion datos normalizados estandar\n",
      "7392/7433 [============================>.] - ETA: 0sVALIDATION ACCURACY (activation relu-softmax) = 0.915579\n",
      "7328/7433 [============================>.] - ETA: 0sVALIDATION ACCURACY (activation relu-sigmoid) = 0.915108\n",
      "7328/7433 [============================>.] - ETA: 0sVALIDATION ACCURACY (optimizer RMSprop and activation relu-sigmoid) = 0.908973\n",
      "------------------------------------------------\n",
      "Para representacion datos escalados por la intensidad maxima (0-255 pasa a 0-1)\n",
      "7360/7433 [============================>.] - ETA: 0sVALIDATION ACCURACY (activation relu-softmax) = 0.901022\n",
      "7360/7433 [============================>.] - ETA: 0sVALIDATION ACCURACY (activation relu-sigmoid)= 0.887502\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "from keras.optimizers import SGD,RMSprop\n",
    "\n",
    "\n",
    "Xtr,Xv,Xt = scaler_t(X_train,X_val,X_test,\"standar\")\n",
    "Ytr = to_categorical(Y_train)\n",
    "Yv = to_categorical(Y_val)\n",
    "Yt = to_categorical(Y_test)\n",
    "print \"Para representacion datos normalizados estandar\"\n",
    "\n",
    "#experimentar variando valores\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(Xtr, Ytr, nb_epoch=50, batch_size=32, verbose=0, validation_data=(Xv,Yv))\n",
    "\n",
    "scores = model.evaluate(Xv, Yv)\n",
    "\n",
    "print \"VALIDATION ACCURACY (activation relu-softmax) = %f\"% scores[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(Xtr, Ytr, nb_epoch=50, batch_size=32, verbose=0, validation_data=(Xv,Yv))\n",
    "\n",
    "scores = model.evaluate(Xv, Yv)\n",
    "\n",
    "print \"VALIDATION ACCURACY (activation relu-sigmoid) = %f\"% scores[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer=RMSprop(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(Xtr, Ytr, nb_epoch=50, batch_size=32, verbose=0, validation_data=(Xv,Yv))\n",
    "\n",
    "scores = model.evaluate(Xv, Yv)\n",
    "\n",
    "print \"VALIDATION ACCURACY (optimizer RMSprop and activation relu-sigmoid) = %f\"% scores[1]\n",
    "\n",
    "print \"------------------------------------------------\"\n",
    "\n",
    "X,Xv,Xt = scaler_t(X_train,X_val,X_test,\"int_max\")\n",
    "Ytr = to_categorical(Y_train)\n",
    "Yv = to_categorical(Y_val)\n",
    "Yt = to_categorical(Y_test)\n",
    "print \"Para representacion datos escalados por la intensidad maxima (0-255 pasa a 0-1)\"\n",
    "\n",
    "#experimentar variando valores\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(Xtr, Ytr, nb_epoch=50, batch_size=32, verbose=0, validation_data=(Xv,Yv))\n",
    "\n",
    "scores = model.evaluate(Xv, Yv)\n",
    "print \"VALIDATION ACCURACY (activation relu-softmax) = %f\"% scores[1]\n",
    "\n",
    "#experimentar variando valores\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(Xtr, Ytr, nb_epoch=50, batch_size=32, verbose=0, validation_data=(Xv,Yv))\n",
    "\n",
    "scores = model.evaluate(Xv, Yv)\n",
    "print \"VALIDATION ACCURACY (activation relu-sigmoid)= %f\"% scores[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42567 samples, validate on 7433 samples\n",
      "Epoch 1/50\n",
      "42567/42567 [==============================] - 10s - loss: 0.3161 - acc: 0.9000 - val_loss: 0.3053 - val_acc: 0.9000\n",
      "Epoch 2/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2987 - acc: 0.9000 - val_loss: 0.2928 - val_acc: 0.9001\n",
      "Epoch 3/50\n",
      "42567/42567 [==============================] - 10s - loss: 0.2894 - acc: 0.9006 - val_loss: 0.2857 - val_acc: 0.9008\n",
      "Epoch 4/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2838 - acc: 0.9007 - val_loss: 0.2813 - val_acc: 0.9010\n",
      "Epoch 5/50\n",
      "42567/42567 [==============================] - 10s - loss: 0.2794 - acc: 0.9014 - val_loss: 0.2779 - val_acc: 0.9014\n",
      "Epoch 6/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2765 - acc: 0.9018 - val_loss: 0.2754 - val_acc: 0.9022\n",
      "Epoch 7/50\n",
      "42567/42567 [==============================] - 10s - loss: 0.2741 - acc: 0.9022 - val_loss: 0.2734 - val_acc: 0.9023\n",
      "Epoch 8/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2719 - acc: 0.9026 - val_loss: 0.2715 - val_acc: 0.9024\n",
      "Epoch 9/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2700 - acc: 0.9030 - val_loss: 0.2700 - val_acc: 0.9029\n",
      "Epoch 10/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2681 - acc: 0.9034 - val_loss: 0.2688 - val_acc: 0.9027\n",
      "Epoch 11/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2667 - acc: 0.9036 - val_loss: 0.2670 - val_acc: 0.9039\n",
      "Epoch 12/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2649 - acc: 0.9039 - val_loss: 0.2653 - val_acc: 0.9039\n",
      "Epoch 13/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2632 - acc: 0.9042 - val_loss: 0.2643 - val_acc: 0.9042\n",
      "Epoch 14/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2619 - acc: 0.9049 - val_loss: 0.2628 - val_acc: 0.9045\n",
      "Epoch 15/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2605 - acc: 0.9050 - val_loss: 0.2617 - val_acc: 0.9047\n",
      "Epoch 16/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2593 - acc: 0.9053 - val_loss: 0.2603 - val_acc: 0.9053\n",
      "Epoch 17/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2578 - acc: 0.9058 - val_loss: 0.2598 - val_acc: 0.9052\n",
      "Epoch 18/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2566 - acc: 0.9057 - val_loss: 0.2584 - val_acc: 0.9060\n",
      "Epoch 19/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2555 - acc: 0.9063 - val_loss: 0.2573 - val_acc: 0.9062\n",
      "Epoch 20/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2542 - acc: 0.9065 - val_loss: 0.2564 - val_acc: 0.9064\n",
      "Epoch 21/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2530 - acc: 0.9067 - val_loss: 0.2559 - val_acc: 0.9061\n",
      "Epoch 22/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2521 - acc: 0.9071 - val_loss: 0.2548 - val_acc: 0.9068\n",
      "Epoch 23/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2509 - acc: 0.9073 - val_loss: 0.2541 - val_acc: 0.9069\n",
      "Epoch 24/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2502 - acc: 0.9075 - val_loss: 0.2534 - val_acc: 0.9070\n",
      "Epoch 25/50\n",
      "42567/42567 [==============================] - 10s - loss: 0.2489 - acc: 0.9080 - val_loss: 0.2527 - val_acc: 0.9071\n",
      "Epoch 26/50\n",
      "42567/42567 [==============================] - 10s - loss: 0.2480 - acc: 0.9081 - val_loss: 0.2521 - val_acc: 0.9070\n",
      "Epoch 27/50\n",
      "42567/42567 [==============================] - 10s - loss: 0.2473 - acc: 0.9083 - val_loss: 0.2519 - val_acc: 0.9072\n",
      "Epoch 28/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2465 - acc: 0.9087 - val_loss: 0.2513 - val_acc: 0.9074\n",
      "Epoch 29/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2458 - acc: 0.9086 - val_loss: 0.2506 - val_acc: 0.9077\n",
      "Epoch 30/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2449 - acc: 0.9091 - val_loss: 0.2501 - val_acc: 0.9080\n",
      "Epoch 31/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2439 - acc: 0.9092 - val_loss: 0.2495 - val_acc: 0.9079\n",
      "Epoch 32/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2432 - acc: 0.9094 - val_loss: 0.2490 - val_acc: 0.9083\n",
      "Epoch 33/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2423 - acc: 0.9099 - val_loss: 0.2488 - val_acc: 0.9082\n",
      "Epoch 34/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2418 - acc: 0.9098 - val_loss: 0.2488 - val_acc: 0.9083\n",
      "Epoch 35/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2410 - acc: 0.9101 - val_loss: 0.2480 - val_acc: 0.9085\n",
      "Epoch 36/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2400 - acc: 0.9102 - val_loss: 0.2479 - val_acc: 0.9081\n",
      "Epoch 37/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2390 - acc: 0.9109 - val_loss: 0.2473 - val_acc: 0.9086\n",
      "Epoch 38/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2385 - acc: 0.9110 - val_loss: 0.2468 - val_acc: 0.9087\n",
      "Epoch 39/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2377 - acc: 0.9112 - val_loss: 0.2467 - val_acc: 0.9086\n",
      "Epoch 40/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2371 - acc: 0.9115 - val_loss: 0.2463 - val_acc: 0.9090\n",
      "Epoch 41/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2364 - acc: 0.9116 - val_loss: 0.2463 - val_acc: 0.9090\n",
      "Epoch 42/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2356 - acc: 0.9119 - val_loss: 0.2460 - val_acc: 0.9091\n",
      "Epoch 43/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2352 - acc: 0.9117 - val_loss: 0.2457 - val_acc: 0.9092\n",
      "Epoch 44/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2343 - acc: 0.9122 - val_loss: 0.2451 - val_acc: 0.9095\n",
      "Epoch 45/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2335 - acc: 0.9126 - val_loss: 0.2448 - val_acc: 0.9094\n",
      "Epoch 46/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2330 - acc: 0.9124 - val_loss: 0.2446 - val_acc: 0.9093\n",
      "Epoch 47/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2324 - acc: 0.9129 - val_loss: 0.2449 - val_acc: 0.9094\n",
      "Epoch 48/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2313 - acc: 0.9132 - val_loss: 0.2441 - val_acc: 0.9096\n",
      "Epoch 49/50\n",
      "42567/42567 [==============================] - 9s - loss: 0.2311 - acc: 0.9127 - val_loss: 0.2443 - val_acc: 0.9095\n",
      "Epoch 50/50\n",
      "42567/42567 [==============================] - 10s - loss: 0.2304 - acc: 0.9133 - val_loss: 0.2438 - val_acc: 0.9100\n",
      "7360/7433 [============================>.] - ETA: 0sVALIDATION ACCURACY (activation relu-softmax) = 0.909983\n"
     ]
    }
   ],
   "source": [
    "#scores = model.evaluate(Xt, Yt)\n",
    "#print \"TEST ACCURACY = %f\"% scores[1]\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "from keras.optimizers import SGD,RMSprop\n",
    "\n",
    "#Xtr,Xv,Xt = scaler_t(X_train,X_val,X_test,\"standar\")\n",
    "Ytr = to_categorical(Y_train)\n",
    "Yv = to_categorical(Y_val)\n",
    "Yt = to_categorical(Y_test)\n",
    "#X,Xv,Xt = scaler_t(X_train,X_val,X_test,\"int_max\")\n",
    "Xtr,Xv,Xt = X_train,X_val,X_test\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=Xtr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(Xtr, Ytr, nb_epoch=50, batch_size=32, verbose=0, validation_data=(Xv,Yv))\n",
    "scores = model.evaluate(Xv, Yv)\n",
    "print \"VALIDATION ACCURACY (activation relu-softmax) = %f\"% scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42567, 3072)\n",
      "(42567, 32, 32, 3)\n",
      "Dimensiones de representacion segun histograma de gradientes:  (42567, 144)\n",
      "(42567, 32, 32, 3)\n",
      "Dimensiones de representacion segun histogramas de color:  (42567, 10)\n",
      "(42567, 32, 32, 3)\n",
      "Dimensiones de representacion mixta:  (42567, 154)\n",
      "[[  3.28252652e+00   9.02344707e-01   0.00000000e+00 ...,   1.46484375e-02\n",
      "    1.46484375e-02   4.49218750e-02]\n",
      " [  1.27768186e+00   2.71226101e+00   6.44353672e-01 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.93778528e+00   0.00000000e+00   8.79941741e-01 ...,   9.57031250e-02\n",
      "    4.49218750e-02   7.32421875e-02]\n",
      " ..., \n",
      " [  1.02592044e+00   5.98453495e-01   5.65761366e-01 ...,   1.46484375e-02\n",
      "    1.26953125e-02   1.75781250e-02]\n",
      " [  4.52694478e-01   9.61371393e-01   1.09370906e+00 ...,   6.83593750e-03\n",
      "    6.83593750e-03   1.75781250e-02]\n",
      " [  0.00000000e+00   0.00000000e+00   5.84914941e-02 ...,   1.95312500e-03\n",
      "    1.95312500e-03   2.63671875e-02]]\n"
     ]
    }
   ],
   "source": [
    "from top_level_features import hog_features\n",
    "from top_level_features import color_histogram_hsv\n",
    "from top_level_features import extract_features\n",
    "X_train, Y_train, X_test, Y_test,X_val,Y_val = load_CIFAR10(\"datasets/\")\n",
    "print X_train.shape\n",
    "\n",
    "features = extract_features(X_train,[hog_features],verbose=0) #extrae hog features\n",
    "print 'Dimensiones de representacion segun histograma de gradientes: ',features.shape\n",
    "features = extract_features(X_train,[color_histogram_hsv]) #extrae histogramas de color\n",
    "print 'Dimensiones de representacion segun histogramas de color: ',features.shape\n",
    "features = extract_features(X_train,[hog_features, color_histogram_hsv]) #extrae todo\n",
    "print 'Dimensiones de representacion mixta: ' ,features.shape\n",
    "\n",
    "print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def representacion(x,xv,xt,tipo):\n",
    "    if tipo==\"hog\":\n",
    "        features_train = extract_features(x,[hog_features]) #extrae hog features\n",
    "        features_val = extract_features(xv,[hog_features]) #extrae hog features\n",
    "        features_test = extract_features(xt,[hog_features]) #extrae hog features\n",
    "    elif tipo==\"histogram\":\n",
    "        features_train = extract_features(x,[color_histogram_hsv]) #extrae histogramas de color\n",
    "        features_val = extract_features(xv,[color_histogram_hsv]) #extrae histogramas de color\n",
    "        features_test = extract_features(xt,[color_histogram_hsv]) #extraehistogramas de color\n",
    "    else:\n",
    "        features_train = extract_features(x,[hog_features, color_histogram_hsv]) #extrae todo\n",
    "        features_val = extract_features(xv,[hog_features, color_histogram_hsv]) #extrae todo\n",
    "        features_test = extract_features(xt,[hog_features, color_histogram_hsv]) #extrae todo\n",
    "\n",
    "    return features_train,features_val,features_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) SVM no lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ajustar SVM no lineal sobre las distintas representaciones y variar hiperparametros\n",
    "from sklearn.svm import SVC\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "Cs = [pow(2,k) for k in np.arange(-2,7,1)]\n",
    "def do_SVC(x,y,xv,yv):\n",
    "    mejor = 0\n",
    "    info1 = []\n",
    "    info2 = []\n",
    "    for C in Cs:\n",
    "        clf1 = SVC(C=C, kernel=\"rbf\")\n",
    "        clf2 = SVC(C=C, kernel=\"poly\",degree=2, coef0=1)\n",
    "        \n",
    "        clf1 = clf1.fit(x,y)\n",
    "        clf2 = clf2.fit(x,y)\n",
    "        \n",
    "        acc_1 = clf1.score(x,y)\n",
    "        accv_1 = clf1.score(xv,yv)\n",
    "        \n",
    "        acc_2 = clf2.score(x,y)\n",
    "        accv_2 = clf2.score(xv,yv)\n",
    "        \n",
    "        if accv_1 > mejor:\n",
    "            mejor = accv_1\n",
    "        if accv_2 > mejor:\n",
    "            mejor = accv_2\n",
    "        info1.append([acc_1,accv_1])\n",
    "        info2.append([acc_2,accv_2])\n",
    "    print \"Best Validation Accuracy = %f\"%mejor\n",
    "    return info1,info2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42567, 3072)\n",
      "(42567, 10)\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "Xtr,Xv,Xt = scaler_t(X_train,X_val,X_test,\"standar\")\n",
    "print X.shape\n",
    "\n",
    "clf = SVC(C=1, kernel=\"rbf\",verbose=1)        \n",
    "clf = clf.fit(Xtr,Y_train)  \n",
    "\n",
    "acc = clf.score(Xt,Y_test)\n",
    "print \"TEST ACCURACY WITH STANDAR NORMALIZE = %f\"% acc\n",
    "\n",
    "#do_SVC(X,Ytr,Xv,Yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#probar otros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr,Xv,Xt = representacion(X_train,X_val,X_test,\"hog\")\n",
    "\n",
    "clf = SVC(C=1, kernel=\"rbf\",verbose=1)        \n",
    "clf = clf.fit(Xtr,Y_train)  \n",
    "\n",
    "acc = clf.score(Xt,Y_test)\n",
    "print \"TEST ACCURACY WITH STANDAR NORMALIZE = %f\"% acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Árbol de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "N_ts = [2,5,10,13,17,20,25,30,50,80,90,100,150]\n",
    "def do_Tree(x,y,xv,yv):\n",
    "    mejor = 0\n",
    "    nivel = 0\n",
    "    info = []\n",
    "    for n_t in N_ts:\n",
    "        print \"arbol: %d\"%n_t\n",
    "        clf=Tree(criterion=\"gini\",splitter=\"best\",random_state=0,max_depth=n_t)\n",
    "        clf.fit(x,y)\n",
    "        acc = clf.score(x,y)\n",
    "        acc_v = clf.score(xv,yv)\n",
    "        if acc_v > mejor:\n",
    "            mejor = acc_v\n",
    "            nivel = n_t\n",
    "        info.append([acc,acc_v])\n",
    "    print \"Best Validation Accuracy = %f\"%mejor\n",
    "    print \"Tree's Level = %f\"%nivel\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arbol: 2\n",
      "arbol: 5\n",
      "arbol: 10\n",
      "arbol: 13\n",
      "arbol: 17\n",
      "arbol: 20\n",
      "arbol: 25\n",
      "arbol: 30\n",
      "arbol: 50\n",
      "arbol: 80\n",
      "arbol: 90\n",
      "arbol: 100\n",
      "arbol: 150\n",
      "Best Validation Accuracy = 0.267052\n",
      "Tree's Level = 30.000000\n"
     ]
    }
   ],
   "source": [
    "Xtr,Xv,Xt = scaler_t(X_train,X_val,X_test,\"standar\")\n",
    "\n",
    "#cuidado---se demora harto\n",
    "info1 = do_Tree(Xtr,Y_train,Xv,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3YAAAFRCAYAAAA4mz8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMzMzKzi/g/4br2+uQfXVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8793863cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#utilizar el info\n",
    "error1 = [1-i[0] for i in info1]\n",
    "error2 = [1-i[1] for i in info1]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(N_ts,error1, label = \"Training set\")\n",
    "plt.plot(N_ts,error2, label = \"Validation set\")\n",
    "plt.xticks(N_ts)\n",
    "plt.xlabel('Numero de niveles')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error sobre arbol de clasificacion con representacion estandarizada de pixeles')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ACCURACY WITH NORMALIZE BETWEEN 0-1 = 0.292479\n"
     ]
    }
   ],
   "source": [
    "Xtr,Xv,Xt = scaler_t(X_train,X_val,X_test,\"int_max\")\n",
    "\n",
    "clf=Tree(criterion=\"gini\",splitter=\"best\",random_state=0,max_depth=10)\n",
    "clf.fit(Xtr,Y_train)\n",
    "acc = clf.score(Xv,Y_val)\n",
    "print \"VALIDATION ACCURACY WITH NORMALIZE BETWEEN 0-1 = %f\"% acc\n",
    "        \n",
    "#info2 = do_Tree(Xtr,Ytr,Xv,Yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ACCURACY WITH 0's and 1's REPRESENTATION = 0.284946\n"
     ]
    }
   ],
   "source": [
    "Xtr,Xv,Xt = scaler_t(X_train,X_val,X_test,\"zeros_ones\")\n",
    "\n",
    "clf=Tree(criterion=\"gini\",splitter=\"best\",random_state=0,max_depth=10)\n",
    "clf.fit(Xtr,Y_train)\n",
    "acc = clf.score(Xv,Y_val)\n",
    "print \"VALIDATION ACCURACY WITH 0's and 1's REPRESENTATION = %f\"% acc\n",
    "\n",
    "#info3 = do_Tree(Xtr,Ytr,Xv,Yv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se prueban las distintas representaciones de extracción de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42567, 32, 32, 3)\n",
      "(7433, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "VALIDATION ACCURACY WITH HOG REPRESENTATION = 0.291941\n"
     ]
    }
   ],
   "source": [
    "Xtr,Xv,Xt = representacion(X_train,X_val,X_test,\"hog\")\n",
    "\n",
    "clf=Tree(criterion=\"gini\",splitter=\"best\",random_state=0,max_depth = 10)\n",
    "clf.fit(Xtr,Y_train)\n",
    "acc = clf.score(Xv,Y_val)\n",
    "print \"VALIDATION ACCURACY WITH HOG REPRESENTATION = %f\"% acc\n",
    "\n",
    "#info4 = do_Tree(Xtr,Ytr,Xv,Yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42567, 32, 32, 3)\n",
      "(7433, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "VALIDATION ACCURACY WITH COLOR HISTOGRAM REPRESENTATION = 0.262344\n"
     ]
    }
   ],
   "source": [
    "Xtr,Xv,Xt = representacion(X_train,X_val,X_test,\"histogram\")\n",
    "\n",
    "clf=Tree(criterion=\"gini\",splitter=\"best\",random_state=0,max_depth=10)\n",
    "clf.fit(Xtr,Y_train)\n",
    "acc = clf.score(Xv,Y_val)\n",
    "print \"VALIDATION ACCURACY WITH COLOR HISTOGRAM REPRESENTATION = %f\"% acc\n",
    "\n",
    "#info5 = do_Tree(Xtr,Ytr,Xv,Yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42567, 32, 32, 3)\n",
      "(7433, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "VALIDATION ACCURACY WITH COLOR HISTOGRAM AND HOG REPRESENTATION = 0.315485\n",
      "VALIDATION ACCURACY WITH COLOR HISTOGRAM AND HOG REPRESENTATION = 0.273241\n",
      "VALIDATION ACCURACY WITH COLOR HISTOGRAM AND HOG REPRESENTATION = 0.273645\n",
      "VALIDATION ACCURACY WITH COLOR HISTOGRAM AND HOG REPRESENTATION = 0.273645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "\n",
    "Xtr,Xv,Xt = representacion(X_train,X_val,X_test,\"combinacion\")\n",
    "\n",
    "clf=Tree(criterion=\"gini\",splitter=\"best\",random_state=0,max_depth=10)\n",
    "clf.fit(Xtr,Y_train)\n",
    "acc = clf.score(Xv,Y_val)\n",
    "print \"VALIDATION ACCURACY WITH COLOR HISTOGRAM AND HOG REPRESENTATION = %f\"% acc\n",
    "\n",
    "clf=Tree(criterion=\"gini\",splitter=\"best\",random_state=0,max_depth=30)\n",
    "clf.fit(Xtr,Y_train)\n",
    "acc = clf.score(Xv,Y_val)\n",
    "print \"VALIDATION ACCURACY WITH COLOR HISTOGRAM AND HOG REPRESENTATION = %f\"% acc\n",
    "\n",
    "clf=Tree(criterion=\"gini\",splitter=\"best\",random_state=0,max_depth=50)\n",
    "clf.fit(Xtr,Y_train)\n",
    "acc = clf.score(Xv,Y_val)\n",
    "print \"VALIDATION ACCURACY WITH COLOR HISTOGRAM AND HOG REPRESENTATION = %f\"% acc\n",
    "\n",
    "clf=Tree(criterion=\"gini\",splitter=\"best\",random_state=0,max_depth=100)\n",
    "clf.fit(Xtr,Y_train)\n",
    "acc = clf.score(Xv,Y_val)\n",
    "print \"VALIDATION ACCURACY WITH COLOR HISTOGRAM AND HOG REPRESENTATION = %f\"% acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a lo anteriormente experimentado se escogen los mejores parametros y representación para un arbol de clasificación para este problema de clasificación de imágenes. Mostrando a continuación el error sobre el test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42567, 32, 32, 3)\n",
      "(7433, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "TEST ACCURACY WITH ... = 0.312300\n"
     ]
    }
   ],
   "source": [
    "#la mejor representacion = combinacion\n",
    "#el mejor nivel = 30\n",
    "Xtr,Xv,Xt = representacion(X_train,X_val,X_test,\"combinacion\")\n",
    "\n",
    "clf=Tree(criterion=\"gini\",splitter=\"best\",random_state=0,max_depth=10)\n",
    "clf.fit(Xtr,Y_train)\n",
    "\n",
    "acc = clf.score(Xt,Y_test)\n",
    "print \"TEST ACCURACY WITH ... = %f\"% acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
