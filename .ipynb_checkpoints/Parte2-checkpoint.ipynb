{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing: Predicción de Demanda Horaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para esta sección se simulará el participar en una competencia *Bike Sharing Demanda* de *Kaggle*, donde el objetivo será predecir la demanda de bicicletas en la ciudad de Washington, la cual tiene un comportamiento ni lineal y no determinista como función de la hora del día.  \n",
    "En base a esto se ajustarán distintos modelos para ir mejorando en el puntaje obtenido (*score*) y así avanzar en el top-100 del *leaderboard*. Las filas del dataset corresponden a registros de cada hora de la demanda de bicicletas con datos relevantes para predecir esta demanda, los atributos entregados en el dataset se presentan a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributo|Descripción|Tipo Variable \n",
    "--------|-------------|--------------- \n",
    "_datetime_|hourly date + timestamp|numérica \n",
    "_season_|1 = spring, 2 = summer, 3 = fall, 4 = winter|categórica \n",
    "_holiday_|whether the day is considered a holiday|categórica \n",
    "_workingday_|whether the day is neither a weekend or holiday|categórica \n",
    "_weather_|1: Clear, 2: Cloudy, 3: Light Snow, 4: Heavy Rain|categórica \n",
    "_temp_|temperature in Celsius|numérica \n",
    "_atemp_|\"feels like\" temperature in Celsius|numérica \n",
    "_humidity_|relative humidity|numérica \n",
    "_windspeed_|windspeed|numérica \n",
    "_casual_|number of non-registered user rentals initiated|numérica \n",
    "_registered_|number of registered user rentals initiated|numérica\n",
    "_count_|number of total rentals|numérica "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función para evualar los distintos clasificadores (modelos) será la siguiente:  \n",
    "\n",
    "$$\n",
    "E_{bikes}(\\hat{y},y) = \\sqrt{ \\frac{1}{n} \\sum_i^n (\\ln{(y_i+1)} - \\ln{(\\hat{y} +1)})^2 }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correspondiente a una medición del error para las predicciones de algun modelo de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Carga Dataset y Análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary - dataframe completo:\n",
      "\n",
      "             season       holiday    workingday       weather         temp  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.00000   \n",
      "mean       2.506614      0.028569      0.680875      1.418427     20.23086   \n",
      "std        1.116174      0.166599      0.466159      0.633839      7.79159   \n",
      "min        1.000000      0.000000      0.000000      1.000000      0.82000   \n",
      "25%        2.000000      0.000000      0.000000      1.000000     13.94000   \n",
      "50%        3.000000      0.000000      1.000000      1.000000     20.50000   \n",
      "75%        4.000000      0.000000      1.000000      2.000000     26.24000   \n",
      "max        4.000000      1.000000      1.000000      4.000000     41.00000   \n",
      "\n",
      "              atemp      humidity     windspeed        casual    registered  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
      "mean      23.655084     61.886460     12.799395     36.021955    155.552177   \n",
      "std        8.474601     19.245033      8.164537     49.960477    151.039033   \n",
      "min        0.760000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%       16.665000     47.000000      7.001500      4.000000     36.000000   \n",
      "50%       24.240000     62.000000     12.998000     17.000000    118.000000   \n",
      "75%       31.060000     77.000000     16.997900     49.000000    222.000000   \n",
      "max       45.455000    100.000000     56.996900    367.000000    886.000000   \n",
      "\n",
      "              count  \n",
      "count  10886.000000  \n",
      "mean     191.574132  \n",
      "std      181.144454  \n",
      "min        1.000000  \n",
      "25%       42.000000  \n",
      "50%      145.000000  \n",
      "75%      284.000000  \n",
      "max      977.000000  \n",
      "Dimensiones de training set:  (6562, 13)\n",
      "Dimensiones de validation set:  (2177, 13)\n",
      "Dimensiones de test set:  (2147, 13)\n",
      "10886\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dftrain = pd.read_csv('datasets/bike_sharing_train.csv')\n",
    "dfval = pd.read_csv('datasets/bike_sharing_val.csv')\n",
    "dftest = pd.read_csv('datasets/bike_sharing_test.csv')\n",
    "ntrain = len(dftrain)\n",
    "nval = len(dftrain) + len(dfval)\n",
    "df = pd.concat([dftrain,dfval,dftest])\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "print('\\nSummary - dataframe completo:\\n')\n",
    "print(df.describe())\n",
    "#print df\n",
    "print \"Dimensiones de training set: \",dftrain.shape\n",
    "print \"Dimensiones de validation set: \", dfval.shape\n",
    "print \"Dimensiones de test set: \", dftest.shape\n",
    "\n",
    "print len(df)\n",
    "#procesamiento\n",
    "df['hour'] = pd.to_datetime(df['datetime']).apply(lambda x: x.strftime('%H'))\n",
    "df['hour'] = pd.to_numeric(df['hour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se cargan los datos de entrenamiento y de prueba, mostrándo un resumen del dataset con ciertas métricas estádisticas entregadas por la función $describe()$, para describir el dataset. Esta posee 11 atributos (características) para predecir el target (count), de las cuales para los atributos categóricos estas métricas estadísticas no tienen un gran significado debido a que estas están codificadas en intervalos discretos, como por ejemplo *season* y *weather* presentan sus valores enteros discretos entre 1 y 4. Se puede ver que las características numéricas varían en un rango muy distinto entre sí y entre las características categóricas, evidenciado en el promedio y desviación estándar de cada uno. Para la variable a predecir, la demanda de bicicletas varía entre 1 y 977, con media 191 y desviación estándar de 181 por lo que en base a esto se puede verificar que la demanda es bastante variable.  \n",
    "\n",
    "El primer preprocesamiento es extraer la hora del día desde la característica fecha (*datetime*).  \n",
    "Para este dataset cada fila simboliza la cuantificación de la demanda en un rango de hora específico, tomando estas mediciones cada 1 hora, por ejemplo si una fila tiene demanda 10 significa que en esa hora se vendieron 10 bicicletas. La cantidad de datos que posee el *training set* es de 6562, el *validation set* de 2177 y el *test set* de 2147. El *training set* corresponde a los registros de la demanda de los primeros 19 días de cada mes por 2 años, siendo el *test set* el registro de la demanda del resto de los 11 días de cada mes por los 2 años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13773, 60141, 43002, 53708, 53708, 53708] [27250, 98354, 81833, 96599, 96599, 96599] [33947, 104681, 89197, 100973, 100973, 100973] [27305, 99762, 78460, 93241, 93241, 93241]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/tight_layout.py:225: UserWarning: tight_layout : falling back to Agg renderer\n",
      "  warnings.warn(\"tight_layout : falling back to Agg renderer\")\n",
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 2 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spring_rows1 = df[ (df['season'] == 1) & (df['hour'] <= 6)]\n",
    "spring_rows2 = df[ (df['season'] == 1) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "spring_rows3 = df[ (df['season'] == 1) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "spring_rows4 = df[ (df['season'] == 1) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "spring_rows5 = df[ (df['season'] == 1) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "spring_rows6 = df[ (df['season'] == 1) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "spring_vals = [sum(spring_rows1['count']),sum(spring_rows2['count']),sum(spring_rows3['count']),sum(spring_rows4['count'])\n",
    "              ,sum(spring_rows4['count']),sum(spring_rows4['count'])]\n",
    "\n",
    "summer_rows1 = df[ (df['season'] == 2) & (df['hour'] <= 6)]\n",
    "summer_rows2 = df[ (df['season'] == 2) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "summer_rows3 = df[ (df['season'] == 2) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "summer_rows4 = df[ (df['season'] == 2) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "summer_rows5 = df[ (df['season'] == 2) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "summer_rows6 = df[ (df['season'] == 2) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "summer_vals = [sum(summer_rows1['count']),sum(summer_rows2['count']),sum(summer_rows3['count']),sum(summer_rows4['count'])\n",
    "              ,sum(summer_rows4['count']),sum(summer_rows4['count'])]\n",
    "\n",
    "fall_rows1 = df[ (df['season'] == 3) & (df['hour'] <= 6)]\n",
    "fall_rows2 = df[ (df['season'] == 3) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "fall_rows3 = df[ (df['season'] == 3) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "fall_rows4 = df[ (df['season'] == 3) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "fall_rows5 = df[ (df['season'] == 3) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "fall_rows6 = df[ (df['season'] == 3) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "fall_vals = [sum(fall_rows1['count']),sum(fall_rows2['count']),sum(fall_rows3['count']),sum(fall_rows4['count'])\n",
    "              ,sum(fall_rows4['count']),sum(fall_rows4['count'])]\n",
    "\n",
    "winter_rows1 = df[ (df['season'] == 4) & (df['hour'] <= 6)]\n",
    "winter_rows2 = df[ (df['season'] == 4) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "winter_rows3 = df[ (df['season'] == 4) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "winter_rows4 = df[ (df['season'] == 4) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "winter_rows5 = df[ (df['season'] == 4) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "winter_rows6 = df[ (df['season'] == 4) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "winter_vals = [sum(winter_rows1['count']),sum(winter_rows2['count']),sum(winter_rows3['count']),sum(winter_rows4['count'])\n",
    "              ,sum(winter_rows4['count']),sum(winter_rows4['count'])]\n",
    "\n",
    "\n",
    "print spring_vals, summer_vals,fall_vals,winter_vals\n",
    "\n",
    "# Construir histograma -------------------------------------------\n",
    "\n",
    "#PARA COMPARAR LAS EPOCAS DEL AÑO\n",
    "f, axarr = plt.subplots(2, 2, figsize=(12,8) )\n",
    "axarr[0, 0].bar(np.arange(0,6,1), spring_vals, width  = 0.5, align = \"center\", color = 'b')\n",
    "axarr[0, 0].set_title('Spring')\n",
    "axarr[0, 0].set_xticks([-0.25,0.5,1.5,2.5,3.5,4.5,5.25])\n",
    "axarr[0, 0].set_xticklabels(('12am','6am','9am','12pm','15pm','6pm','12am'))\n",
    "axarr[0, 0].set_ylabel('Ventas')\n",
    "axarr[0, 0].axis('tight')\n",
    "\n",
    "axarr[0, 1].bar(np.arange(0,6,1), summer_vals, width  = 0.5, align = \"center\", color = 'r')\n",
    "axarr[0, 1].set_title('Summer')\n",
    "axarr[0, 1].set_xticks([-0.25,0.5,1.5,2.5,3.5,4.5,5.25])\n",
    "axarr[0, 1].set_xticklabels(('12am','6am','9am','12pm','15pm','6pm','12am'))\n",
    "axarr[0, 1].set_ylabel('Ventas')\n",
    "axarr[0, 1].axis('tight')\n",
    "\n",
    "\n",
    "axarr[1, 0].bar(np.arange(0,6,1), fall_vals, width  = 0.5, align = \"center\", color = 'g')\n",
    "axarr[1, 0].set_title('Fall')\n",
    "axarr[1, 0].set_xticks([-0.25,0.5,1.5,2.5,3.5,4.5,5.25])\n",
    "axarr[1, 0].set_xticklabels(('12am','6am','9am','12pm','15pm','6pm','12am'))\n",
    "axarr[1, 0].set_ylabel('Ventas')\n",
    "axarr[1, 0].axis('tight')\n",
    "\n",
    "\n",
    "axarr[1, 1].bar(np.arange(0,6,1), winter_vals, width  = 0.5, align = \"center\", color = 'y')\n",
    "axarr[1, 1].set_title('Winter')\n",
    "axarr[1, 1].set_xticks([-0.25,0.5,1.5,2.5,3.5,4.5,5.25])\n",
    "axarr[1, 1].set_xticklabels(('12am','6am','9am','12pm','15pm','6pm','12am'))\n",
    "axarr[1, 1].set_ylabel('Ventas')\n",
    "axarr[1, 1].axis('tight')\n",
    "\n",
    "f.tight_layout() #separar los subplot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los gráficos anteriores son presentados para resumir el comportamiento de la demanda (Ventas) en función de distintos rangos de horas (12am a 6am, 6am a 9 am y así), para distintas épocas del año, mostrándo que esta es distinta, ya que a pesar que los gráficos sean parecidos, estos varían en un distinto rango. En Otoño se posee la mayor demanda y en Primavera es la menor demanda.  \n",
    "[algo mas ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Árbol de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE TEST=0.703388\n",
      "KAGG EVAL TRAIN =0.028516\n",
      "KAGG EVAL VAL =0.554511\n",
      "KAGG EVAL TEST =0.574239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as Tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eval_bikemodel(y_predict,y_true):\n",
    "    diff = np.log(y_predict+1.0) - np.log(y_true+1.0)\n",
    "    return np.sqrt(np.sum(np.square(diff))/len(y_predict))\n",
    "\n",
    "\n",
    "Xdf=df.ix[:,['season','holiday','workingday','weather','temp','atemp',\n",
    "'humidity','windspeed','hour']]\n",
    "Ydf=df.ix[:,'count']\n",
    "\n",
    "X_train = Xdf[0:ntrain].values\n",
    "X_val = Xdf[ntrain:nval].values\n",
    "X_test = Xdf[nval:].values\n",
    "\n",
    "Y_train = Ydf[0:ntrain].values\n",
    "Y_val = Ydf[ntrain:nval].values\n",
    "Y_test = Ydf[nval:].values\n",
    "\n",
    "#Modelo\n",
    "model = Tree(random_state=0)\n",
    "model.fit(X_train,Y_train)\n",
    "score_test = model.score(X_test,Y_test)\n",
    "print \"SCORE TEST=%f\"%score_test\n",
    "\n",
    "Y_pred_train = model.predict(X_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "kagg_train = eval_bikemodel(Y_pred_train,Y_train)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "\n",
    "print \"KAGG EVAL TRAIN =%f\"%kagg_train\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "print \"KAGG EVAL TEST =%f\"%kagg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se crea la función para evaluar los distintos clasificadores (modelos) denominada $eval\\_bikemodel()$, además de crear el input set y el output set (X y Y respectivamente) para los distintos *set*, utilizando las características procesadas en la pregunta anterior, es decir, las entregadas y reemplazando el *datetime* por la hora.  \n",
    "Se ajusta un árbol de regresión como clasificador para el problema sobre el *training set*, mostrándo distintas métricas, como el *accuracy* sobre el *test set* del 70%, la función para evaluar el error para este problema (**KAGG EVAL**) sobre el *validation set* del 55,4% y sobre el *test set* 57,4%. Se puede ver que las métricas difieren (siendo el error según el *accuracy* sobre el *test set* del 30%), debido a la forma distinta de medir el error para **KAGG EVAL**, aplicando logaritmo sobre la demanda (*target*) produciendo esta medición del error mayor y más significativa.  Al tener una medición del *score KAGG* sobre el *test set* del **57,4%** nos deja en un una posición mayor al 2140 en la competencia.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 374 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(Y_test,Y_pred_test,'.')\n",
    "plt.plot(range(1000),range(1000), color =\"r\")\n",
    "plt.xlabel('Valor Real')\n",
    "plt.ylabel('Prediccion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a este gráfico donde se puede comparar las predicciones del árbol de regresión versus los valores reales del *test set* (puntos azules), y la línea roja que representa la predicción exacta. Se puede ver que la predicción es bastante buena para algunos casos, presentándose *outliers* en la predicción. Además de ver que los valores (puntos azules) están cercanos en rango a la línea roja, mostrándose el error en su lejanía a esta, teniendo una gran cantidad de error (alrededor del 30% como lo calculado anteriormente). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Árbol de regresión - variando hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 449 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n"
     ]
    }
   ],
   "source": [
    "kaggs_val = []\n",
    "kaggs_train = []\n",
    "N_ts = np.arange(2,26)\n",
    "for n_t in N_ts:\n",
    "    model = Tree(random_state=0,max_depth=n_t)\n",
    "    model.fit(X_train,Y_train)\n",
    "\n",
    "    Y_pred_val = model.predict(X_val)\n",
    "    kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "    kaggs_val.append(kagg_val)\n",
    "    \n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    kagg_train = eval_bikemodel(Y_pred_train,Y_train)\n",
    "    kaggs_train.append(kagg_train)\n",
    "\n",
    "plt.figure(figsize=(15,5))    \n",
    "plt.plot(N_ts,kaggs_val , label  = \"Validation set\", color = \"y\")\n",
    "plt.plot(N_ts,kaggs_train, label = \"Training set\", color = \"b\")\n",
    "plt.xticks(N_ts)\n",
    "plt.xlabel('Numero de niveles')\n",
    "plt.ylabel('KAGG EVAL')\n",
    "plt.title('Valor de funcion KAGG para distintos niveles en un arbol de regresion (validation set)')\n",
    "plt.legend()\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se presenta un gráfico mostrándo como evoluciona la función de evaluación **KAGG** en función del número máximo de niveles del árbol de regresión. Se puede ver que a medida que aumenta el número de niveles (2-8) disminuye el error sobre el *validation set* y luego desde el nivel 8 en adelante el error sobre el *validation set* se mantiene y sobre el *training set* disminuye, produciéndo un claro *overfitting*. Para este caso se escoge una profundidad máxima de 10 niveles para el árbol de regresión ajustado en la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGG EVAL TEST =0.516396\n"
     ]
    }
   ],
   "source": [
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred_test = model.predict(X_test)\n",
    "kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "print \"KAGG EVAL TEST =%f\"%kagg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el árbol de regresión ajustado anteriormente con una máxima profundidad de 10 niveles se tiene un modelo con **KAGG EVAL** sobre el *test set* del **51,6%**, lo cual mejora un 5% al árbol de regresión sin máxima profundidad definido anteriormente. Con esta medición se avanza alrededor de unas 300 posiciones en el *leaderboard*, lo cual es lo esperado debido a que un árbol con máxima profundidad no se sobre ajusta a los datos con los que se entrena produciendo un clasificador más genérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 560 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(Y_test,Y_pred_test,'.')\n",
    "plt.plot(range(1000),range(1000), color =\"r\")\n",
    "plt.xlabel('Valor Real')\n",
    "plt.ylabel('Prediccion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Árbol de regresión - variando representación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 2011 total demand:  781979\n",
      "year 2012 total demand:  1303497\n"
     ]
    }
   ],
   "source": [
    "#procesamiento de fecha(datetime-timestamp) a numeros\n",
    "df['cday'] = pd.to_datetime(df['datetime']).dt.dayofweek#0:lunes,6:domingo\n",
    "df['cday'] = pd.to_numeric(df['cday'])\n",
    "\n",
    "df['year'] = pd.to_datetime(df['datetime']).dt.year\n",
    "df['year'] = pd.to_numeric(df['year'])\n",
    "\n",
    "df['month'] = pd.to_datetime(df['datetime']).dt.month#1:enero, 12: diciembre\n",
    "df['month'] = pd.to_numeric(df['month'])\n",
    "\n",
    "once = df[ (df['year'] == 2011)]\n",
    "print \"year 2011 total demand: \", sum(once['count'])\n",
    "donce = df[ (df['year'] == 2012)]\n",
    "print \"year 2012 total demand: \",sum(donce['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se extrae desde el *datetime* datos para tener una mejor representación de los datos y así mejorar el score obtenido hasta el momento. Se extrae el \"cday\" correspondiente al día de la semana codificado de 0 a 6, desde lunes a domingo respectivamente. Otro atributo que se extrae de la fecha es el año en que fueron realizado los distintos registros de datos y finalmente el mes del mismo, codificado desde 1 a 12 (enero a diciembre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected = hour ...\n",
      "selected = cday ...\n",
      "selected = season ...\n",
      "selected = year ...\n",
      "selected = month ...\n",
      "selected = holiday ...\n",
      "selected = workingday ...\n",
      "selected = weather ...\n",
      "selected = temp ...\n",
      "selected = humidity ...\n",
      "selected = windspeed ...\n",
      "selected = atemp ...\n",
      "se eliminaron\n",
      "set(['windspeed', 'atemp', 'temp', 'humidity'])\n"
     ]
    }
   ],
   "source": [
    "def fss(x, y, xval,yval, names_x, k = 10000):\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)+1\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = range(0, p+1)\n",
    "    selected = []\n",
    "    current_score = 0.0\n",
    "    best_new_score = 0.0\n",
    "    while remaining and len(selected)<=k :\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = Tree(max_depth = 10)\n",
    "            indexes = selected + [candidate]\n",
    "            x_train = x[:,indexes]\n",
    "            x_val = xval[:,indexes]\n",
    "            \n",
    "            predictions_val = model.fit(x_train, y).predict(x_val)\n",
    "            kagg_val = eval_bikemodel(predictions_val,yval) #en base al evaluador kagg\n",
    "            \n",
    "            score_candidates.append((kagg_val, candidate))\n",
    "        score_candidates.sort()\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        best_new_score, best_candidate = score_candidates.pop() #el de menor error es el mejor candidato\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        print \"selected = %s ...\"%names_x[best_candidate]\n",
    "    return selected\n",
    "\n",
    "names_features = ['season','holiday','workingday','weather','temp','atemp',\n",
    "    'humidity','windspeed','hour','cday','month','year']\n",
    "Xdf=df.ix[:,names_features]\n",
    "Ydf=df.ix[:,'count'] \n",
    "\n",
    "X_train = Xdf[0:ntrain].values\n",
    "X_val = Xdf[ntrain:nval].values\n",
    "Y_train = Ydf[0:ntrain].values\n",
    "Y_val = Ydf[ntrain:nval].values\n",
    "        \n",
    "new_names_features = fss(X_train,Y_train,X_val,Y_val,names_features)[:8]\n",
    "new_names_features = np.array(names_features)[new_names_features]\n",
    "print \"se eliminaron\"\n",
    "x = set(names_features)\n",
    "y = x - set(new_names_features)\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que se añaden más características, es necesario filtrar algunas de estas para ver el efecto, es por esto que en la celda anterior se ocupa **FSS** para determinar cuales son las características más influyentes para el problema según un modelo de árbol de regresión con 10 niveles como máximo. Se filtran, a partir de este algoritmo, 4 características (\"windspeed\", \"atemp\", \"temp\", \"humidity\") eliminando estas del modelo, es decir, se eliminan las nuḿericas dejando únicamente las características categóricas.  \n",
    "Finalmente, se obtienen 3 tipos de representaciones en base a las características en el modelo de regresión, sumado a la posible normalización del *input set* y una transformación al *output* (demanda), propuesto a continuación, se presentan finalmente 12 tipos posibles de representaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre|Características|Normalizado|Transformacion(y)\n",
    "------|---------------|-----------|--------------\n",
    "old|season, holiday, workingday, weather, temp, atemp, humidity,windspeed, hour|  X | X\n",
    "all|old + **cday**, **month**, **year** | X | X \n",
    "extract|season, holiday, workingday, weather, hour, cday,month, year|X|X|\n",
    "-|-|-|-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "representacion no normalizada de las viejas caracteristicas\n",
      "KAGG EVAL VAL =0.476274\n",
      "representacion normalizada de las viejas caracteristicas\n",
      "KAGG EVAL VAL =0.477858\n",
      "---------------------------------------------\n",
      "representacion no normalizada de todas las caracteristicas\n",
      "KAGG EVAL VAL =0.406954\n",
      "representacion normalizada de todas las caracteristicas\n",
      "KAGG EVAL VAL =0.407576\n",
      "---------------------------------------------\n",
      "representacion no normalizada con extraccion de caracteristicas\n",
      "KAGG EVAL VAL =0.393547\n",
      "representacion normalizada con extraccion de caracteristicas\n",
      "KAGG EVAL VAL =0.396293\n",
      "---------------------------------------------\n",
      "representacion normalizada con extracion de caracteristicas y transformar la respuesta\n",
      "KAGG EVAL VAL =0.402794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#print df2\n",
    "print \"---------------------------------------------\"\n",
    "names_features = ['season','holiday','workingday','weather','temp','atemp',\n",
    "'humidity','windspeed','hour','cday','month','year']\n",
    "\n",
    "df2 = df.ix[:,names_features+['count']]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "def representacion(df, features,scaler,vector=False):\n",
    "    if features == \"all\":\n",
    "        names_features = ['season','holiday','workingday','weather','temp','atemp',\n",
    "                            'humidity','windspeed','hour','cday','month','year']\n",
    "    elif features == \"old\":\n",
    "        names_features = ['season','holiday','workingday','weather','temp','atemp',\n",
    "                            'humidity','windspeed','hour']\n",
    "    elif features == \"extract\":\n",
    "        names_features = ['season','holiday','workingday','weather','hour','cday','month','year']\n",
    "\n",
    "    #se procesan las caract\n",
    "    Xdf=df.ix[:,names_features]\n",
    "    \n",
    "    if vector: #para representacion vectorial de variables categoricas que no son 0 y 1\n",
    "        all_categorical_features = ['season','weather','temp','hour','cday','month']\n",
    "        x = set(all_categorical_features)\n",
    "        categorical_features = x.intersection(names_features)\n",
    "\n",
    "        Xdf = pd.get_dummies(Xdf,columns=categorical_features) #categorizar las caract\n",
    "    \n",
    "    #se crean las matrices\n",
    "    Ydf=df.ix[:,'count'] #no se normaliza\n",
    "    X_train = Xdf[0:ntrain].values\n",
    "    X_val = Xdf[ntrain:nval].values\n",
    "    X_test = Xdf[nval:].values\n",
    "    Y_train = Ydf[0:ntrain].values\n",
    "    Y_val = Ydf[ntrain:nval].values\n",
    "    Y_test = Ydf[nval:].values\n",
    "        \n",
    "    #se escala\n",
    "    if scaler == \"standar\":\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        X_val = scaler.fit_transform(X_val)\n",
    "        \n",
    "        return X_train,Y_train,X_val,Y_val,X_test,Y_test\n",
    "            \n",
    "    elif scaler == \"normal\":\n",
    "        return X_train, Y_train, X_val, Y_val,X_test,Y_test\n",
    "    return 0\n",
    "   \n",
    "print \"representacion no normalizada de las viejas caracteristicas\"\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"old\",\"normal\")\n",
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "print \"representacion normalizada de las viejas caracteristicas\"\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"old\",\"standar\")\n",
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "print \"---------------------------------------------\"\n",
    "\n",
    "print \"representacion no normalizada de todas las caracteristicas\"\n",
    "X_train,Y_train,X_val,Y_val, X_test,Y_test = representacion(df2,\"all\",\"normal\")\n",
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "print \"representacion normalizada de todas las caracteristicas\"\n",
    "X_train,Y_train,X_val,Y_val, X_test,Y_test = representacion(df2,\"all\",\"standar\")\n",
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "print \"---------------------------------------------\"\n",
    "print \"representacion no normalizada con extraccion de caracteristicas\"\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"normal\")\n",
    "model = Tree(random_state=0,max_depth=10) \n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "print \"representacion normalizada con extraccion de caracteristicas\"\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"standar\")\n",
    "model = Tree(random_state=0,max_depth=10) \n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "print \"---------------------------------------------\"\n",
    "print \"representacion normalizada con extracion de caracteristicas y transformar la respuesta\"\n",
    "X_train,Y_train,X_val,Y_val, X_test,Y_test = representacion(df2,\"extract\",\"standar\")\n",
    "\n",
    "#transforma la respuesta (Target)\n",
    "Y_train = np.log(Y_train+1)\n",
    "Y_val = np.log(Y_val+1)\n",
    "        \n",
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train) #ajusta el modelo con target normalizado\n",
    "Y_pred_val = model.predict(X_val)\n",
    "\n",
    "#volver a la variable original\n",
    "Y_val = np.exp(Y_val)-1\n",
    "Y_pred_val = np.exp(Y_pred_val)-1\n",
    "\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se ajusta un árbol de regresión para las distintas representaciones creadas para el problema, eligiendo la representación que se ajusta mejor al score **KAGG EVAL** para el *validation set*, un error del 39,3% para la representación con el *input set* no normalizado y extrayendo características del modelo de regresión en base a la importancia según el algoritmo **FSS** para el árbol de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representacion no normalizada con extraccion de caracteristicas\n",
      "KAGG EVAL TEST =0.413617 \n"
     ]
    }
   ],
   "source": [
    "print \"representacion no normalizada con extraccion de caracteristicas\"\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"normal\")\n",
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "print \"KAGG EVAL TEST =%f \"%kagg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a la representación elegida según el mejor score sobre el *validation set*, correspondiente a la representación no normalizada de los datos con extracción de características, entrega un score **KAGG EVAL** sobre el *test set* del **41,4%**, mejorando el score de la pregunta anterior donde se varió unicamente la cantidad de niveles del árbol de regresión, es decir, el cambio de representación benefició al modelo. Con esto se entra en el top 1000 de la competencia.  \n",
    "Se espera que la representación sobre las características dejadas en el modelo según la extracción sean no normalizadas debido a que la mayoría son categóricas, por lo que tienen un mayor significado para el árbol de decisión codificadas con números discretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 659 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(Y_test,Y_pred_test,'.')\n",
    "plt.plot(range(1000),range(1000), color =\"r\")\n",
    "plt.xlabel('Valor Real')\n",
    "plt.ylabel('Prediccion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) SVM no lineal - distintas representaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 724 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n",
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 869 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n"
     ]
    }
   ],
   "source": [
    "Y = df.ix[:,'count']\n",
    "plt.boxplot(Y)\n",
    "plt.show()\n",
    "Y = np.log(Y+1)\n",
    "plt.boxplot(Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hola!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representacion normalizada de todas las caracteristicas y transformar el Y(target)\n",
      "KAGG EVAL VAL =0.386837\n",
      "-------------------------------------------------------\n",
      "representacion normalizada con todas las caracteristicas\n",
      "KAGG EVAL VAL =1.255825\n",
      "-------------------------------------------------------\n",
      "representacion normalizada con extraccion de caracteristicas y transformar el Y(target)\n",
      "KAGG EVAL VAL =0.320551\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"all\",\"standar\",vector=True)\n",
    "print \"representacion normalizada de todas las caracteristicas y transformar el Y(target)\"\n",
    "#transformar el Y\n",
    "Y_train = np.log(Y_train+1)\n",
    "Y_val = np.log(Y_val+1)\n",
    "        \n",
    "# Se ajusta a modelo SVR\n",
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "model.fit(X_train,Y_train)\n",
    "#Y_pred_train = model.predict(X_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "#volver a la variable original\n",
    "Y_train = np.exp(Y_train)-1\n",
    "Y_val = np.exp(Y_val) -1\n",
    "Y_pred_val = np.exp(Y_pred_val) -1\n",
    "Y_pred_test = np.exp(Y_pred_test)-1\n",
    "\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "print \"-------------------------------------------------------\"\n",
    "\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"all\",\"standar\",vector=True)\n",
    "print \"representacion normalizada con todas las caracteristicas\"\n",
    "\n",
    "# Se ajusta a modelo SVR\n",
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "print \"-------------------------------------------------------\"\n",
    "\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"standar\",vector=True)\n",
    "print \"representacion normalizada con extraccion de caracteristicas y transformar el Y(target)\"\n",
    "#transformar el Y\n",
    "Y_train = np.log(Y_train+1)\n",
    "Y_val = np.log(Y_val+1)\n",
    "        \n",
    "# Se ajusta a modelo SVR\n",
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "model.fit(X_train,Y_train)\n",
    "#Y_pred_train = model.predict(X_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "#volver a la variable original\n",
    "Y_train = np.exp(Y_train)-1\n",
    "Y_val = np.exp(Y_val) -1\n",
    "Y_pred_val = np.exp(Y_pred_val) -1\n",
    "Y_pred_test = np.exp(Y_pred_test)-1\n",
    "\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso se ajusta un clasificador *SVM* no lineal intentando mejorar el score del árbol de regresión definido anteriormente. En primer lugar se realiza una representación especial para este caso donde las variables categóricas, que no varían entre 1 y 0 (si y no), son transformadas en un vector binario donde va un 1 si es en ese caso, por ejemplo para la variable \"season\", esta será dividida en 4 vectores binarios simbolizando las 4 estaciones del año, en este caso si la \"season\" es *fall*  tendrá un 1 en el vector binario que corresponda a la \"season\" *fall*.  \n",
    "Otro factor importante es que es necesario un escalamiento de los datos (*input* y *output*) para tener rangos comparables y tener una mejor predicción. Como se ve en los resultados de la celda anterior si es que el *output* (target) no es transformado, el clasificador *SVM* logra predecir el modelo de una manera muy escasa, obteniendo un error **KAGG EVAL** del 125%. Para esto se realiza una transformación al *output* de la misma manera que la función **KAGG EVAL**, es decir aplicando logaritmo natural mas uno al valor a transforma, luego invirtiendo esta operación cuando se evalúa sobre la función **KAGG EVAL**. Esta transformación es requerida ya que los valores de la demanda son bastante altos (hasta 977 como se vio en la letra *a*) ), reduciendo el rango en el que varía estando continuamente entre 0 y 7 aproximadamente, elimimando los *outliers*\n",
    "\n",
    "Se elige la representación con menor error de **KAGG EVAL** sobre el *validation set*, la cual es la que normaliza el *input set* con la representación extrayendo características y transformando el target, un score del 32%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representacion normalizada con extraccion de caracteristicas y transformar el Y\n",
      "KAGG EVAL TEST =0.343653 \n"
     ]
    }
   ],
   "source": [
    "print \"representacion normalizada con extraccion de caracteristicas y transformar el Y\"\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"standar\",vector=True)\n",
    "#transformar el Y\n",
    "Y_train = np.log(Y_train+1)\n",
    "        \n",
    "# Se ajusta a modelo SVR\n",
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "#volver a la variable original\n",
    "Y_pred_test = np.exp(Y_pred_test)-1\n",
    "\n",
    "kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "print \"KAGG EVAL TEST =%f \"%kagg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta representación elegida según el *validation set* se logra un score *KAGG EVAL* sobre el *test set* del **34,4%**, utilizando los hiperparámetros por defectos de la *SVM*. Entrando ya en el top 10 del *leaderboard*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 979 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(Y_test,Y_pred_test,'.')\n",
    "plt.plot(range(1000),range(1000), color =\"r\")\n",
    "plt.xlabel('Valor Real')\n",
    "plt.ylabel('Prediccion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) SVR (regresion) no lineal - variación de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representacion con extraccion de caracteristicas normalizadas y transformar el Y(target)\n",
      "[[1.4082932660716465, 1.4084854078286415, 1.408290320311923, 1.3880066416156127, 1.6644681370370946], [1.0976059992374543, 1.0981263092264608, 1.0992643686290147, 1.1654884610229708, 1.6644681370370946], [0.45048495053006765, 0.45043817619250492, 0.45176715859134409, 0.77451963138845348, 1.6644681370370946], [0.3214669929108584, 0.32094457559331713, 0.32055055323835274, 0.6757385160570123, 1.6644681370370946], [0.36565862478440092, 0.3644692642586706, 0.35770076731199224, 0.66641216203463538, 1.6644681370370946], [0.39752891182952899, 0.3949076073807552, 0.37599482786505783, 0.66641216203463416, 1.6644681370370946]]\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"standar\",vector=True)\n",
    "print \"representacion con extraccion de caracteristicas normalizadas y transformar el Y(target)\"\n",
    "\n",
    "# Se ajusta a modelo SVR\n",
    "from sklearn.svm import SVR\n",
    "Cs = [0.001,0.01,0.1,1,10,100]\n",
    "es = [0.001,0.01,0.1,1,10]\n",
    "info = []\n",
    "for c in Cs:\n",
    "    subinfo=[]\n",
    "    for e in es:\n",
    "        #transformar el Y\n",
    "        Y_train = np.log(Y_train+1)\n",
    "        Y_val = np.log(Y_val+1)\n",
    "\n",
    "        model = SVR(C=c, epsilon=e)\n",
    "        model.fit(X_train,Y_train)\n",
    "        Y_pred_val = model.predict(X_val)\n",
    "\n",
    "        #volver a la variable original\n",
    "        Y_train = np.exp(Y_train) -1\n",
    "        Y_val = np.exp(Y_val) -1\n",
    "        Y_pred_val = np.exp(Y_pred_val) -1\n",
    "\n",
    "        #kagg_train = eval_bikemodel(Y_pred_train,Y_train)\n",
    "        kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "        subinfo.append(kagg_val)\n",
    "    info.append(subinfo)\n",
    "print info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========  ========  ========  ========  ========  ========\n",
      "C/Epsilon  0.001     0.01      0.1       1         10\n",
      "0.001      1.40829   1.40849   1.40829   1.38801    1.66447\n",
      "0.01       1.09761   1.09813   1.09926   1.16549    1.66447\n",
      "0.1        0.450485  0.450438  0.451767  0.77452    1.66447\n",
      "1          0.321467  0.320945  0.320551  0.675739   1.66447\n",
      "10         0.365659  0.364469  0.357701  0.666412   1.66447\n",
      "100        0.397529  0.394908  0.375995  0.666412   1.66447\n",
      "=========  ========  ========  ========  ========  ========\n"
     ]
    }
   ],
   "source": [
    "fila1 = ['C/Epsilon']+es\n",
    "filas = [[Cs[i]]+info[i] for i in range(len(info))]\n",
    "table = [fila1]+filas\n",
    "from tabulate import tabulate\n",
    "print tabulate(table,   tablefmt=\"rst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estas celdas se ajusta un clasificador *SVM* no lineal con kernel \"RBF\" variando los hiperparámetros de esta y con la representación adecuada (*input* normalizado, atributos categóricos en vector binario y transformación al target). En la tabla anterior se presentan los distintos scores de la función **KAGG EVAL** en el *validation set*. En la columna de la izquierda se ve como varía el hiperparámetro *C*, en la primera fila se ve como varía el hiperparámetro $\\epsilon$.  \n",
    "Se puede ver que para valores altos de $\\epsilon$ el error aumenta, y para valores pequeños de *C* también, visualizado en la parte superior derecha (diagonal superior) de la tabla. Para valores pequeños de *C* el clasificador *SVM* se relaja, penalizando menos y permitiendo un mayor error sobre el *training set*.  \n",
    "\n",
    "El menor error sobre el *validation set* se produce en el centro de la tabla, con los hiperparámetros configurados en 1 y 0.1 para *C* y $\\epsilon$ respectivamente, siendo un valor de 32,1% de error, utilizando esta configuración de parámetros para predecir el *test set* a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGG EVAL TEST =0.343653 \n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"standar\",vector=True)\n",
    "\n",
    "#transformar el Y\n",
    "Y_train = np.log(Y_train+1)\n",
    "\n",
    "model = SVR(C=1, epsilon=0.1)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "#volver a la variable original\n",
    "Y_pred_test = np.exp(Y_pred_test) -1\n",
    "\n",
    "kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "print \"KAGG EVAL TEST =%f \"%kagg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que este error es el mismo que para los parámetros por defecto, esto es ya que los parámetros seteados son los por defecto, siendo esa la mejor configuración para ajustar a este problema una *SVM* no lineal con la representación dada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G) Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Decision Tree\n",
      "representacion no normalizada con extraccion de caracteristicas\n",
      "BEST DEPTH =  30\n",
      "*SVM\n",
      "representacion normalizada con extraccion de caracteristicas y Transformar Y\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "def cross_validation_fun(X_train,Y_train,model):\n",
    "    k_fold = cross_validation.KFold(len(X_train)-2,10)\n",
    "    score_cv = 0\n",
    "    for k, (train, val) in enumerate(k_fold):\n",
    "        #model = ) #SVR(C=1,epsilon=0.1)\n",
    "        aux_model = model\n",
    "        aux_model.fit(X_train[train], Y_train[train])\n",
    "        Ypred_val = aux_model.predict(X_train[val])\n",
    "        Ytrue_val = Y_train[val]\n",
    "        score_fold = eval_bikemodel(Ypred_val,Ytrue_val)\n",
    "        score_cv += score_fold\n",
    "    score_cv = score_cv / 10\n",
    "    return score_cv\n",
    "\n",
    "def cross_validation_svm(X_train,Y_train,model):\n",
    "    k_fold = cross_validation.KFold(len(X_train)-2,10)\n",
    "    score_cv = 0\n",
    "    for k, (train, val) in enumerate(k_fold):\n",
    "        aux_model = model\n",
    "        aux_model.fit(X_train[train], Y_train[train])\n",
    "        Ypred_val = aux_model.predict(X_train[val])\n",
    "        Ytrue_val = Y_train[val]\n",
    "        \n",
    "         #volver a la variable original\n",
    "        Ypred_val = np.exp(Ypred_val) -1\n",
    "        Ytrue_val = np.exp(Ytrue_val) -1\n",
    "        \n",
    "        score_fold = eval_bikemodel(Ypred_val,Ytrue_val)\n",
    "        score_cv += score_fold\n",
    "    score_cv = score_cv / 10\n",
    "    return score_cv\n",
    "\n",
    "\n",
    "#añadir X_val a X_train\n",
    "newX_train = np.concatenate((X_train,X_val))\n",
    "newY_train = np.concatenate((Y_train,Y_val))\n",
    "\n",
    "\n",
    "print \"*Decision Tree\" #mejor representacion para el arbol\n",
    "print \"representacion no normalizada con extraccion de caracteristicas\"\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"normal\")\n",
    "\n",
    "N = np.arange(1,31)\n",
    "mejor = 1\n",
    "mejor_numero = 0\n",
    "for n in N:\n",
    "    model = Tree(random_state=0,max_depth=n)\n",
    "    model.fit(X_train,Y_train)    \n",
    "    val = cross_validation_fun(newX_train,newY_train, model)\n",
    "    if val < mejor:\n",
    "        mejor = val\n",
    "        mejor_numero = n\n",
    "print \"BEST DEPTH = \",mejor_numero\n",
    "\n",
    "\n",
    "print \"*SVM\" #mejor representacion para el arbol\n",
    "print \"representacion normalizada con extraccion de caracteristicas y Transformar Y\"\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"standar\",vector=True)\n",
    "\n",
    "Cs = [0.001,0.01,0.1,1,10,100]\n",
    "es = [0.001,0.01,0.1,1,10]\n",
    "mejor = 1\n",
    "mejor_numero = []\n",
    "for c in Cs:\n",
    "    for e in es:\n",
    "        #transformar el Y\n",
    "        newY_train = np.log(newY_train+1)\n",
    "        model = SVR(C=c, epsilon=e)\n",
    "        model.fit(newX_train,newY_train)\n",
    "        val = cross_validation_svm(newX_train,newY_train, model)\n",
    "        if val < mejor:\n",
    "            mejor = val\n",
    "            mejor_numero = [c,e]\n",
    "        #volver a la variable original\n",
    "        newY_train = np.exp(newY_train) -1\n",
    "print \"BEST CONFIG C =%f , e =%f \"%(mejor_numero[0],mejor_numero[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"*Decision Tree\"\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"normal\")\n",
    "model = Tree(random_state=0,max_depth=12)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "print \"KAGG EVAL TEST =%f \"%kagg_test   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se presenta el error sobre el *test set* del árbol de regresión prediciendo su parámetro (máxima profundidad) con el método *cross validation*, este error es **40%**, lo cual es mejor que el error sobre el árbol de regresión prediciendo su parámetro con el *validation set* siendo de 41,4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H) Ensamblador (Registered-Casual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 3036 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spring_rows1 = df[ (df['season'] == 1) & (df['hour'] <= 6)]\n",
    "spring_rows2 = df[ (df['season'] == 1) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "spring_rows3 = df[ (df['season'] == 1) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "spring_rows4 = df[ (df['season'] == 1) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "spring_rows5 = df[ (df['season'] == 1) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "spring_rows6 = df[ (df['season'] == 1) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "spring_vals_reg = [sum(spring_rows1['registered']),sum(spring_rows2['registered']),\n",
    "                   sum(spring_rows3['registered']),sum(spring_rows4['registered'])\n",
    "                  ,sum(spring_rows4['registered']),sum(spring_rows4['registered'])]\n",
    "spring_vals_cas = [sum(spring_rows1['casual']),sum(spring_rows2['casual']),\n",
    "                   sum(spring_rows3['casual']),sum(spring_rows4['casual'])\n",
    "                  ,sum(spring_rows4['casual']),sum(spring_rows4['casual'])]\n",
    "\n",
    "summer_rows1 = df[ (df['season'] == 2) & (df['hour'] <= 6)]\n",
    "summer_rows2 = df[ (df['season'] == 2) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "summer_rows3 = df[ (df['season'] == 2) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "summer_rows4 = df[ (df['season'] == 2) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "summer_rows5 = df[ (df['season'] == 2) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "summer_rows6 = df[ (df['season'] == 2) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "summer_vals_reg = [sum(summer_rows1['registered']),sum(summer_rows2['registered']),\n",
    "               sum(summer_rows3['registered']),sum(summer_rows4['registered'])\n",
    "              ,sum(summer_rows4['registered']),sum(summer_rows4['registered'])]\n",
    "summer_vals_cas = [sum(summer_rows1['casual']),sum(summer_rows2['casual']),\n",
    "               sum(summer_rows3['casual']),sum(summer_rows4['casual'])\n",
    "              ,sum(summer_rows4['casual']),sum(summer_rows4['casual'])]\n",
    "\n",
    "fall_rows1 = df[ (df['season'] == 3) & (df['hour'] <= 6)]\n",
    "fall_rows2 = df[ (df['season'] == 3) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "fall_rows3 = df[ (df['season'] == 3) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "fall_rows4 = df[ (df['season'] == 3) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "fall_rows5 = df[ (df['season'] == 3) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "fall_rows6 = df[ (df['season'] == 3) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "fall_vals_reg = [sum(fall_rows1['registered']),sum(fall_rows2['registered']),\n",
    "             sum(fall_rows3['registered']),sum(fall_rows4['registered'])\n",
    "              ,sum(fall_rows4['registered']),sum(fall_rows4['registered'])]\n",
    "fall_vals_cas = [sum(fall_rows1['casual']),sum(fall_rows2['casual']),\n",
    "             sum(fall_rows3['casual']),sum(fall_rows4['casual'])\n",
    "              ,sum(fall_rows4['casual']),sum(fall_rows4['casual'])]\n",
    "\n",
    "winter_rows1 = df[ (df['season'] == 4) & (df['hour'] <= 6)]\n",
    "winter_rows2 = df[ (df['season'] == 4) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "winter_rows3 = df[ (df['season'] == 4) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "winter_rows4 = df[ (df['season'] == 4) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "winter_rows5 = df[ (df['season'] == 4) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "winter_rows6 = df[ (df['season'] == 4) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "winter_vals_reg = [sum(winter_rows1['registered']),sum(winter_rows2['registered']),\n",
    "               sum(winter_rows3['registered']),sum(winter_rows4['registered'])\n",
    "              ,sum(winter_rows4['registered']),sum(winter_rows4['registered'])]\n",
    "winter_vals_cas = [sum(winter_rows1['casual']),sum(winter_rows2['casual']),\n",
    "               sum(winter_rows3['casual']),sum(winter_rows4['casual'])\n",
    "              ,sum(winter_rows4['casual']),sum(winter_rows4['casual'])]\n",
    "\n",
    "# Construir histograma -------------------------------------------\n",
    "\n",
    "#PARA COMPARAR LAS EPOCAS DEL AÑO\n",
    "f, axarr = plt.subplots(1,2, figsize=(14,5) )\n",
    "axarr[0].plot(np.arange(0,6,1), spring_vals_reg, color = 'b', label = \"spring\")\n",
    "axarr[0].plot(np.arange(0,6,1), summer_vals_reg, color = 'r', label = \"summer\")\n",
    "axarr[0].plot(np.arange(0,6,1), fall_vals_reg, color = 'c', label = \"fall\")\n",
    "axarr[0].plot(np.arange(0,6,1), winter_vals_reg, color = 'y', label = \"winter\")\n",
    "axarr[0].set_xticks(np.arange(0,6))\n",
    "axarr[0].set_xticklabels(('6am','9am','12pm','15pm','6pm','12am'))\n",
    "axarr[0].set_title('Registered')\n",
    "axarr[0].set_ylabel('Ventas')\n",
    "axarr[0].axis('tight')\n",
    "\n",
    "axarr[0].legend(loc=4)\n",
    "\n",
    "axarr[1].plot(np.arange(0,6,1), spring_vals_cas, color = 'b', label = \"spring\")\n",
    "axarr[1].plot(np.arange(0,6,1), summer_vals_cas, color = 'r', label = \"summer\")\n",
    "axarr[1].plot(np.arange(0,6,1), fall_vals_cas, color = 'c', label = \"fall\")\n",
    "axarr[1].plot(np.arange(0,6,1), winter_vals_cas, color = 'y', label = \"winter\")\n",
    "axarr[1].set_xticks(np.arange(0,6))\n",
    "axarr[1].set_xticklabels(('6am','9am','12pm','15pm','6pm','12am'))\n",
    "axarr[1].set_title('Casual')\n",
    "axarr[1].set_ylabel('Ventas')\n",
    "axarr[1].axis('tight')\n",
    "\n",
    "axarr[1].legend(loc=2)\n",
    "\n",
    "f.tight_layout() #separar los subplot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el efecto de los ensamblados de 2 maquinas de aprendizaje en su intento para predecir la demanda total de bicicletas, se confeccionan dos graficos que muestran el valor de ventas acumuladas entre 5 rangos horarios, que cubren todas las horas del dia. Uno de los graficos representa la prediccion de demanda por parte de los usuarios registrados (*Registered*) y el otro la prediccion de la demanda por parte de los usuarios casuales (*Casual*).\n",
    "Se piensa que las representaciones son distintas.\n",
    "\n",
    "Como se puede observar en el grafico *Registered*, la acumulacion de ventas de este tipo de usuario se produce principalmente entre las 6am y las 9am, y luego las ventas son oscilantes, lo que hace pensar que este tipo de usuario tiene una rutina mas madrugadora.\n",
    "Tambien se puede observar que la cantidad de ventas es diferente por cada epoca del año, produciendose mas ventas en **otoño** e **invierno**.\n",
    "\n",
    "Por el lado del grafico *Casual*, se puede visualizar que el horario del dia en que se realizan las ventas tiene una tendencia ascendente, es decir, a medida que se hace mas tarde las ventas tienden a aumentar gradualmente.\n",
    "Este grafico presenta una diferencia con el grafico anterior, puesto que las epocas del año en que se producen mas ventas en este caso son **otoño** y **verano**.\n",
    "\n",
    "Es importante notar que la escala de ventas de ambos graficos es diferente, teniendo una mayor dimension la del grafico *Registered*, registrando una acumulacion de ventas por sobre los 90.000, a diferencia de *Casual* que llega a valores del orden de los 30.000.\n",
    "Esto concuerda con lo esperado, ya que los usuarios registrados tienden a efecturar compras de manera periodica, versus los usuarios casuales que realizan compras de vez en cuando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**la demanda es definida registered-casual**\n",
      "Para la combinacion SVM-SVM\n",
      "KAGG EVAL VAL =0.319178\n",
      "Para la combinacion SVM-TREE\n",
      "KAGG EVAL VAL =0.320107\n",
      "Para la combinacion TREE-SVM\n",
      "KAGG EVAL VAL =0.358993\n",
      "Para la combinacion TREE-TREE\n",
      "KAGG EVAL VAL =0.370031\n"
     ]
    }
   ],
   "source": [
    "Y=df.ix[:,['count','registered','casual']] #demanda total\n",
    "#print Y\n",
    "\n",
    "def do_ensambler(df,Y,model1,model2):\n",
    "    # ------------------ Demanda Registrada ---------------------------\n",
    "    Yreg=Y.ix[:,'registered']     \n",
    "    Yreg_train = Yreg[0:ntrain].values\n",
    "    Yreg_val = Yreg[ntrain:nval].values\n",
    "    Yreg_test = Yreg[nval:].values\n",
    "\n",
    "    if model1 == \"arbol\":\n",
    "        X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df,\"extract\",\"normal\")\n",
    "        model = Tree(random_state=0,max_depth=10)\n",
    "        \n",
    "    elif model1 == \"svm\":\n",
    "        X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df,\"extract\",\"standar\",vector=True)\n",
    "        #transformar el Y de entrenamiento\n",
    "        Yreg_train = np.log(Yreg_train+1)\n",
    "        \n",
    "        model = SVR(C=1, epsilon=0.1)\n",
    "        \n",
    "    model.fit(X_train,Yreg_train)\n",
    "    Yreg_pred_val = model.predict(X_val)\n",
    "    Yreg_pred_test = model.predict(X_test)\n",
    "    \n",
    "    if model1==\"svm\": #volver a variable original\n",
    "        Yreg_pred_val = np.exp(Yreg_pred_val)-1\n",
    "        Yreg_pred_test = np.exp(Yreg_pred_test)-1\n",
    " \n",
    "    # ------------------ Demanda Casual ---------------------------\n",
    "    Ycas=Y.ix[:,'casual'] #demanda casual\n",
    "    Ycas_train = Ycas[0:ntrain].values\n",
    "    Ycas_val = Ycas[ntrain:nval].values\n",
    "    Ycas_test = Ycas[nval:].values\n",
    "    \n",
    "    if model2 == \"arbol\":\n",
    "        X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df,\"extract\",\"normal\")\n",
    "        model = Tree(random_state=0,max_depth=10)\n",
    "        \n",
    "    elif model2 == \"svm\":\n",
    "        X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df,\"extract\",\"standar\",vector=True)\n",
    "        #transformar Y entrenamiento\n",
    "        Ycas_train = np.log(Ycas_train+1)\n",
    "        \n",
    "        model = SVR(C=1,epsilon=0.1)\n",
    "    \n",
    "    model.fit(X_train,Ycas_train)\n",
    "    Ycas_pred_val = model.predict(X_val)\n",
    "    Ycas_pred_test = model.predict(X_test)\n",
    "    \n",
    "    if model2 == \"svm\": #volver a variable original\n",
    "        Ycas_pred_val = np.exp(Ycas_pred_val)-1\n",
    "        Ycas_pred_test = np.exp(Ycas_pred_test) -1\n",
    "\n",
    "    return Yreg_pred_val+Ycas_pred_val, Yreg_pred_test+Ycas_pred_test\n",
    "\n",
    "\n",
    "\n",
    "print \"**la demanda es definida registered-casual**\"\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"standar\",vector=True)\n",
    "\n",
    "print \"Para la combinacion SVM-SVM\"\n",
    "Y_pred_val,Y_pred_test = do_ensambler(df2,Y,\"svm\",\"svm\")\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "print \"Para la combinacion SVM-TREE\"\n",
    "Y_pred_val,Y_pred_test = do_ensambler(df2,Y,\"svm\",\"arbol\")\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "print \"Para la combinacion TREE-SVM\"\n",
    "Y_pred_val,Y_pred_test = do_ensambler(df2,Y,\"arbol\",\"svm\")\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "print \"Para la combinacion TREE-TREE\"\n",
    "Y_pred_val,Y_pred_test = do_ensambler(df2,Y,\"arbol\",\"arbol\")\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se crea un ensamblado ajustando 2 modelos regresores, cada uno ajustado y especializado sobre una parte de la data, esto se produce ya que la data se divide en demanda de usuarios registrados y demanda de usuarios casuales, por lo que se evalúa el efecto de utilizar este ensamblado donde cada máquina se ajusta a los usuarios registrados o los usuarios casuales. Por ejemplo si se escoge la combinacuón árbol-svm, el árbol de decisión se ajusta y especializa sobre la demanda de usuarios registrados, por otro lado el svm se ajusta y especializa sobre la demanda de usuarios casuales.  \n",
    "Distintas combinaciones son presentadas en la celda anterior mostrándo su score del error **KAGG EVAL** sobre el *validation set*, eligiendo la mejor de estas (*SVM-SVM*) para evaluar su score sobre el *test set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la combinacion SVM-SVM\n",
      "BEST KAGG EVAL in TEST SET =0.342514\n"
     ]
    }
   ],
   "source": [
    "print \"Para la combinacion SVM-SVM\"\n",
    "Y_pred_val,Y_pred_test = do_ensambler(df2,Y,\"svm\",\"svm\")\n",
    "kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "print \"BEST KAGG EVAL in TEST SET =%f\"%kagg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presenta el error sobre el *test set* de un **34,3%**, valor menor que una única svm ajustada sobre todo el dataset (34,4%). Esto es gracias a que un ensamblado presenta un mayor desempeño que una máquina singular debido a que una máquina puede presentar errores que la otra máquina corrige, es por esto que dos máquinas ensamblados una especializándose en una parte de la data entrega un mejor score. Además de que cada parte de la data se comporta de una manera distinta (usuarios registrados vs usuarios casuales) mostrádo en el gráfico anterior, por lo que resulta conveniente ajustar 2 máquinas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST NUMBER OF TREES = 20\n",
      "--------------------------------------------\n",
      "BEST DEEPTH= 13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = representacion(df2,\"extract\",\"normal\")\n",
    "\n",
    "N = np.arange(1,31)\n",
    "info1 = []\n",
    "mejor = 1\n",
    "mejor_numero = 0\n",
    "for n_trees in N:\n",
    "    model = RandomForestRegressor(n_estimators=n_trees,max_depth=10,random_state=0)\n",
    "    model.fit(X_train,Y_train)    \n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_val = model.predict(X_val)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    #para grafico de mas abajo\n",
    "    kagg_train = eval_bikemodel(Y_pred_train,Y_train)\n",
    "    kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "    info1.append([kagg_train,kagg_test])\n",
    "    \n",
    "    val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "    if val <mejor:\n",
    "        mejor = val\n",
    "        mejor_numero = n_trees\n",
    "print \"BEST NUMBER OF TREES = %d\"%mejor_numero\n",
    "print \"--------------------------------------------\"\n",
    "\n",
    "N = np.arange(1,31)\n",
    "info2 = []\n",
    "mejor = 1\n",
    "mejor_niveles = 0\n",
    "for level in N:\n",
    "    model = RandomForestRegressor(n_estimators=20,max_depth=level,random_state=0)\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_val = model.predict(X_val)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "\n",
    "    kagg_train = eval_bikemodel(Y_pred_train,Y_train)\n",
    "    kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "    info2.append([kagg_train,kagg_test])\n",
    "    \n",
    "    val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "    if val <mejor:\n",
    "        mejor = val\n",
    "        mejor_niveles = level\n",
    "print \"BEST DEEPTH= %d\"%mejor_niveles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se ajusta un clasificador *Random Forest Regresor* el cual es un ensamblador de *n* árboles de regresión para este caso. Se varía la cantidad de árboles utilizados en el ensamblado como la cantidad de niveles para el mejor clasificador, ajustando sobre el clasificador y tomando la decisión en base al error de la función **KAGG EVAL** sobre el *validation set*. Presentando la mejor configuración de cantidad de árboles en el ensamblado (20) y la máxima profunidad de cada árbol de regresión en el ensamblado (13), se ve el efecto sobre el *test set* a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "BEST KAGG EVAL in TEST SET =0.370870\n"
     ]
    }
   ],
   "source": [
    "print \"--------------------------------------------\"\n",
    "model = RandomForestRegressor(n_estimators=20,max_depth=13,random_state=0)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "print \"BEST KAGG EVAL in TEST SET =%f\"%kagg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El score sobre el *test set* (en base **KAGG EVAL**) es del 37,1%, este error es mayor que el de la *SVM*, pero menor que el de los árboles de decisión ajustados anteriormente (alrededor del 40%). Con esto se puede ver el poder de un ensamblado de $n$ árboles donde tiene un mayor poder para entregar una buena predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAFRCAYAAAAhPBPJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd8FHX+x/HXJ4XQEgwtIGA4lKpUEVFR0RNFRRBsoKKe\n/WycimI9RM8T9U7Rn3p3nqiHiig2UBBUNCo2UBGUrtKRJiV0SPL9/TGTsFl208hmd5P38/HIIzv9\nM7Oz+9nPzHdmzDmHiIiIiIiIVB0J0Q5AREREREREKpYKQRERERERkSpGhaCIiIiIiEgVo0JQRERE\nRESkilEhKCIiIiIiUsWoEBQREREREaliVAhKRJjZC2Z2f7TjKA9mlmlmeWamzwuxtT3MrLqZvWtm\nm83stQjMf4mZney/vtPMni3JuGVYzidmdnlZ4xSp6pRzRMDM/mVmd0c5hkrzWQwUuF5m1sPM5h/g\n/JqZWbaZWflEWDb6kolhZrbUzHb4O8pW//+T0Y4rFphZlpnt9LfJOjN708wyIrjIiDxwM2g98t/j\noyOxrCJiyDOzFqWcLFYeQHou0ABId85dEMkFOececs5dHcllhGJmh5vZFDNbb2a5IYanm9nbZrbN\nL0YHVXSMUjko54SnnFOuMZQl55R3DC3N7B3/vdxgZu+bWaugcW42s9/MbJOZPWdmydGKt6Scc392\nzj0Y7TgqO+fcdOdc2wOcxwrnXJqL8gPdVQjGNgec6e8oqf7/m0KNaGaJJelXlNKOX17KuFwHXOec\nSwMOA2oD/yjXwCpGwXoEvMfflHYmB3hEKVaKukJKuF9kAoui/UUaYXuB14BwZwyfAXbhFcQXA/8y\nswNKUFJlKeeEp5wToBLknIOACUArIAOY6XcDYGanAbcDJwHNgUOBERUepZRJtL5b4pEKwdgX8svW\nzC41s+lm9piZ/Q4MD9PPzOwe/0jvGjN70czS/HnkNz+53MyWAdNCLKee3/Ruk5n9bmafBgxr4zdp\n22RmP5rZWUGTNzCzD/wjjp+Y2SEB0+aZ2XVmtghYFDC/D/zlzDez80qybZxz2cA7QKeA+R9lZl/6\nsa0ys/8zs6Sg5V9jZov85T0VMCzBzP7hn4H5GTgzaJs0NrMJ/nSLzOzKgGHDzex1M3vJX+/Z/pHH\nO8xsrZktM7NeodYjxLY/1sxm+OvwjZkdEzDsEzP7m/9+bwf+YGZpZjbazFab2QozeyA/WZvZof6R\n4M3+EdBX/f6f+suf48e73zYvwfZI84+W7rfcEPMabmbjzWycv7xvzaxDwPAlZna7mc0GtvnLbhtq\nPzOz+4C/AgP9ef3Jn/9LAfMr1MTKn8/9/nbLNu9MW92A8Qeb91lZb2Z3hYj9pRKOW9z+18vfxzeZ\n2f8RZh8AcM4tcs69AMwLsT1rAgOAe5xzO51zXwATgcHh5idSDOWcYraNck5kc44/3lVmNs8f5ycz\n6+T3D7sPmNd07ykze8+f7isz+0Oo+TvnZjrnXnDObXbO5QKPA63NLN0f5RJgtHNugXNuC/AA8Kcw\nsebv15eZ2XL/fbrGzLr678dG/3s+f/wWZjbNvDOR68zs5fzPiD+8s5l9Z2ZbzMuVr9q+JomXmtnn\nQcsvOMNqhZsvnui/L7f4+8IqM7ssYLozzOx7fznLzGx4wLAUf5/aELA/NAiz/oXiBaoHDe9jZrP8\n+Uw3s/ah5uOPO8rfhlvMbKaZ9QgYVpbfD43N7A1/O/9iZjcGze81M/ufP78fzaxLSdYrf9v6r8+3\nfWfXs81sl5l9XIJtHPz7pMS/pcqVc05/MfoHLAFODjPsUrwzBdfhFfQpYfpdjpf0MoGawJvAGH8e\nmUAe8CJQA0gJsZy/451xSAASgeP8/knAYmCY//okIBto6Q9/AdgCHAckA6OAzwPmmwdMxTsql+LH\nthzvy9fwEuw6oG2Y9f8EuNx/XQ/4EHgrYHgXoJs/r0OAucBNQcufCKQCzfxlneoPuxbvR/fBfnwf\nA7lAgj/8U+D//PXq6E97kj9sOLADOMXfZv8DfgXu9LfflcCvodYjaP3SgY3Ahf58Bvrd6QHTLQXa\n+MOT8H6YPIP3ZVUf+Bq4yh9/LHCn/7oacGzQtvhDEfthcdsj7HJDzGs4sBvo72+PW/3tkxiwz3/v\nLyuF4vez4fj7c5juzKBYP/Hnd6g//0+Av/vD2gFb2bfP/hPYg/8ZDJx3CcYNu//h7a9bArbBX/A+\nt/vtB0Hb7lAgN6hfJ2B7UL9bgQnR/v7SX/z9oZyjnBMbOec8YAXQxe9u4W+zkuwDG4Aj/RhfBsaW\ncN8/G1gV0P0DcF5Adz3/PUkPMW3+fv2Mv66nADuBt/zpDgbWAsf74x8K/NFfh3pAFvCYPyzZ3843\n+e/fOXi55f6Az+FnQcvPBVoEbIP8cU/E+3wO9+d1OrAdqOMPPwE43H99BPAb0NfvvhrvDGkK3j7d\nGagdYt2Li7eLv+5d/fkMxvueSQ7zPlyI9xlIAG72Y6oWsK+X5veDAd8Cd/vjNwd+BnoFfXZO88f9\nO/BVCdfrRGB5iPhT8T7LV5ZgGwf/Pinxb6ly/d6P9AL0dwBvjrdTZ+N9GW/y/1/hD7sUWBo0fqh+\nHwHXBnS38nfmhICdMLOIGEYAbwOHBvXvAawO6jcW+Kv/+gUCvoCBWkAO0MTvzgNODBh+PvBp0Pz+\nDdwbJq5PgG3+dsnzP/xNi1iPIcCbAd15wDEB3a8Bt/uvpwFXBwzrlf9hxUtGe4GaAcP/Djzvvx4O\nTA0Y1sd/D83vru0vOy1oPfLf42/9/hcDXwetw5fAJQHT3RcwrCFe88CUgH4DgWn+6//527NJiG2T\nh59Ewmy7orZHRpjlfhxmXsOBLwO6DVjNvh97S4BLS7GfDaf0heBdAcP/DEz2X99L4X22Jl7SCVUI\nFjluUfsfXiL8Mmj4CspWCIbaPleG2/76019RfyjnKOcUXodo5ZwpwI0h+pdkH3g2YNjpwLwS7PdN\ngZXA+QH9fsYv1P3uJD/uQ0JMn79fNwrot4HCheQbBBwYCJq+H/Cd//oEYGXQ8C8ouhAs2J7sXwhu\nx89/fr+1QLcwcTwO/NN//SdgOtC+mG13fDHxPgOMCBq+AL8oLsF7szE/Bkr/+6Eb+38/3YF3pjd/\nfh8EDGuLf2C1BO/DiQQVgn487wFPFbE+gdu44PcJpfwtVZ5/ahoa+/o55+o659L9/6MDhq0IMX5w\nv4OBZQHdy/C+0AIvcl9ZxPIfAX4BPjCzn81sWMB8g5e1DGgSKhbn3Ha8D/TBYZabCXT3m1BsNLNN\neEeGGhUR203OuXSgPd7RzKb5A8xrGvOueRd6bwYexDvCEmhtwOsdeAkz1LoFbr/GwEbn3I6g4YHr\nHTjfncAG53+q/W4ClpW/HvnvcdeAGAKXG2o5gTFm4h3B+i1g+/0b77oxgNvwvmxm+M0fQjZxCaOo\n7XFImOUGb+tAgfuFw9sPwu0XJdnPSmtNwOuw77v/Hv8eZh5FjlvM/hdqnUJ9lktiG5AW1C8N72yl\nSFko54SnnLNPJHNOM7x9IFhJ9oFw3+8h+c0dp+L9eH89YFDwd2sa3rWNRX23rgt4vZP935fa+cv0\nm3uu9PeVl9m3rzQGVgXNN/h9KY3fnXN5Ad0F28TMjjazj/1mk5uBawLieAlvu4zz4xxpoa+7O7iY\neDOBW4M+Z00p/LksYGa3mtckeJM/bhqFP0el+f2QCTQJWvadeAcx8gXvL9X9pppleR/+jncAakjA\n+nQrYhsHKstvqXKhQjD2FdU+2JWg32q8D0O+TLyji4FfUKHm4w1wbrtzbqhz7lDgLOAWMzvJn+8h\nQaMfQuEPTrP8F2ZWG6gbNDxwuSuALD855SeoNOfc9eFiC4hxLl7SfSag97+A+XhHlQ/CaxpQ0rbW\nvwXGTuHttxqoa2a1AvoFr3d5WI3XjCFQ8HKCt98uoF7A9jvIOdcBwDm3zjl3tXOuCV4zpGes5Hdt\nK2p7FLncMAL3C8NLCuHWa3XQsqHo7b0d7+xcvsZFxBGs0Hqad/1dvTKOW9T+9xv7f3aC17GkFgFJ\nZnZoQL+OeM3SRMpCOacYyjlAZHPOCrwWEKFiLE0+KJKZHYRX7LzjnBsZNHgu3ndpvk7AWufcprIs\nK8hDeGfxjvD3lYspnB+CD3QG7veFcpyZFXXgojiv4DVHbOLH8Z/8OJxzOc65B5xzhwPH4n0WLwkx\nj+LiXQE8GPQ5q+2c2+9xT/71gLcD5/rjpeOf3Q4YrTS/H1bgNYsOXHYd51zwtcWhFLdewbEPBC4A\nznHeNaf5xhJmGwcpy2+pcqFCsPJ7FbjZzJr7ifFBYFzAEaIiE5WZnRnwI3MbXlObXOAbvItxbzez\nJDPridck5dWAyc8w7+LzangXWn/tnFsdZlHvAa3M7GJ/fsnmXWjdpoTr+T+goe27cDwVyHbO7fDn\n8ecSzgfgdeAmM2ti3oXj+Uekcc6txGsu85B5F1N3AK7AO6JXniYDLc1soJklmtkFeM0W3g01snNu\nDfAB8LiZpZqnhZmdAGBm55pZ/pfaZrwklP9ltQbvGoxwitoeRS43jCPN7Gz/6OLNeF9+4e5a9w2w\nvZj9LNAPwAnmPZ+nDl4zkJJ6A+jj77PJwP2E/3wUN25R+98koF3+NjCzIRQ+W7IfM0vBv+bB3++q\nQcGZyLeA+82sppkdB/TFO5orEg3KOco5B5pzngOGmn/jDvNuPNOM0ueDsMws1Y9/unMu1HP3xgBX\nmHezsnS8wv6FomZZisWn4u3b2f42ui1g2FdAjpnd6L8PA/CaOOabDRxuZh38vDCcst+FtTawyTm3\n18y64Z0R91bGrKeZHWHe2bFteAdz9nt8UQni/S9wrT9/zKyWeTdQqRViXqn+cn43s2pm9le/X6DS\n/H6YgbeNbzfvmcOJ5j2OqWuY8WHf+1jceu2bwKwz8CRwtnNuY9DgsNs4UBl/S5ULFYKx713bdyei\nbDN7s5TTP4/3o/AzvKYWO/Aufs1X3BdIS+AjM9uK1z76aefcZ865vXg/OM/Aawv/FDDYObc4YL5j\ngfvwmsx1Bi4Kt1zn3DbgVLw20av9v5F4F16HEjz9XrwP4r1+r6HARWaWjXcEZlxR0wd1/xfvKOFs\nvAuNg7f5IOAPfoxv4l1T8nGYOIuLPeT2979M+uCtxwb//5kBRyNDTXcJ3vaah9ckajz7mjkdBXzj\nb4938JoG5TdzuA8YY15zhHNDzLe47VHUckOZgHfkbBPePjEg4AhaqPe1qP2MoPE/wrv2Zg7e7cCD\nf8QUdSZiHnA93o+K1Xj7bcgmbCUYN+z+55z7He9mCA/763Qo3mcrJDPLxGtW9KMf/068ayzyXY93\nhHgd3hHea51zB/SgW6nSlHNCU87ZX0RyjnPuDbwDCGP96d8G6pZwHyip/ng3lfmTeXd8zL/rY1M/\nhql4zZQ/wbv2bIkfdzhFvb/B3SP8ZW/Gy1EF77e/jgPwrtHbiJcrAocvxjvwOA2vRUihO4iWQGAc\n1wEPmNkW4B683JmvEd4Bzy14Z0c/IcTBhxLE+x1wFfCUmW30Y740TGxT8a4PXYS3vXewf1Pg0vx+\nyMM7k9nJn986vM9a8OUUhSYryXoF6Yt3g5vpAfvRJH/Y9YTfxsFK+1uqXORfTBy5BZj1xrt7VwLe\nBZoPhxnvXLyjYl2dc98H9M+/+9Zw59xjEQ1WRCLKvFsnH+qcC9XERERERAKY2QvACufcX6MdSzRV\ntt8P5j3aZJFzLjmacUT0jKB/SvkpvFuzHg4MCtXswm8+ciPerVKDPYbXZEFERERERCTetcd7REVU\nRbppaDdgsXNumX+adRzebXKDPYDXTGp3YE8z64fXtEQ3PhARERGRqiayTfekwpnZzXh3BR1W3LiR\nlhTh+TehcPvelQRdbGlmnfCexTPZzG4L6F8T7+5BvSh8Ia2IxCnn3IhoxyAiIhIvnHOXRzuGWFCZ\nfj845x7He6Zg1EW6EAx1F6WCIxtmZngbItSFoyOAx/07cIWbl4iIiIiIiJRSpAvBlRR+7kZTvLte\n5UvFu3Ywyy8KGwETzawvcDRwjpk9gvfg1lwz2+mcC3xuD2amU+YiIlWIc04HBktIOVJEpOoobX6M\n9DWCM4HDzCzTvOf6DAQm5g90zmU75xo651o45/6Ad7OYs5xz3zvnTvD7t8C76+jfg4vAgPlU2b/h\nw4dHPQatu9Zf6651r6g/Kb1ov2f6rGj9te5af6175P/KIqKFoPOe7XED3kMS5+I9VHa+mY0wsz6h\nJkFNQEVERERERCIq0k1Dcc5NAVoH9RseZtyTw/SvNBeIioiIiIiIRFukm4ZKhPXs2TPaIURNVV53\nqNrrr3UXkeJU9c9KVV7/qrzuULXXvyqve1lYWduUxgozc/G+DiIiUjJmhtPNYkpMOVJEpGooS36M\neNNQEZGK0rx5c5YtWxbtMKQcZGZmsnTp0miHISJSKSg/Vh7lmR91RlBEKg3/aFi0w5ByEO691BnB\n0lGOFBFQfqxMyjM/6hpBERERERGRKkaFoIiIiIiISBWjQlBERERERKSKUSEoIhJn8vLySE1NZeXK\nleU6roiISLxTjiw5FYIiIhGWmppKWloaaWlpJCYmUrNmzYJ+r776aqnnl5CQwNatW2natGm5jltR\njj/+eMaMGRPtMEREJAYoRxZWkTlSj48QEYmwrVu3Frxu0aIFo0eP5qSTTgo7fm5uLomJiRURmoiI\nSFQpR0aPzgiKiFQg59x+t32+9957GThwIBdeeCF16tThlVde4euvv+aYY44hPT2dJk2aMGTIEHJz\ncwEvCSYkJLB8+XIABg8ezJAhQzjjjDNIS0vjuOOOK3heVGnGBXj//fdp3bo16enp3HTTTfTo0SPs\nkclvvvmGI488kjp16tC4cWOGDRtWMOyLL74oiL9Lly58/vnnANxxxx189dVXXHvttaSlpXHLLbeU\n05YVEZF4pxxZwTkyf4PH65+3CiIizsXD90Hz5s3dtGnTCvW75557XEpKips0aZJzzrldu3a5b7/9\n1s2YMcPl5eW5JUuWuNatW7unn37aOedcTk6OS0hIcMuWLXPOOXfxxRe7Bg0auO+//97l5OS4Cy64\nwA0ePLjU465du9alpqa6d9991+Xk5LjHHnvMVatWzf3vf/8LuS5HHXWUGzdunHPOuW3btrkZM2Y4\n55xbsWKFq1evnvvwww+dc85NnTrV1a9f323cuNE551yPHj3cmDFjitxO4d5Lv3/Uc0+8/MXDZ0JE\nIi9evguUI4vPkeWZH3VGUESqDLPy+YuEHj16cMYZZwCQkpLCkUceyVFHHYWZ0bx5c6666io+/fTT\ngvG97/x9zj33XDp37kxiYiIXXXQRP/zwQ6nHnTRpEp07d6ZPnz4kJiZy8803U69evbAxV6tWjcWL\nF7Nx40Zq1arFUUcdBcCYMWPo168fp5xyCgCnnnoqHTt2ZMqUKWFjEhGR6IrV/AjKkZGiQlBEqgzn\nyucvEpo1a1aoe+HChfTp04fGjRtTp04dhg8fzoYNG8JO36hRo4LXNWvWZNu2baUed/Xq1fvFUdQF\n9C+88AJz586ldevWdO/enffffx+AZcuWMXbsWOrWrUvdunVJT0/nm2++4bfffgs7LxERia5YzY+g\nHBkpKgRFRGKABR1Kveaaa2jfvj2//vorW7ZsYcSIERE/Qti4cWNWrFhRqN+qVavCjt+yZUteffVV\n1q9fzy233MI555zDnj17aNasGZdffjkbN25k48aNbNq0ia1btxZc6xC8riIiIkVRjowMFYIiIjFo\n69at1KlThxo1ajB//nz+85//RHyZffr0YdasWUyaNInc3FxGjRpV5BHWl19+md9//x2AtLQ0EhIS\nSEhIYPDgwbz99tt89NFH5OXlsWvXLrKyslizZg0AGRkZ/PrrrxFfHxERqZyUI8uHCkERkQpU0iN9\n//znP3nxxRdJS0vjz3/+MwMHDgw7n+LmWdJxGzZsyGuvvcbNN99M/fr1WbJkCZ07dyYlJSXk+JMn\nT6Zt27bUqVOH22+/nddff52kpCQyMzN5++23eeCBB2jQoAHNmzfnscceIy8vD4C//OUvBc1ihg4d\nWuy2EBGRqkE5smJzpMX7Bftm5uJ9HUSkfJiZbkJSjvLy8jj44IN58803Oe644yp02eHeS7+/2paW\nkHKkiIDyYyREK0eWZ37UGUERESkwdepUsrOz2b17N/fffz/Jycl069Yt2mFJBdibu5crJ17Jjr07\noh2KiEhMqmw5UoWgiIgUmD59Oi1atKBhw4Z88MEHTJgwgeTk5GiHVaWY2WgzW2tmc4oY50kzW2xm\nP5hZp/JYbnJiMpt3beaJr58oj9mJiFQ6lS1HqmmoiFQaavpSeVTlpqFm1gPYBoxxznUIMfx04Abn\n3JlmdjTwhHOue5h5lSpHLvp9EceOPpYFNyygfs36ZVwDEYk1yo+Vh5qGioiIVFLOuenApiJG6QeM\n8cf9BqhjZhkHvlzYurQVFxx+AQ9+9uCBzk5ERGKcCkEREZH40gQIfJjVKr/fAcnJgXPPhV4pf2XM\nnDEs2bTkQGcpIiIxTIWgiIhIfAnV9OeA23wlJ8Pf/gYP35vBjd1u4p5P7jnQWYqISAxLinYAIiIi\nUiorgWYB3U2B1eFGvu+++wpe9+zZk549e4ad8aBB8Oij0GrDrTy7rBXf//Y9XRp3OeCARUSkfGVl\nZZGVlXVA89DNYkSk0tDF8JVHVb5ZDICZNQfedc61DzHsDOB6/2Yx3YFR5XWzGICpU2HIELjhf//i\nnYVv8uHgD0v8kGcRiU3Kj5VHXN0sxsx6m9kCM1tkZsOKGO9cM8szsy5+9ylm9q2ZzTazmWZ2UqRj\nFRERiTYzGwt8CbQys+Vm9iczu8bMrgZwzk0GlpjZz8B/gOvKc/mnngpNmkDi7CtZkb2CD375oDxn\nLyIiMSKihaCZJQBPAacBhwODzKxNiPFqAzcCXwf0Xg/0cc51BC4DXiqPmD5d+imfLPmkPGYlIlIi\nqamppKWlkZaWRmJiIjVr1izo9+qrr5Z5vscccwxjx44tx0g9//nPf+jVq1e5z1dKxjl3oXPuYOdc\ninPuEOfcC865/zjnng0Y5wbn3GHOuY7Oue/Lc/lmMHIk/G1EMvf1eIhhHw0jz+WV5yJERAooR0ZP\npM8IdgMWO+eWOef2AuPwbnsd7AHgYWB3fg/n3Gzn3Br/9VwgxcwO+ImNy7Ys48kZTx7obERESmzr\n1q1kZ2eTnZ1NZmYmkyZNKug3aNCgaIcXkpoCVm1HHQU9esCSyf2pmVyTV+a8Eu2QRKSSUo6MnkgX\ngsG3uF5J0C2uzawT0NRv6hKSmZ0LzPKLyQPSp1Ufpv06jR17dxzorERESs05t1/b/ry8PB544AEO\nPfRQGjZsyODBg8nOzgZgx44dDBo0iHr16pGens4xxxzDli1bGDp0KDNnzuTKK68kLS2N2267bb9l\nhZsWYNOmTVx66aU0btyYzMxM7r//fgB++OEH/vKXv5CVlUVqaioHH3xwhLeIxKq//Q0ee8y4u9sj\n3PvJvezK2RXtkESkklOOrFiRLgSLvMW1eeX048Ct4aYxs8OBh4CryyOgujXqclSTo3TNg4jEjEce\neYSPPvqIL7/8kpUrV5KcnMzNN98MwHPPPUdubi6//fYbv//+O0899RTVqlXjH//4B0cddRSjR48m\nOzubRx99dL/5hpsW4KKLLiI9PZ2lS5cyY8YMJkyYwEsvvUSnTp0YNWoUPXv2ZOvWraxeHfZmlFLJ\ntWwJF1wAH7/Yg46NOvL0jKejHZKIVEHKkZET6cdHrAQOCegOvsV1Kt61g1l+UdgImGBmfZ1z35tZ\nU+AtYLBzbmm4hZTm1tgA/dv05+0Fb3N2m7NLtTIiEt9sRPk05XDDy/fOa88++yyvvPIKGRkZANx7\n770cccQRjB49muTkZNavX8/ixYs5/PDDOfLIIwvHUsRd4MJNu3z5cj7//HPeffddEhMTycjI4MYb\nb+TVV19l8ODB5bpuB6o8bo8tZXfvvXD44fDaJQ9x4Qc9ubzz5aTXSI92WCISAeWRI8s7P4JyZCRF\nuhCcCRxmZpnAb8BAoKCxr3MuG2iY321mnwC3OOdmmdlBwHvAHc65rylCYCFYEv1a92N41nBy8nJI\nStCjFEWqikgkqPKwYsUKzjjjjIJrDvIT18aNG7niiitYs2YN5557Ltu3b2fw4MH87W9/K9H1CVde\neSVr164tmPaSSy7hgQceYNmyZezcuZMGDRoULM85R8uWLSO3kmUUfHBvxIgR0QumCmrUCK6/Hl56\nrB39zunHyOkjebjXw9EOS0QiQDky/nLkgYpo01DnXC5wA/ABMBcY55ybb2YjzKxPqEnY1zT0euBQ\n4F4zm2Vm35tZ/fKIq1mdZrRIb8Fnyz4rj9mJiByQpk2b8vHHH7Nx40Y2btzIpk2b2L59O3Xr1qVa\ntWqMGDGC+fPn89lnnzF+/HjGjRsHFH+xenJyMvfdd1/BtK+//jrjxo2jWbNmpKamFlre5s2bmTlz\nZonmK1XL0KEwZQpckDGC52Y9x/Ity6MdkohUIcqRkRPx5wg656Y451o751o650b6/YY7594LMe7J\n+bfBds496JxLdc51cc519v9vKK+4zm59Nu8seKe8ZiciUmbXXHMNw4YNY+XKlQCsW7eO997zviKn\nTZvG/Pnzcc5Ru3ZtkpKSSEryWjJkZGTw66+/hp1vuGmbN29O9+7duf3229m2bRvOOX7++We++OKL\ngvmuWLGCnJycCK+5xIO0NLj7bnj8/oP5c9c/89dP/hrtkESkClGOjJyIF4Kxqn/b/ryz4J0i2w6L\niJS3UEcShw0bRq9evTj55JOpU6cOPXr0YNasWQCsWrWKfv36kZaWRocOHejTpw/nnXceADfffDP/\n+9//qFevHnfcccd+8y1q2ldffZXNmzfTpk0b6tWrx8CBA1m3bh0AvXv3pnnz5jRs2JBDDjlkv/lK\n1XPNNTB/PhyTdzvv//w+c9bOiXZIIlIJKUdWLIv3QsjMXFnWwTlHm6fbMHbAWI48+MjiJxCRmGdm\nOrhTSYQYLPXVAAAgAElEQVR7L/3+laddToSVNUeGMnYsPPEEXPjEk0z9ZQqTLwr71CcRiTHKj5VH\neebHKntG0Mw4u/XZvL3g7WiHIiIiEvMGDoQ9eyBjxbUs/H0hnyz5JNohiYjIAaiyhSB4zUNVCIqI\niBQvIQEefhiG31ONESc8yO0f3U6ey4t2WCIiUkZVuhDs1qQbm3ZuYtHvi6IdioiISMzr1QuaNYOt\nX5+Pc47xc8dHOyQRESmjKl0IJlgC/Vr3091DRURESsAMRo6EB+5P4P7jH+Xuj+9mT+6eaIclIiJl\nUKULQYCz2+gxEiIiIiXVtSuccALMeuskWtVrxb+//Xe0QxIRkTKosncNzbcndw8Z/8hg3nXzaJza\nuBwjE5GKpruiVR66a2j5KM+7hgb6+Wfo3h1e/XQm104byM83/lypHrIsUtkoP1Ye5Zkfk8otqjhV\nLbEapx92OhMXTuSartdEOxwROQCZmZn6MVpJZGZmRjsEKcJhh3l3EZ08uivW3Ji1ZhZdGneJdlgi\nEobyY+VRnvmxyp8RBBg/dzyjZ41mysVTyikqERGJBJ0RLJ1InREEWLsW2rWDC569k7Q6jpGnjIzI\nckREpHh6jmAZ9T6sN1+u+JItu7ZEOxQREZG4kJEBN9wAKz84j/HzxqvZmYhInFEhCKSmpHJC5glM\nXjw52qGIiIjEjRtugE9f6wzOax4qIiLxQ4Wg7+w2Z/POQt09VEREpKQaNIDOnYzOKefpmYIiInFG\nhaCvb+u+TP15KrtydkU7FBERkbgxYADsmXUer897Xc1DRUTiiApBX8NaDWmf0Z5pv06LdigiIiJx\no39/+OLNzuBQ81ARkTiiQjBA/zb99XB5ERGRUmjWDA5tYXSrfb6ah4qIxBEVggHObnM2ExdNJDcv\nN9qhiIiIxI1zzoHcObp7qIhIPFEhGKBFegsa1W7EVyu/inYoIiIicaN/f/h8fGccTs1DRUTihArB\nIP3b9Oft+W9HOwwREZG40aoV1K9nHFtHdw8VEYkXKgSD5D9GQk1bRERESm7AAGDu+WoeKiISJ1QI\nBumY0ZE8l8eP636MdigiIiJxY8AAmP6G1zz0hzU/RDscEREphgrBIGbG2a3P1t1DRURESqFDB0gw\n44R63k1jREQktqkQDKF/2/68vUDXCYqIiJSUmXdWMGnhebw+Vw+XFxGJdSoEQziu2XGsyl7Fkk1L\noh2KiIhI3BgwAL58qwt5Lk/NQ0VEYpwKwRASExI5q9VZTFg4IdqhiIiIxI2jj4bNm4xTGp+v5qEi\nIjFOhWAYZ7c5W81DRURESiEhwXumYMrPeri8iEisi3ghaGa9zWyBmS0ys2FFjHeumeWZWZeAfnea\n2WIzm29mp0Y61kCntDiFH9b8wPrt6ytysSIiInFtwAD46u0u5OblqnmoiEgMi2ghaGYJwFPAacDh\nwCAzaxNivNrAjcDXAf3aAucDbYHTgWfMzCIZb6AayTXo1aIX7y56t6IWKSIiEvdOOAGWLjFOa6q7\nh4qIxLJInxHsBix2zi1zzu0FxgH9Qoz3APAwsDugXz9gnHMuxzm3FFjsz6/C9G/TX4+REBERKYWk\nJOjbF2ot1cPlRURiWaQLwSbAioDulX6/AmbWCWjqnJtczLSrgqeNtDNankHW0iy27dlWkYsVERGJ\nawMGwIyJXvPQ2WtnRzscEREJIdKFYKimnAWHBv2mno8Dt5Z22oqQXiOd7k27M/XnqRW5WBERkbh2\nyikwZ7ZxRnPvmYIiIhJ7kiI8/5XAIQHdTYHVAd2peNcOZvlFYSNgopn1LcG0Be67776C1z179qRn\nz57lELon/+6h57Q7p9zmKSIiJZOVlUVWVla0w5BSql4dTj8d6qw8j9fzBvHgyQ9SgZf5i4hICVgk\n2+6bWSKwEPgj8BswAxjknJsfZvxPgFucc7PMrB3wCnA0XpPQD4GWLihgMwvuVa5WZa+i/b/as3bo\nWpITkyO2HBERKZ6Z4ZxTRVFCkc6RRRk/HkY/71jYuwVvX/A2nRp1ikocIiJVQVnyY0SbhjrncoEb\ngA+AuXg3f5lvZiPMrE+oSfCbhDrn5gGvA/OAycB10chmTdKa0PXgrtw57U5d8C4iIlJCp58OX35h\n9D30fMbP1d1DRURiTUTPCFaEijjauXHnRk588UQGHTGIu46/K6LLEhGR8HRGsHSieUYQoF8/OPKs\nb3lp5yAW3bBIzUNFRCIk5s4IVhZ1a9Tlg4s/4PlZz/P0jKejHY6IiEhcGDAAZk0+kpy8HN09VEQk\nxqgQLKHGqY35cPCHjPxiJC/PeTna4YiIiMS8s86Cj6cZZ7c8T81DRURijArBUvhD+h+YevFUhn4w\nlAkLJkQ7HBERkZhWty506waNN+rh8iIisUaFYCm1a9CO9y58j6vevYppv06LdjgiIiIxbcAAmD3l\nSPbm7VXzUBGRGKJCsAy6HtyV8eeNZ+CbA/lm5TfRDkdERCRmnX02vD/ZGNBazUNFRGKJCsEyOrH5\nibzY70X6juvLj2t/jHY4IiJSiZhZbzNbYGaLzGxYiOHNzOxjM/vezH4ws9OjEWdJNG4M7drBIdvO\nU/NQEZEYokLwAJzZ6kxGnTaK0185nV82/hLtcEREpBIwswTgKeA04HBgkJm1CRrtHuA151wXYBDw\nTMVGWToDBsCPU7uyN28vc9bOiXY4IiKCCsEDNqj9IO494V56vdSLVdmroh2OiIjEv27AYufcMufc\nXmAc0C9onDwgzX99EBDTCah/f5g4wTinrXdWUEREok+FYDm4pus1XHPkNfR6qRcbdmyIdjgiIhLf\nmgArArpX+v0CjQAGm9kK4D3gxgqKrUz+8Ado2hRa7j6P1+e+ruahIiIxICnaAVQWw3oMY/OuzfR+\nuTcfX/oxaSlpxU8kIiKyPwvRL7hyGgS84Jx73My6Ay/jNSPdz3333VfwumfPnvTs2bN8oiylAQNg\n7kdd2dvCax7asVHHqMQhIlIZZGVlkZWVdUDzsHg/KmdmLlbWwTnHdZOuY96GeUy5aAo1kmtEOyQR\nkUrFzHDOhSqUKg2/sLvPOdfb774DcM65hwPG+Qk4zTm3yu/+BTjaObchaF4xkyPnzYPTToNLXryH\nTbs28syZMX1Zo4hIXClLflTT0HJkZjx95tM0TWtKn1f78NO6n6IdkoiIxJ+ZwGFmlmlm1YCBwMSg\ncZYBpwCYWVsgJbgIjDXt2kHt2nBiyhDG/TSOldkrox2SiEiVpjOCEbA3dy///OqfjPp6FN2bdufO\nHndydNOjox2WiEjcqwpnBMF7fATwBN4B29HOuZFmNgKY6Zx7zy/+/gvUxrtxzG3OuWkh5hNTOfLu\nuyEvD3JOuo2dOTt56oynoh2SiEilUJb8qEIwgnbs3cHzs57n0S8f5bC6h3Fnjzv54x/+iFml/w0j\nIhIRVaUQLC+xliO/+w4GDYLPv19H26fb8OOff6RJWvB9cEREpLRUCMaovbl7GfvjWEZ+MZLa1Wpz\nV4+76NemHwmmlrkiIqWhQrB0Yi1HOgfNm8OkSfDi6qHsyd3Dk6c/Ge2wRETingrBGJfn8piwYAJ/\nn/53tu/Zzh097mDQEYNITkwudtq9uXtZ+PtCZq+ZzZy1c5i9djbz1s+jXYN29G3dl7NanUWzOs0q\nYC1ERKJHhWDpxGKOvO02ryC87b61tH26LT9d9xMHpx4c7bBEROKaCsE44Zxj2pJpPDT9IX7Z+Au3\nHXsbl3e+vOAuo+u3r2f22n0F35y1c1i4YSHN6jSjY0ZHOmR0oENGB9rWb8vstbOZuHAikxZPovlB\nzenbqi99W/elU6NOaoIqIpWOCsHSicUcuXw5dOoEv/wCD8y4hdy8XJ44/YlohyUiEtdUCMahb1Z+\nw0PTH+LrlV/TsVFH5qydw66cXXTI6FCo6Dui4RHUTK4Zdj45eTl8sfwLJi6cyISFE9iTu4e+rb2i\n8MTME0lJSqnAtRIRiQwVgqUTqznyssugZUu4Ysga2j3djrnXzaVxauNohyUiErdUCMaxuevmsmTz\nEjpkdKBZWrMDOpvnnGPBhgVMWDiBiQsnMm/9PE499FT6tu7LGS3PoG6NuuUYuYhIxVEhWDqxmiPn\nzYOTToIlS+Duz24G4PHej0c5KhGR+KVCUEJau20tkxZPYuLCiXy27DOu7Xotd/S4g7SUtGiHJiJS\nKioESyeWc2T//vDHP8I5l/7G4c8czrzr59GodqNohyUiEpdUCEqxVmav5N5P7uX9xe8z/MThXHXk\nVSQlJEU7LBGRElEhWDqxnCO//hoGDoTFi2HoR0NITEjksdMei3ZYIiJxSYWglNis32Yx9MOhrN66\nmkd7PcqZLc/UzWVEJOapECydWM+RJ50EV1wBJ/dbzRHPHMH86+eTUTsj2mGJiMQdFYJSKs45Ji+e\nzG0f3kbj1Mb889R/0qlRp2iHJSISlgrB0on1HDl1Ktx6K8yZA0Om3EhKUgr/OPUf0Q5LRCTulCU/\n6onmVZiZcWarM5nz5zmc1+48Tn/ldC575zJWZq+MdmgRsWbbGtZvXx/tMERExHfqqVCtGkyeDMN6\nDOP5Wc+zbvu6aIclIlIl6IygFMjenc3D0x/m39/9m+u6Xsftx91OakpqtMM6IDl5OUxePJlnv3uW\nL1d8icORkphCh4wOtG/YnvYZ7QueyZj/HEcRiV06I1g68ZAjX38dnnwSpk+HGybfQM3kmjzS65Fo\nhyUiElfUNFTKxfIty7nn43v46NePGNFzBH/q/KdyuaFMnstjb+5e9uTuYW+e939P7h725u4lwRLI\nPCiTBCufk9TLNi9j9KzRjJ41muYHNefqLldz3uHnUSOpBiuzV/Ljuh/5ce2PzFk3hx/X/sjijYvJ\nrJO5X4HY/KDm5RaTiBw4FYKlEw85MjcXWreGF1+E5h1W0uFfHVhwwwIa1moY7dBEROJGTBaCZtYb\nGIXXDHW0c+7hoOHXANcDucBW4Grn3AIzSwKeA7oAicBLzrmRIeYf80kuXn23+juGfjiUT5d+SmJC\nIomWSIIlkGAJJCbse51gCfsNy8nLKSj68v9yXS7VEquRnJBMtcRq3utE7/XunN3sytnFcYccx/GH\nHM/xhxxPl8ZdSE5MLnG8e3P3MmnxJJ797llmrJrBRe0v4qojr+KIhkcUO+2e3D0s3LBwvwLx952/\nk1Ergwa1GtCgZgMa1mpIg5oNCnf7rxvUakDN5JoHsslFpBgqBEsnXnLks8/ChAkwaRJcN+k6Uqul\n8nCvh4ufUEREgBgsBM0sAVgE/BFYDcwEBjrnFgSMU9s5t81/fRZwnXPudDMbBJzlnLvQzGoA84AT\nnXPLg5YRF0kunuXk5ZDn8gr+cvNy9712uSGHJSYkFhR7+cVfUkJSkXcmXZW9is+Xf87nyz7n8+Wf\ns2TzEro16VZQGHZv2p1a1WrtN93SzUt57vvneH7W8xxa91Cu7nI157Y7t1yaem7dvZV129exfsd6\n7//29azfsZ7129ezbse+7vxhSQlJZNTOoElqE5qkNaFpalOapDWhSWoTmqZ5rxvXblyqAlcqVm5e\nLmu2rWHd9nUkJiSSnJBMcmJykf91x93Ic86xZfcW0mukqxAshXjJkbt2QYsWMGUKHJS5nE7/7sSi\nGxdRv2b9aIcmIhIXYrEQ7A4Md86d7nffAbjgs4IB4w8CLnbOnWlmA4FBwADgIOALoLtzbnPQNHGR\n5KT0Nu3cxJcrvvSKw+WfM3vNbA5veHhBYZiTl8N/v/8v367+lsEdBnPVkVfRrkG7qMXrnGPbnm2s\n2baGVVtXsSp7FSuzV3qvt/qvs1exdvta6tesX6hYzKidUehMY/2a9WlQqwH1atQjMSGx1HHs2LuD\nTbs2sWnnpoL/uS6XZmnNyDwokwY1G1TZ4mVXzi6Wb1nOss3LvP9blrFsy7KCfqu2rqJujbpk1Mog\n1+WyN3cve/P2hv2fk5dDoiWSnJhM9aTq1EquRa1qtUL/D9GvWmI1khKSSEpIIjnRO2CSf+AksF9+\nf4Cte7ayZdcWtuzeQvbubLbs8v/vDt1vT+4eEi2RxIREkhKSCl4nmt8d9DopIYmayTVJS0kjtVpq\n4f8pobtrJdcqaClgmPffrFB3cL9dObsKHWjJ/8s/0BLYvX7HelISU9h611YVgqUQTznykUdg9mx4\n5RW49r1rSa+ezkOnPBTtsERE4kIsFoLnAKc55672uy8Gujnnbgoa7zrgFiAZONk594vfNPQlvLOJ\nNYCbnXPPhVhG3CQ5OTA79+5kxqoZBYVhTl4Ol3e6nHPanUP1pOrRDq/EcvJyWLtt7X7FYf6P3Q07\nNhScddy8azMHVT+ocIFYswHpNdLZvme7V+QFFHwbd25k085NJCYkkl49nbo16pJeI5306ukkWEJB\n4bNz704OqXMImQdlklnH/zto3/+DUw8udF1ofnG5ZfcWNu/azOZdm9myy3sd2C97d3ahM8jBZ4zD\n/TnnvP84nHM4XEH/4Nf5n/eSFBr5/RyO37b+xrIty9iyawtN05oWWv9D6hxSsO5N05qWan9yzpGT\nl8Oe3D3sytnF9r3b2bF3B9v3bGf73u3F/g8sKHPycgq/zt2/v3OOtJQ00lLSqFO9DmnV/P8padRJ\nqVPodf441RKrkZuXS67LJTcvl5y8nJCvc11uwfJ27N1B9u5stu7e6v3fs3Vf9579+2/fs73wexrw\nvgV2B/arnlSdhrUaFjSxblirIQ1rBrz2m2LnD6+eVF1NQ0spnnJkdrZ3VnDGDEisu4wuz3Zh0Q2L\nqFezXrRDExGJebFYCJ4LnBpUCB7lnBsSZvyBQG/n3GVmdizwZ+BSoB7wuT9sadA0bvjw4QXdPXv2\npGfPnhFYG5GKl5OXw8adG73iMKBZ6qZdm6hdrTbp1dMLCr3A/8UVMtv2bGPZZu9MWMH/gNfrt68v\nKAbzC72khCQOqn4QB1U/iDopdUK+TktJIzkxOez1o6H+Ags3Myt0Nin4df5/oESFRn4/gEa1G3FI\nnUNoVLuRbgAUR7KyssjKyiroHjFihArBUoinQhDg7rth82Z4+mm45t1rqF+zPg/+8cFohyUiEvNi\nsRDsDtznnOvtdxfXNNSAjc65dDN7CvjKOfeKP2w08L5z7o2gaeIqyYnEgz25e1ixZQW5Lreg2EtJ\nSol2WCI6I1hK8ZYj166Ftm1h/nzYmbKUI589UmcFRURKIBYfKD8TOMzMMs2sGjAQmBg4gpkdFtDZ\nB1jsv14OnOyPUwvoDixARCKuWmI1Dq17KK3qtaJhrYYqAkWkQmRkwKBB8MQT0Pyg5gxoM4DHv348\n2mGJiFRKFfX4iCfY9/iIkWY2ApjpnHvPzEYBpwB7gE3ADc65+X7x9wKQf/eP551zj4WYf1wd7RQR\nkbLTGcHSicccuWQJHHUU/PILbMxbQtf/dmXxjYupW6NutEMTEYlZMdc0tCLEY5ITEZGyUSFYOvGa\nIy+6CDp2hNtvhysmXEGTtCbcf9L90Q5LRCRmqRAUEZFKTYVg6cRrjvzxRzjtNPj1V1i981e6/bcb\nC29YqGsFRUTCiMVrBEVERERKpX176NIFxoyBFuktGHjEQIZnDS9+QhERKTGdERQRkbihM4KlE885\ncvp0uOwyWLgQNu/+nbZPt2XaJdNon9E+2qGJiMQcnREUERGRSqFHD2jUCN54A+rVrMdfT/wrf5n6\nF+K1sBURiTUqBEVERCQm3XEHjBwJzsG1Xa9l7ba1TFg4IdphiYhUCioERUREJCadeSbk5MAHH0BS\nQhKjeo/i1g9uZVfOrmiHJiIS91QIioiISEwy23dWEOCUFqfQvmF7Rn09KrqBiYhUArpZjIiIxA3d\nLKZ0KkOOzMmBVq3g5Zfh2GPh540/0/257sz58xwOTj042uGJiMQE3SxGREREKpWkJLjzThgxwus+\nrO5hXNnlSu6adld0AxMRiXMqBEVERCSmXXqp9xiJr77yuu8+/m4++OUDZqyaEd3ARETimApBERER\niWnVqsFdd+07K5iaksrf//h3bnr/JvJcXnSDExGJUyoERUREJOZddhnMnw/ffON1X9LxEnJdLmN/\nHBvVuERE4pUKQREREYl51aoVvlYwwRJ4sveT3PHRHWzbsy26wYmIxCEVgiIiIhIX/vQn+OknmOFf\nGnhMs2Po2bwnI6ePjG5gIiJxSI+PEBGRuKHHR5ROZcyRzzwDkyZ5fwArs1fS8d8d+faqb/lD+h+i\nG5yISJTo8REiIiJSqV1xBcyZAzNnet1N05pyc/ebue3D26IbmIhInFEhKCIiInEjJQXuuAPuv39f\nv1uPuZVvV39L1tKsqMUlIhJvVAiKiIhIXLniCpg1C777zuuukVyDf5z6D4ZMGUJuXm50gxMRiRMq\nBEVERCSuVK8Ow4YVPit4TttzSK+eznPfPxe9wERE4ohuFiMiInFDN4spncqcI3ftgkMPhXffhS5d\nvH4/rPmB3i/3Zv7180mvkR7dAEVEKlBEbhZjZolm9o+yhyUiIlK1KHdGXvXqcPvthc8KdmrUibPb\nnM39n94ffkIREQFKeEbQzL52znWvgHhKrTIf7RQRkcLi6YxgLOTOyp4jd+70zgpOngydOnn91m9f\nT7tn2vHZZZ/RtkHb6AYoIlJBypIfS1oI/gtoAowHtuf3d869Vdogy1tlT3IiIrJPnBWCUc+dVSFH\njhoFn30GbwVs1VFfj2LCwgl8OPhDkhKSoheciEgFiWQh+EKI3s45d3lpFhYJVSHJiYiIJ84Kwajn\nzqqQI3fuhBYtYMoU6NjR65eTl0OfsX1oVa8VT57+ZHQDFBGpABErBGNZVUhyIiLiiadCMBZUlRz5\n2GPwxRfw5pv7+m3ZtYVjRh/D9Uddz/Xdro9ecCIiFSAiN4vxZ9zUzN42s3VmttbM3jSzpmULU0RE\npPJT7qw4114LX34Jc+bs61eneh3eu/A9HvjsAab+PDV6wYmIxKiSPkfwBWAicDDe9Q7v+v2KZWa9\nzWyBmS0ys2Ehhl9jZnPMbJaZfWZmbQKGdTCzL83sJzObbWbVShiviIhItEUsd/rjnG9mc83sRzN7\nudyijkM1a8LQofDAA4X7t0hvwRvnv8Hgtwczb/286AQnIhKjSnqN4A/OuU7F9QsxXQKwCPgjsBqY\nCQx0zi0IGKe2c26b//os4Drn3Olmlgh8D1zknPvJzNKBzcFtXKpKsxcREYmvpqERzp2HAa8BJznn\nss2svnNuQ4h5VZkcuX27dwfRjz6CI44oPGzM7DGM+HQEX1/xNQ1qNYhOgCIiERSxpqHABjO72H8u\nUqKZXQz8XoLpugGLnXPLnHN7gXFAv8AR8otAX20gz399KjDbOfeTP96mKpPNRESkMohY7gSuAp52\nzmUDhCoCq5pateDWWws/VzDfJR0v4YLDL2DA6wPYnbO74oMTEYlBJS0ELwfOB9YAvwHn+v2K0wRY\nEdC90u9XiJldZ2Y/AyOBm/zerfxhU8zsWzO7rYSxioiIxIJI5s5WQGszm+5fQnFaOcQb9667Dj79\nFObO3X/Y307+Gw1rNeTq965Gx5VFRKDYh+v4TTTPcc71LcP8Q52e3O/b1zn3DPCMmQ0E7gUu82M7\nDugK7AKmmdm3zrlPgqe/7777Cl737NmTnj17liFUERGJNVlZWWRlZUU7jFKrgNyZBBwGnAAcAnxu\nZofnnyEMVJVyZK1acMst3rWC48YVHpZgCYw5ewwnvHgCD3/xMHf0uCM6QYqIlIPyyI8lvUZwhnOu\nW6lnbtYduM8519vvvgPvGUoPhxnfgE3OuYPM7ALgtPznLZnZPcBO59w/g6ZRi1ERkSoizq4RjFju\n9B9W/5Vzbozf/REwzDn3XdC8qlyO3LbNe65gVha0a7f/8FXZq+g+ujtP9H6CAW0HVHh8IiKREMlr\nBL8ws6fM7Hgz65L/V4LpZgKHmVmmf8fPgXh3UAsM+rCAzj54F8gDTAU6mFl1M0sCTgR0yy8REYkX\nEcudwDvAyQBmVh9oCfxansHHq9q1vbOC994LoWrgJmlNeOeCd7jmvWv4bvV3+48gIlJFlPSM4H7N\nMfGOTp5cgml7A0/gFZ2jnXMjzWwEMNM5956ZjQJOAfYAm4AbnHPz/WkvBO7Cu4HMJOfcnSHmX+WO\ndoqIVFVxdkYwYrnTH+efQG8gB/ibc258iPlUyRy5fTsceyxcfjkMGRJ6nLfmv8WQKUP4+oqvaZK2\n3+0LRETiSlnyY7GFoH8b63Odc68fSHCRUlWTnIhIVRQvhWCs5M6qnCOXLoVjjoExY6BXr9DjjJw+\nkvHzxvPZZZ9Rq1qtCo1PRKQ8RaQQ9Gf8rXOua5kji6CqnORERKqaeCkEITZyZ1XPkZ99BuedB9On\nQ8uW+w93znHZhMvYunsrb5z/BglW0itmRERiSySvEfzIzIaaWTMzq5v/V4YYRUREqgrlzig74QTv\nuYL9+sGWLfsPNzOe7fMs63es5+5pd1d8gCIiUVTSM4JLQvR2zrkW5R9S6VT1o50iIlVJnJ0RjHru\nVI70XH89LFsGEyZAYuL+wzfs2MDRzx3NPcffw586/6niAxQROUARaxoay5TkRESqjngqBGOBcqRn\n71449VTo3h0eeij0OAs2LKDniz15od8LnN7y9IoNUETkAJV701Azuz3g9XlBw/5euvBEREQqP+XO\n2JOcDOPHw2uvwdixocdpU78Nb13wFpe8cwkzV82s2ABFRKKguGsEBwa8Dn50Q+9yjkVERKQyUO6M\nQfXre01DhwyBb78NPc6xzY5ldN/R9B3Xl583/lyxAYqIVLDiCkEL8zpUt4iIiCh3xqz27eHZZ6F/\nf/jtt9Dj9G3dlxE9R9D75d6s3ba2YgMUEalAxRWCLszrUN0iIiKi3BnT+veHq6/2/u/aFXqcq4+8\nmovaX8SZY89k255tFRugiEgFKfJmMWaWC2zHO4JZA9iRPwio7pxLjniExdCF8CIiVUc83CwmlnKn\nchzyjssAACAASURBVGRozsH550OtWvDCC2Ah9ijnHFe/ezUrslfw7qB3SU6M+k8eEZGwdNdQERGp\n1OKhEIwlypHhbd8Oxx0Hl14KN98cepycvBz6v9afujXq8mK/F7FQFaOISAyI5APlRURERCqNWrW8\nm8c88ghMnRp6nKSEJMadM46FGxZy17S7KjZAEZEIUyEoIiIiVVJmJrz+OgweDIsWhR6nVrVavHfh\ne7y14C2emvFUxQYoIhJBKgRFRESkyjr+eHjwQejbF7ZsCT1O/Zr1mXLRFB6a/hBvzHujYgMUEYkQ\nXSMoIiJxQ9cIlo5yZMndcAMsXQoTJ0JCmMPks36bxWkvn8Yb57/BCZknVGh8IiJF0TWCIiIiImXw\n+OOQnQ0jRoQfp3Pjzow9ZyznjT+Pn9b9VHHBiYhEgApBERERqfKSk73rBZ9/3jsrGM4pLU5h1Gmj\nOOOVM1ixZUXFBSgiUs5UCIqIiIgAjRrB+PFw5ZWwcGH48Qa1H8SQo4fQ+5XebN29teICFBEpR7pG\nUERE4oauESwd5ciy+e9/vaai33wDqanhx7vk7UvIqJXBo6c+WnHBiYiEoAfKi4hIpaZCsHSUI8vu\n6qvh99/hjTcg3HPk125byxH/OoJPL/uUdg3aVWyAIiIBdLMYERERkXLwf/8Hq1bByJHhx8moncHw\nE4dzw+QbUMEtIvFGhaCIiIhIkJQUePNNryCcMiX8eNd2vZaNOzfy2tzXKi44EZFyoEJQREREJIQm\nTeC11+DSS+GXX0KPk5SQxNNnPM3QD4bqxjEiEldUCIqIyP+3d+dxUlTn/sc/z8zADIsgUbYrgiIa\nN9xAJWBgTNSgoCYkRlETjTEuaNSY3XsR0HgjxkS9ySUmEZMYF4yCuP+EqKPXBUHZERTEBRRwCSgI\nDLM8vz9ONdPT9MA0dE/3TH3fr1e9qurU0k91Q595us45JSIN+PKXYfRo+MY34PPP0+8zqOcgTuh9\nAtc9d13TBicisgs0WIyIiDQbGiwmM6ojs8Mdzj8ftmyBe+9NP3hMYuCYivMqOKTLIU0eo4jEmwaL\nEREREckyM7j9dnjzzfBYiXS2DhzzpAaOEZHmQYmgiIiIyA60aQNTpsBNN8Ezz6Tf55L+l7B201oN\nHCMizULOE0EzG2pmS8zsTTP7eZrtF5vZfDObY2bPm9mBKdt7mtl6M7s617GKiIiINKRXr9A09Oyz\n4d13t92ugWNEpDnJaR9BMysC3gS+CnwAzALOcvclSfu0d/cN0fKpwCh3Pzlp+4NADfCKu/8uzWuo\n/4OISEyoj2BmVEfmxm9/GxLCF14IdwpTfe/h77FHmz24+aSbmz44EYmlQuwjeAyw1N3fdfcqYBJw\nevIOiSQw0h6oTayY2enAW8CiHMcpIiIi0ihXXw0HHACXXhoGkkk1/oTx/H3e31n0of58EZHCletE\ncC9gRdL6yqisHjMbZWbLgBuBK6KytsDPgHGAfv0VERGRgmAGd9wBM2bAE09su71Luy4aOEZECl5J\njs+fLoHb5hvR3ScAE8zsLGA0cD4hAbzF3TdaGKe5wWRw7NixW5fLy8spLy/flZhFRKRAVFRUUFFR\nke8wRLbRrh386lcwdiyccsq2j5S4pP8l3DH7DiYtnMTIviPzEqOIyPbkuo/gAGCsuw+N1n8BuLuP\nb2B/A/7t7p3M7HmgR7SpE6Gf4LVR0ph8jPo/iIjEhPoIZkZ1ZG7V1sKRR4aE8NRTt93+4nsvcuaD\nZ7L4ssXsVrpb0wcoIrFRiH0EZwF9zKyXmbUGzgIeSd7BzPokrQ4HlgK4+2B37+3uvYFbgf9OTQJF\nRERE8qWoKNwRHDMmfV/BQT0HceJ+JzLuuXFNHpuIyI7kNBF09xrgcmAaYcCXSe6+2MzGmdnwaLfL\nzWyhmc0GrgLOy2VMIiIiItny9a+HJPDhh9Nv18AxIlKocto0tCmo2YuISHyoaWhmVEc2jUcegWuv\nhdmzw13CVH+Y+QcmL57MM999BkvtTCgikgWF2DRUREREpEU79VQoKYGHHkq//ZL+l7Bu8zomLZzU\ntIGJiGyH7giKiEizoTuCmVEd2XQeewx++UuYNy/9XcGXVrzEGQ+cweLLFtOhtEPTBygiLZruCDbC\nX/4Ct92W7yhERESkJRk2DNq0gcmT028fuPdATtrvJEY/M7ppAxMRaUDsEsGePeGBB/IdhYiIiLQk\nZjBuXBhFtKYm/T43nXAT05ZP48onr6S6trpJ4xMRSRW7RHDIEFiwAD75JN+RiIiISEsydCh06NDw\nD86d23Xm5e+/zOKPF3PafafxWeVnTRugiEiS2CWCZWVw/PHw1FP5jkRERERaksRdwXHjGr4ruHvZ\n7jx+9uP06tiLgRMH8s66d5o0RhGRhNglghDa8T/2WL6jEBERkZbmxBPhC1+ASdsZILRVcSsmDJvA\nRf0uYuDEgby04qWmC1BEJBLLUUPffx8OOwzWrAnDPYuISPOgUUMzo1FD8+Ppp2HUKFi0aMd/Zzyx\n9AnOn3o+tw69lbP7nt00AYpIi6NRQxtpr72gVy94+eV8RyIiIiItzVe+Al27wr337njfU/Y/hae/\n+zT/+cx/cu2z11LrtbkPUESEmCaCEJqHPv54vqMQERGRlsYMrrsOrr8eqhsxOGjfrn2Z8f0ZTF8+\nnZGTR7KpalPugxSR2IttIjh8uBJBERERyY3ycujRA+6+u3H7d23flWfPe5ZiK6b87+Ws3rA6p/GJ\niMQ2ETz66NBH8N138x2JiIhIfWY21MyWmNmbZvbz7ez3LTOrNbOjmjI+aZxx48Kdwaqqxu1fVlLG\nPSPuYdj+wzj2jmOZt3pebgMUkViLbSJYVAQnn6y7giIiUljMrAj4A/A14BBgpJkdmGa/9sAPgRlN\nG6E01uDB0Ls33HVX448xM64dci03nXATJ/zjBB5949HcBSgisRbbRBBC81A9RkJERArMMcBSd3/X\n3auAScDpafa7HhgPVDZlcJKZceNCX8EtWzI77sxDz+SxkY9xyeOXMObZMVRW62MWkeyKdSJ40knw\nwguwcWO+IxEREdlqL2BF0vrKqGwrMzsC6OHuTzRlYJK5QYPgi1+Ev/0t82OP7XEsr1z4Cgs+XEDf\nP/blX8v/lfX4RCS+Yp0IduwI/fvDM8/kOxIREZGt0j0HauvDAM3MgFuAH+/gGCkQ48bBDTdA5U7c\n1OvRoQdTzpzC7772O37w6A8YOXkkq9avyn6QIhI7sX+c+rBhoXno8OH5jkRERAQIdwB7Jq33AD5I\nWt+N0HewIkoKuwEPm9lp7j479WRjx47dulxeXk55eXkOQpbtGTAADj4Y7rwTLr10584x/IDhfGXf\nr/Cr53/FYbcfxrWDr2XU0aMoLirObrAi0ixUVFRQUVGxS+cwd9/xXgXMzHxXrmHJEjjxRHjvvfDc\nHxERKVxmhru36G9rMysG3gC+CqwCZgIj3X1xA/s/C1zt7nPSbNulOlKyZ+ZM+OY3YdkyKC3dtXMt\n/mgxo54YxWeVn3H7sNs5eq+jsxOkiDRbO1M/xrppKIR2+6WlMH9+viMREREBd68BLgemAYuASe6+\n2MzGmVm69iuOmoYWvGOOgcMPhzvu2PVzHdT5IJ757jNcdexVnDbpNEY9Pop1m9ft+olFJFZif0cQ\n4MoroWtXuOaaLAUlIiI5EYc7gtmkO4KFZfZsOOUUeOUV6NUrO+dcu2kt1zx9DVPfmMpvTvwN5/Q9\nB1MTJ5HY2Zn6UYkgMH06jB0LL76YnZhERCQ3lAhmRolg4bnllvBcwRdegHbtsnfeV1a+wqWPX8ru\nZbszYdgEDtxzm0dPikgLpkRwJ1VWQpcu8NZbsOeeWQpMRESyTolgZpQIFh53OP982LwZJk3K7vgE\n1bXVTJg1geueu47enXpzeNfDObzb4Rze9XAO63oYHcs6Zu/FRKSgKBHcBd/4RujEfe65WQhKRERy\nQolgZpQIFqbNm2Hw4PC3xy9/mf3zb9iygflr5jNv9TzmrQnTwg8XsmfbPUNymJQg7ttpX4qs+Q0Z\nUVNbw6bqTWyq2rTNvLKmki01W9JOldXpt1XXVlNdW02N14R5bQ3VHs1Tymu8hpraGoCtzXAN22bZ\noq67jV1Od57Wxa1pU9KGspIy2rSK5iVt6i0ntrUpaUNpSSm1Xlt3DUmxpytLvp5ar6031XiasqT9\nHMfdM1oGcPftLqf7zmrovWrovYuj/x32v0oEd9bEiaGJ6KRJWQhKRERyQolgZpQIFq733w8DyPzp\nT03zCKtar+Wtf78VEsOkBHHtprX07dqXA/c4kHat21FaXEppSWmj5iVF4SlkyX/I72h9c/VmNlZt\n5POqz8N8y+f119OUp0v2qmurtyY/yfOykjLKSsooLS6ldXHr7U6JfVoVt6JVUSuKi4opKSqh2KJ5\n0nrqtuTkOTl5SSw3NulJfZ9Sl7fUbGFz9WY2VW8K8+g9SCxvrqlftrl6c9p4U69n67qFaykuKg5z\nC/PElChPNxkW5lGS1pjl7SXOycuJJC/d+9LQv63Eclz98NgfKhHcWatWwSGHwJo10KpVFgITEZGs\nUyKYGSWChW3GDDjtNHjuOTjooPzEsHbTWuavmc+bn7zJpupNVFZXUllTuXW+uXpzXVlSeWV1JdW1\n1du9O5NuvaykjHat29G2pG2Yt2pLu1bRPGU9eUpN+loXt4713R+RVAXZNNTMhgK3Eh5VMdHdx6ds\nvxi4DKgB1gMXufsSMzsBuBFoBWwBfubuz6Y5f9Yquf794be/hSFDsnI6ERHJMiWCmVEiWPj++lf4\n9a/DSKKdOuU7GhFprgouETSzIuBNwkNxPwBmAWe5+5Kkfdq7+4Zo+VRglLufbGaHA2vcfbWZHQI8\n5e490rxG1iq5MWNg0ya46aasnE5ERLJMiWBmlAg2D1ddBUuWwOOPQ3FxvqMRkeaoEB8ofwyw1N3f\ndfcqYBJwevIOiSQw0h6ojcrnufvqaHkRUGpmOW20OWxY+BIWERERaSo33wxVVbkZOEZEpCG5TgT3\nAlYkra+Myuoxs1FmtozQFPSKNNu/BcyJksmc6d8fPv4Y3n47l68iIiIiUqekBP75T5g8Ge6+O9/R\niEhc5DoRTHd7cps2Ku4+wd37AD8HRtc7QWgW+mvgopxEmKSoCE45RXcFRUREpGntsQdMnQo/+hG8\n+mq+oxGROCjJ8flXAj2T1nsQ+go25H7g9sSKmfUApgDfcfd3Gjpo7NixW5fLy8spLy/fqWAhDOH8\nl7/A5Zfv9ClERCRLKioqqKioyHcYIk2ib1/4859hxAiYORO6dct3RCLSkuV6sJhi4A3CYDGrgJnA\nSHdfnLRPH3dfFi2fCox292PMbHegAhjn7g9t5zWy2hH+s8+gR4/wOIl27bJ2WhERyQINFpMZDRbT\nPI0bB9OmwTPPQGlpvqMRkeag4AaLcfca4HJgGrAImOTui81snJklHp96uZktNLPZwFXAeVH5ZcB+\nwGgzm2Nms81sz1zGC9ChAxx9NDz9dK5fSURERGRbo0dD165w2WWgPF5EckUPlE/jlltg8eLQPENE\nRAqH7ghmRncEm6/162HgQLj4YnVXEZEdK7jnCDaFXFRyb74Jxx8PK1eC6c8NEZGCoUQwM0oEm7fl\ny+FLXwojiZ54Yr6jEZFCVnBNQ5urAw6Atm1h7tx8RyIiIiJx1bs3PPAAnHMOPPFEvqMRkZZGiWAD\nhg/XYyREREQkvwYPhkcfhe99LzxrUEQkW5QINmDYMCWCIiIikn/HHgvTp4dnDE6cmO9oRKSlUB/B\nBmzZAl26wNKl0Llz1k8vIiI7QX0EM6M+gi3L0qWhr+BVV4VJRCRBfQSzqHVr+OpX4ckn8x2JiIiI\nCOy/Pzz/PEyYEJ41qBxfRHaFEsHtGDYMHnss31GIiIiIBD17wv/9H0yZAj/5iZJBEdl5ahq6HatX\nw0EHwYcfQqtWOXkJERHJgJqGZkZNQ1uutWvhlFPg0EPh9tuhuDjfEYlIPqlpaJZ16wZ9+sCLL+Y7\nEhEREZE6nTqFAWSWLw+Pl9iyJd8RiUhzo0RwB4YPV/NQERERKTzt24cRzjduhBEjYNOmfEckIs2J\nEsEd0GMkREREpFCVlcHkydCxI5x8Mqxfn++IRKS5UCK4A0cdBevW6a6giIiIFKZWreCuu+DAA8OI\n5598ku+IRKQ5UCK4A0VFcP/9cMkl8MtfQlVVviMSERERqa+4GP74RygvD9OyZfmOSEQKnRLBRhg8\nGGbPhrlzw5frihX5jkhERESkPjMYPx4uvhgGDIAbb9QP2CLSMCWCjdSlS+greNpp0L8/PPpoviMS\nERERqc8MLr8cZs2Cigo4+mh49dV8RyUihUjPEdwJL70EI0fCN78Zfm1r3bpJX15EJLb0HMHM6DmC\n8eYO99wDP/4xnHsuXHcdtGuX76hEJBf0HMEmMnAgzJkDb70Fxx0XnuEjIiIiUkjMQgK4cCF8+GF4\n+PxTT+U7KhEpFEoEd9IXvgBTp8LZZ4d2+A8+mO+IRERERLbVuTP84x9w++1h8LvvfAc+/jjfUYlI\nvikR3AVmcNVVoe/gz34Gl10GmzfnOyoRERGRbX3ta7BgQUgMDz00NBtVy2GR+FIfwSz59FO48EJY\nuhT++U844IB8RyQi0vKoj2BmCqWOlMIza1b4u6V793CncJ998h2RiOwK9RHMo44dQwJ48cUwaFB4\nsGttbb6jEhEREdlWYjTR8vIwGvpvfgOff57vqESkKemOYA7MnQsXXBCaW1x3HQwfHpqRiojIrtEd\nwcwUYh0phWfpUvj5z+GFF+DSS8PjJzp3zndUIpIJ3REsEEccAa+9BqNHwzXXhMFknnpK7fBFRESk\n8Oy/P0yZEhLB1avhi1+EUaNg2bJ8RyYiuaREMEfMYMQImDcPrr46DCrz5S/Ds8/mOzIRERGRbR1w\nAPzpT7B4cRgdfcAAOOOM0J9QRFoeNQ1tIjU1cO+9MG4c9OwJ118f+hKKiEjjqWloZppLHSmFaf16\nmDgRbrkFeveGn/4UTj5Z3V1ECtHO1I9KBJtYVVUYSOb66+HAA0MfwmOO2blz1dRAcXF24xMRKWRK\nBDPT3OpIKUxVVWFAvJtuCgPh/fSncNZZ0Lp1viMTkYSCTATNbChwK6EZ6kR3H5+y/WLgMqAGWA9c\n5O5Lom2/BC4AqoEr3X1amvM3y0puyxa480644YbQp/C66+DII0M/wn//G1atCu30U6fk8rVrQ3PT\nK66A00+HkpJ8X5WISG4pEcxMc60jpTC5w/TpISF84w34wQ/gW9+Cgw7SXUKRfCu4RNDMioA3ga8C\nHwCzgLMSiV60T3t33xAtnwqMcveTzexg4B7gaKAH8C9g/9QarblXcps3w5//DDfeGL5EP/oI2reH\nbt3qT927b7veoQNMnQr/8z+wYkV4oP2FF4Z2/SIiLZESwcw09zpSCtfs2aGF05Qp0LZtGBdhxAjo\n109JoUg+FGIiOAAY4+4nR+u/ADz1rmDS/iOBc919WOq+ZvYkMNbdX0k5pkVUcps2wYcfQteuUFaW\n+fGvvQa//z08/HDo2P3DH0LfvtmPU0Qkn5QIZqal1JFSuNzD8winTIHJk6Gysi4pHDhQXVhEmkoh\nPj5iL2BF0vrKqKweMxtlZsuAG4ErGjj2/XTHthRt2kCvXjuXBEL4Be5vfwtNNXr2hKFD4StfCXcM\na2qyGqqIiIgIEO7+HX00/PrX4W+QJ56ATp3CD9J77QUXXwzTpoUuMSJSWHKdCKbLSrf5adLdJ7h7\nH+DnwOhMjpX6unSB//ovePvt0HZ//Hjo0wduvjn0KRQRERHJBTM45BC49lqYOxdefDE8o3Ds2NCt\n5bvfhXvugZUr8x2piADkeniRlUDPpPUehL6CDbkfuD3p2L0bc+zYsWO3LpeXl1NeXp55pC1M69Yw\ncmSYZs4MzUZ794Zvfzv0I+zfX234RaTwVVRUUFFRke8wRGQn7Lcf/OQnYXr//dB95aGHwrOVO3aE\n8vK6qUePPAcrEkO57iNYDLxBGCxmFTATGOnui5P26ePuy6LlU4HR7n5M0mAxxxKahE6nBQ4W05RW\nr4Y77gijlbZvD9//PpxzDuy5Z74jExFpHPURzIzqSClEtbXw+utQURGm556rnxgOGQJ77739c4hI\nfQU3WAxsfXzEbdQ9PuJGMxsHzHL3x8zsVuAEYAuwFrg8kShGj4/4PlBFC3t8RD7V1oYv3YkT4bHH\n4KST4IIL4MQT1albRApbXBLBRjx66UfAhYT68SPgAndfkeY8qiOl4CUnhs89F+YdOoSk8Ljj4IAD\nQqumbt3UmkmkIQWZCOaaKrlds24d3HdfuEu4ejWcfz5873vhC1dEpNDEIRFs5KOXhgCvuPtmM7sE\nKHf3s9KcS3WkNDu1tbB4cUgIX3oJli8P0/r1sM8+4W+UxLTvvnXz9u3zHblI/igRlF0yb15ICO+9\nFw47LNwlHDEijGgqIlIIYpIIZvropSOA37v7l9NsUx0pLcaGDWEwvOXL6+aJ6e23w13EffcNo6d3\n6VI3de1af71DB91ZlJZHiaBkRWVl6NB9550waxacfHIYXKZfPzjySP3iJiL5E5NE8JvA19z9omj9\nXOAYd7+igf1/D6xy9/9Os011pMRCbS2sWROSwvfeg48+Cs9nTjdVVtZPDLc3de6884/2EmlKO1M/\n5nrUUGmGSkvD6KLf/nb4Mp0+PTyw/r77YOHC8Etbv35105FHwm675TtqEZEWo9GPT4qSxH7AkJxG\nJFLgioqge/cwDRq0/X03baqfKK5ZE9bXrIEFC7ZNHNu02TZB3GOPkCC2alU3tW6dfjmxXlQUnu1c\nUwPV1XXL21tPSNzBTDdPLUtI/g0o9feg1HWzEF9RUeOXtzc1tE9D17OjslSZlkt6uiMoGamqCh26\nX3utblqwIIzulUgMjzoqJJPr1sGnn9bNG1pety58KXftGoaP3muv9PM99tj+f/DPPw/DUzc0ffBB\nSGKHDAkd0AcOhHbtmuytE5EsiMkdwQHAWHcfGq2nbRpqZicQBmMb7O6fNHAuHzNmzNZ1PWJJJDPu\n4W+V1OTw449hy5YwVVWFKXk53XpNDZSUhIH5kqfUsuR1s7qkLd08XVlDiVTq31CJ9cR5amu3nadb\nrqmpO2Z7U2L/5DjTXceOytJ9JpmUt1SfflrBp59WbF1fsWKcmoZK06uqCp26E4nhnDnhP3/HjmHa\nfff683TLZWXhl7j33w8Pmk03//zzkBQmEsPS0vqJXmVl3fZ0U/fu8NZbdaOSzZkT+kImhqseOFDN\nXkUKXUwSwcY8eulI4AFCE9K3tnMu1ZEiIjGgPoLSom3cGO7qrVwZps2b6yeGnTpl1iRg40Z4+eW6\noapnz4a+feueYTRokJq8ihSaOCSC0KhHL00HDiUkiga86+5fT3Me1ZEiIjGgRFBkF2zaBDNm1D3g\n9rXX4OCD4fDD4ZBD6qbu3dUGXSRf4pIIZovqSBGReFAiKJJFmzbBq6+GAXIWLaqbqqrqJ4aHHhrm\nXbooQRTJNSWCmVEdKSISD0oERZrAhx/WTwwTk1lICPfbr+H+kKlT69b5vhqR5kWJYGZUR4qIxIMS\nQZE8cQ+D3SxaFB5qm26U1HRTq1YhIdxzzzBqakNTt27hWUatWuX7SkXyS4lgZlRHiojEgxJBkWbE\nPQxY8+mnYRjq1atDMpk8JZd98klIGhPJ4e67Q4cO295lTFfWsSO0baumq9L8KRHMjOpIEZF4UCIo\n0oLV1IRkMJEYpt5d/Oyz7ZcB9O4dmq726ROmxHLPnuG5RSKFTolgZlRHiojEgxJBEWnQhg3hOYpv\nvQXLltXNly0LieXee9dPDvfbLySI3buHpqtFRfm+AhElgplSHSkiEg9KBEVkp1RWhr6NqUniypWw\nalXo69i5c0gKu3ULU7rlrl2hrAyKi3PTDNUdamuhurr+VFW1bVlqOYSY0k3pthUXh+a07dqFedu2\noUzC3enKStiyJcwrK8N73KpVmFq3rptatWrcvwX3MFLvxo3w+ed18+TljRvhvPOUCGZCdaSISDwo\nERSRnKiqquuzuHp1SA5Tl1etCvts2RISheLi0Nx0R1NRUdg/OYFLXU8uMwvJRep50pUlyhMJnPu2\nU0Pl1dUhMUkkIBs3hsQmkRimm5eWpo9he+9FaWlIntu0ady8pCTc3d2wAdavTz+lbtu8OSTQNTXp\n5+nKEklecrKXWK+tDXGXlob3JHHd1dVhe1VVmCeWS0rqJ4aJZff6729pacPvbWJ+991KBDOhOlJE\nJB6UCIpIQXBPn8ylm2pqtp80Ja8XF+eviap7SKhS71Alzysrt3/dqduqqsIxmzeHpHPz5vrL6cqq\nqqB9+zDtttu2U7ryxF3aoqL089SyoqK6BC8xT036MnnfEglicnK4ZUvY3q5dmNq0adwdVzUNzYzq\nSBGReFAiKCIiLZoSwcyojhQRiYedqR81/IOIiIiIiEjMKBEUERERERGJGSWCIiIiIiIiMaNEUERE\nREREJGaUCIqIiIiIiMSMEkEREREREZGYUSIoIiIiIiISM0oERUREREREYkaJoIiIiIiISMzkPBE0\ns6FmtsTM3jSzn6fZ/iMzW2Rmc81supntnbRtvJktjLbfmutYRURERERE4iCniaCZFQF/AL4GHAKM\nNLMDU3abDfRz9yOAycBvomO/BAx090OBQ4FjzGxwLuNtjioqKvIdQt7E+doh3tevaxeRHYn7/5U4\nX3+crx3iff1xvvadkes7gscAS939XXevAiYBpyfv4O7PufvmaHUGsFdiE1BmZmVAG6AEWJPjeJud\nOP+Dj/O1Q7yvX9cuIjsS9/8rcb7+OF87xPv643ztOyPXieBewIqk9ZXUJXrpfB94EsDdZwAVwCrg\nfeApd38jN2GKiIiIiIjER0mOz29pyjztjmbnAv2AIdH6fsCBwH9E5/mXmT3l7i/kKFYRERER7MZY\nLgAADYBJREFUEZFYMPe0eVl2Tm42ABjr7kOj9V8A7u7jU/Y7AbgNGOzun0RlPwFK3f2GaH00sMnd\nb045NncXICIiBcfd0/3IKGmojhQRiY9M68dc3xGcBfQxs16EJp5nASOTdzCzI4Hbga8lksDIe8CF\nZnYjoQnrEOCW1BfQHwQiIiLpqY4UEZGG5LSPoLvXAJcD04BFwCR3X2xm48xseLTbTUA74AEzm2Nm\nU6PyB4HlwAJgDjDH3R/PZbwiIiIiIiJxkNOmoSIiIiIiIlJ4cv5A+Vza0cPqWzIze8fM5kV3UWfm\nO55cM7OJZrbGzOYnlXUys2lm9oaZPWVmHfMZY640cO1jzGylmc2OpqH5jDFXzKyHmT1jZq+b2QIz\nuyIqj8tnn3r9P4zKW/znb2alZvZK9B23wMzGROX7mNmM6LO/z8xy3cWhWYpz/QiqI6OyuHxPqo6M\nYR0Z5/oRsldHNts7ghYeVv8m8FXgA0J/xLPcfUleA2siZrYc6Ofua/MdS1Mws+OADcBd7n5YVDYe\n+MTdb4r+0Onk7r/IZ5y50MC1jwHWu/vv8hpcjplZN6Cbu881s/bAa4RnkX6PeHz2DV3/mcTj82/r\n7hvNrBh4EbgSuBp40N0fMLM/AnPd/U95DbTAxL1+BNWRUZnqyJb/HRnbOjLu9SNkp45szncEd/iw\n+hbOaN6fX0aix4akVuinA3+Plv8OfL1Jg2oiDVw7pH88S4vi7qvdfW60vAFYDPQgPp99uutPPIs1\nDp//xmixlDC4mQPHA5Oj8r8D38hDaIUu7vUjqI6E+HxPqo4kfnVk3OtHyE4d2Zy/JDN9WH1L48BT\nZjbLzH6Q72DypIu7r4HwhQB0znM8Te0yM5trZne0xGYfqcxsH+AIYAbQNW6ffdL1vxIVtfjP38yK\nzGwOsBqYDrwFrHP32miXlYRnzUp9ca8fQXUkqI5s8d+RyeJcR8axfoTs1JHNORFs9MPqW6iB7t4f\nOIXwD/64fAckTWoCsJ+7H0H4AmjRTSCiZh8PAldGv/zF6f96uuuPxefv7rXufiThF+5jgIPS7da0\nUTULca8fQXVk3MXiOzIhznVkXOtHyE4d2ZwTwZVAz6T1HoS+ELEQ/cKDu38EPET4BxA3a8ysK2xt\nK/5hnuNpMu7+kdd18P0LcHQ+48mlqKPzg8A/3P3hqDg2n32664/T5w/g7p8BzwEDgN2jPnAQs+/9\nDMS6fgTVkZHYfE+mitN3ZJzrSNWPwa7Ukc05Edz6sHoza014WP0jeY6pSZhZ2+gXEMysHXASsDC/\nUTUJo/4v3Y8A50fL5wEPpx7QgtS79uiLPWEELfvzvxN43d1vSyqL02e/zfXH4fM3sz0TTXrMrA1w\nAvA68CxwRrRbS//sd1Zs60dQHZm0HqfvSdWR8awjY1k/QvbqyGY7aiiE4bGB2wgJ7UR3vzHPITUJ\nM9uX8AunEzqH3tPSr93M7gXKgT2ANcAYYCrwALA38B5whruvy1eMudLAtR9PaA9fC7wDXJzoD9CS\nmNkg4HlgAeHfuwPXADOBf9LyP/uGrv9sWvjnb2Z9CR3di6Lpfne/Ifr+mwR0AuYA50YDokiSuNaP\noDoS1ZGqI2NQR8a5foTs1ZHNOhEUERERERGRzDXnpqEiIiIiIiKyE5QIioiIiIiIxIwSQRERERER\nkZhRIigiIiIiIhIzSgRFRERERERiRomgiIiIiIhIzCgRlKwxs1oz+03S+o/N7Np8xtQYZvZXMxuR\n7zi2x8xeaMLXetbMjmqq19tV0UOzF0TL/czs1p04R3cz+2f2oxMRab7iXq/vSt1gZkPM7NFdjUEk\nl5QISjZVAiPM7Av5eHEzK87H6zYFdz8u3zHkQhY/Mwdw99fc/aqMD3Zf5e7fzlIsIiItRazr9SzU\nDXpYtxQ0JYKSTdXAn4GrUzek/jpnZuuj+RAzqzCzqWa2zMx+bWZnm9krZjbPzPaN9tvTzB6Myl8x\nsy9F5WPM7K7ojtldZlZqZnea2Xwze83MytMFamZ/MLPFZjYN6JJUflQUzywze9LMujZwLRPM7OUo\n5sFmNtHMXjezO5P2m2BmM81sgZmNSSofGr32q2Z2W+IXw+hark7ab4GZ9Uzzfj1rZg9E5/hH0v6j\no/dmvpndnlR+hZktMrO5ZnZvmuspM7P7on2mAGVJ2040s5eiWO83s7Zpjr8wus45UVxlSe/TH6P3\ncomZnRKVn2dmD5vZ08C/orKfROeYm3ivojt9r5vZn81soZn9PzMrjbb1i/adA1yWFMvWX2DN7HEz\nmx3Ftc7MvhOd8/noel41swFJr5W4q1hkZjdF7+VcM/tB6jWLiMREnOr128zsxSjmEVF5ct0ww8wO\nSjrmWTM70szaWvgb4JUovlPTnD/tPmZ2cFQ2O6pv9mvEZyKSPe6uSVNWJuAzoD3wNrAb8GPg2mjb\nX4ERyftG8yHAvwlf2q2BlcCYaNsVwO+i5XuAgdHy3sDr0fIYYBbQOlq/GpgYLX8ReDexLem1vwE8\nFS13B9YCI4AS4EVgj2jbtxPnSjn+r8C90fJpwKfAwdH6q8Bh0fLu0bwIeBY4FCgF3gN6R9vuBx5J\nupark15nAdAzzfu1NorbgJeS3pfdk469CxgWLb8PtIqWO6S5nh8Bd0TLfYEq4ChgD+A5oE207WfA\n6DTHd0pavh64LOl9eiJa7gOsiD7j86L3oGO07UTgT9GyAY8CxwG9gC1A36T36uxoeR5wXLR8EzA/\n6f15JCW+o4C5hH+TZUn/VvoAs6LlXknn+AFwTbTcmvDvq1e+/39p0qRJU1NPxKtevz9aPghYGi0n\n1w1XAmOj5W7Akmj5hqS6qSPwBtAmuT7azj7/A4yMykuA0nx/5priNZUgkkXuvsHM/k74wtzUyMNm\nufuHAGb2FjAtKl8AlEfLJwAHmZlF6+3NrF20/Ii7b4mWjyN8seLub5jZO8ABwMKk1xsM3Bfts8rM\nnonKv0hI1qZHr1MEfNBAzIl2/wuA1e7+erS+CNgHmA+cFd1NKiFUGgcDxcByd18e7X83IfHIxEx3\nXwVgZnOj13sJ+KqZ/RRoC3SKrvlxQtJ0r5lNBaamOd9g4DYAd19gZvOi8gFRzC9G70cr4OU0x/c1\ns18BuwPtgKeStv0zOu+y6LM9MCqf7u6fRssnASea2WxCItgO2J+QOL7t7gui/V4D9jGzDoQkMtFv\n8h/A0HRvlJntGW3/lruvj479g5kdAdREr5PqpOiazojWO0T7vZvuNUREWrIY1etTo+MXm1mXNNsf\niK5jLCGhfCAqPwk4Nap/ISS/PVOObWifl4H/NLMewEPuvqyB2ERyQomg5MJtwGzCL2wJ1dRvitw6\nabkyabk2ab2Wun+jBgxIqhhCYag/Pk8uSokldT0hXbt9Axa6+6AGjkmWHGNq/CVmtg/hl9N+7v6Z\nmf2VpCaXDUh9jxraP/n1aqLXKwX+FzjK3T+w0LwycfwwQiV5GqHCOdTda1POmfx+WNJ8mrufs4O4\n/wac5u4Lzew8wq+gDZ03sZ76mf3a3f+SfFIz65XmWsto+DOtx8yKCH8YjHX3xVHxjwiJ+2EW+p6k\n+6PGgB+6+/TGvI6ISAzEqV5P+xpR3fqJmfUFzgQuStr8TXdfWu+FzbqlnG+bfYA3zGwGMBx4wswu\ncveKRsQqkhXqIyjZZADuvpZwJ+j7SdveAfoDmNnXCXeXMjGN0KSE6ByHN7Df88A50T4HEJqbvJFm\nn7OivmDdgeOj8jeAzkn9xkrM7OBGxJauUuoAbADWR/0RTo7KlxDuau0brY9MOuYdQjNGLIzauW/S\nth0lP2WESvATM2sPfCtpW093fw74RRRX+5RjnwfOjV73UOCwqHwGMCjRZ8HM2phZujto7YHVZtaK\n6L1PcoYF+0XXk/pZQLiDeEHil2Az+w8z69zQdUd3EteZ2cCo6Nw05wQYD8xz9weSyjoCq6Ll7xLu\n0KaLZ5SZlUTx7G9mbRp4DRGRlkz1ev3lSYRuEh3cfVFU9lTKdRyR5nxp9zGzfd39bXf/PfAwdfWv\nSJNQIijZlPxr3G8JfcwSZX8BhlgY3GMA9X/ta+gcya4E+lvoaL4QuLiB/SYQ7pDNJ9wNOs/dq+q9\ngPtDwDJCM86/EZpVEu33LWB81ORyDvClRsToqcvuPp/QL20xofnnC1F5ZRT7E2b2KrAm6djJwB5R\nx/RR1K/oGnpfEq/3KXBHdE1PAjMhVHrA3VFzz9eA29z9s5Rz/JHQJGcRocnLq9E5PwbOB+6Ljn+Z\n0Mwm1ejo9f4vut5k70XbHgcuTv3lN3qd6cC9wMvR5/YAdclqQ9d9ATAhak7a0D4/Bk6yMFjMbDMb\nTvj3cX707/AA6v87TJznDuB1YHb0WdyOWk+ISDypXq+/PJlwN/D+pLJfAa0sDGYzH7guzfmvT9pn\nQdI+Z1oYDG0OcAihf79IkzF3jWwrki9mNgT4sbuflu9Ysi1qDvuou0/Jdyw7Ymb9gJvd/fgd7iwi\nIiLSAuiOoIjkSrP4lSlKAu8BMn4QvYiIiEhzpTuCIiIiIiIiMaM7giIiIiIiIjGjRFBERERERCRm\nlAiKiIiIiIjEjBJBERERERGRmFEiKCIiIiIiEjNKBEVERERERGLm/wMCffS6VjrO/gAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6659b77510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6668c35e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_train1 = [ i[0] for i in info1]\n",
    "error_test1 = [ i[1] for i in info1]\n",
    "error_train2 = [ i[0] for i in info2]\n",
    "error_test2 = [ i[1] for i in info2]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(1, 2, figsize=(15,5))\n",
    "axarr[0].plot(N,error_train1, label = \"Training set\")\n",
    "axarr[0].plot(N,error_test1, label = \"Test set\")\n",
    "#axarr[0].set_xticks(N)\n",
    "axarr[0].set_xlabel('Numero de maquinas de aprendizaje')\n",
    "axarr[0].set_ylabel('Error')\n",
    "axarr[0].set_title('Error sobre RandomForest de profundidad 10')\n",
    "#axarr[0].set_ylim(0,0.5)\n",
    "axarr[0].legend(loc=\"upper right\")\n",
    "\n",
    "axarr[1].plot(N,error_train2, label = \"Training set\")\n",
    "axarr[1].plot(N,error_test2, label = \"Test set\")\n",
    "#axarr[1].set_xticks(N)\n",
    "axarr[1].set_xlabel('Numero de niveles')\n",
    "axarr[1].set_ylabel('Error')\n",
    "axarr[1].set_title('Error sobre RandomForest con 20 maquinas de aprendizaje')\n",
    "axarr[1].legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(N[:10],error_train1[:10], label = \"Training set\")\n",
    "plt.plot(N[:10],error_test1[:10], label = \"Test set\")\n",
    "#axarr[1].set_xticks(N)\n",
    "plt.xlabel('Numero de niveles')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error sobre RandomForest de maxima 10 niveles')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En la celda anterior se ejecuta un algoritmo generico basado en *Random Forest* para ensamblar maquinas de aprendizaje que prediscan la demanda total de bicicletas y asi poder generar los graficos presentados.\n",
    "\n",
    "En el primer grafico se grafica el error versus el numero de arboles de profundidad 10 utilizados en el ensamblado. Se puede observar que el error registrado por el training set y el test set presentan valores inferiores a 0.44 lo cual es relativamente bajo.\n",
    "Se puede apreciar claramente que tanto el training set como el test set poseen un comportamiento muy similar y uniforme al aumentar el numero de maquinas de aprendizaje, por lo que se infiere que no se produce *overffiting*.\n",
    "\n",
    "En el segundo grafico se grafica el error versus el numero de niveles de profundidad en un modelo *Random Forest* con 20 maquinas de aprendizaje\n",
    "\n",
    "\n",
    "\n",
    "Evalúe el efecto de utilizar un algoritmo genérico para ensamblar máquinas de aprendizaje para predecir\n",
    "la demanda total de bicicletas. Puede experimentar con una sola técnica (e.g. Random Forest), pero\n",
    "por favor estudie y discuta la evolución del rendimiento (de entrenamiento y pruebas) a medida que\n",
    "aumenta el número de máquinas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
