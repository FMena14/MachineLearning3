{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing: Predicción de Demanda Horaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explicacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Atributo| Descripción |\n",
    "|--------|-------------|\n",
    "|datetime| algo|\n",
    "|season | algo|\n",
    "|holiday| otro algo|\n",
    "|workingday| bla|\n",
    "|weather| bla|\n",
    "|temp| caca|\n",
    "|atemp|caca|\n",
    "|humidity|blabla|\n",
    "|windspeed|caca|\n",
    "|casual|casc|\n",
    "|registered|blasd|\n",
    "|count| demanda|  \n",
    "\n",
    "hourly date + timestamp\n",
    "1 = spring, 2 = summer, 3 = fall, 4 = winter\n",
    "whether the day is considered a holiday\n",
    "whether the day is neither a weekend nor holiday\n",
    "1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "temperature in Celsius\n",
    "“feels like” temperature in Celsius\n",
    "relative humidity\n",
    "wind speed\n",
    "number of non-registered user rentals initiated\n",
    "number of registered user rentals initiated\n",
    "number of total rentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary - dataframe completo:\n",
      "\n",
      "             season       holiday    workingday       weather         temp  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.00000   \n",
      "mean       2.506614      0.028569      0.680875      1.418427     20.23086   \n",
      "std        1.116174      0.166599      0.466159      0.633839      7.79159   \n",
      "min        1.000000      0.000000      0.000000      1.000000      0.82000   \n",
      "25%        2.000000      0.000000      0.000000      1.000000     13.94000   \n",
      "50%        3.000000      0.000000      1.000000      1.000000     20.50000   \n",
      "75%        4.000000      0.000000      1.000000      2.000000     26.24000   \n",
      "max        4.000000      1.000000      1.000000      4.000000     41.00000   \n",
      "\n",
      "              atemp      humidity     windspeed        casual    registered  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
      "mean      23.655084     61.886460     12.799395     36.021955    155.552177   \n",
      "std        8.474601     19.245033      8.164537     49.960477    151.039033   \n",
      "min        0.760000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%       16.665000     47.000000      7.001500      4.000000     36.000000   \n",
      "50%       24.240000     62.000000     12.998000     17.000000    118.000000   \n",
      "75%       31.060000     77.000000     16.997900     49.000000    222.000000   \n",
      "max       45.455000    100.000000     56.996900    367.000000    886.000000   \n",
      "\n",
      "              count  \n",
      "count  10886.000000  \n",
      "mean     191.574132  \n",
      "std      181.144454  \n",
      "min        1.000000  \n",
      "25%       42.000000  \n",
      "50%      145.000000  \n",
      "75%      284.000000  \n",
      "max      977.000000  \n",
      "Dimensiones de training set: \n",
      "(6562, 13)\n",
      "Dimensiones de validation set: \n",
      "(2177, 13)\n",
      "Dimensiones de test set: \n",
      "(2147, 13)\n",
      "10886\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dftrain = pd.read_csv('bike_sharing_train.csv')\n",
    "dfval = pd.read_csv('bike_sharing_val.csv')\n",
    "dftest = pd.read_csv('bike_sharing_test.csv')\n",
    "ntrain = len(dftrain)\n",
    "nval = len(dftrain) + len(dfval)\n",
    "df = pd.concat([dftrain,dfval,dftest])\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "print('\\nSummary - dataframe completo:\\n')\n",
    "print(df.describe())\n",
    "#print df\n",
    "print \"Dimensiones de training set: \"\n",
    "print dftrain.shape\n",
    "print \"Dimensiones de validation set: \"\n",
    "print dfval.shape\n",
    "print \"Dimensiones de test set: \"\n",
    "print dftest.shape\n",
    "\n",
    "print len(df)\n",
    "#procesamiento\n",
    "df['hour'] = pd.to_datetime(df['datetime']).apply(lambda x: x.strftime('%H'))\n",
    "df['hour'] = pd.to_numeric(df['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13773, 60141, 43002, 53708, 53708, 53708] [27250, 98354, 81833, 96599, 96599, 96599] [33947, 104681, 89197, 100973, 100973, 100973] [27305, 99762, 78460, 93241, 93241, 93241]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/tight_layout.py:225: UserWarning: tight_layout : falling back to Agg renderer\n",
      "  warnings.warn(\"tight_layout : falling back to Agg renderer\")\n",
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 2 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spring_rows1 = df[ (df['season'] == 1) & (df['hour'] <= 6)]\n",
    "spring_rows2 = df[ (df['season'] == 1) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "spring_rows3 = df[ (df['season'] == 1) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "spring_rows4 = df[ (df['season'] == 1) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "spring_rows5 = df[ (df['season'] == 1) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "spring_rows6 = df[ (df['season'] == 1) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "spring_vals = [sum(spring_rows1['count']),sum(spring_rows2['count']),sum(spring_rows3['count']),sum(spring_rows4['count'])\n",
    "              ,sum(spring_rows4['count']),sum(spring_rows4['count'])]\n",
    "\n",
    "summer_rows1 = df[ (df['season'] == 2) & (df['hour'] <= 6)]\n",
    "summer_rows2 = df[ (df['season'] == 2) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "summer_rows3 = df[ (df['season'] == 2) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "summer_rows4 = df[ (df['season'] == 2) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "summer_rows5 = df[ (df['season'] == 2) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "summer_rows6 = df[ (df['season'] == 2) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "summer_vals = [sum(summer_rows1['count']),sum(summer_rows2['count']),sum(summer_rows3['count']),sum(summer_rows4['count'])\n",
    "              ,sum(summer_rows4['count']),sum(summer_rows4['count'])]\n",
    "\n",
    "fall_rows1 = df[ (df['season'] == 3) & (df['hour'] <= 6)]\n",
    "fall_rows2 = df[ (df['season'] == 3) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "fall_rows3 = df[ (df['season'] == 3) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "fall_rows4 = df[ (df['season'] == 3) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "fall_rows5 = df[ (df['season'] == 3) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "fall_rows6 = df[ (df['season'] == 3) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "fall_vals = [sum(fall_rows1['count']),sum(fall_rows2['count']),sum(fall_rows3['count']),sum(fall_rows4['count'])\n",
    "              ,sum(fall_rows4['count']),sum(fall_rows4['count'])]\n",
    "\n",
    "winter_rows1 = df[ (df['season'] == 4) & (df['hour'] <= 6)]\n",
    "winter_rows2 = df[ (df['season'] == 4) & (df['hour'] > 6) & (df['hour'] <= 9)]\n",
    "winter_rows3 = df[ (df['season'] == 4) & (df['hour'] > 9) & (df['hour'] <= 12)]\n",
    "winter_rows4 = df[ (df['season'] == 4) & (df['hour'] > 12) & (df['hour'] <= 15)]\n",
    "winter_rows5 = df[ (df['season'] == 4) & (df['hour'] > 15) & (df['hour'] <= 18)]\n",
    "winter_rows6 = df[ (df['season'] == 4) & (df['hour'] > 18) & (df['hour'] <= 24)]\n",
    "\n",
    "winter_vals = [sum(winter_rows1['count']),sum(winter_rows2['count']),sum(winter_rows3['count']),sum(winter_rows4['count'])\n",
    "              ,sum(winter_rows4['count']),sum(winter_rows4['count'])]\n",
    "\n",
    "\n",
    "print spring_vals, summer_vals,fall_vals,winter_vals\n",
    "\n",
    "# Construir histograma -------------------------------------------\n",
    "\n",
    "#PARA COMPARAR LAS EPOCAS DEL AÑO\n",
    "f, axarr = plt.subplots(2, 2, figsize=(12,8) )\n",
    "axarr[0, 0].bar(np.arange(0,6,1), spring_vals, width  = 0.5, align = \"center\", color = 'b')\n",
    "axarr[0, 0].set_title('Spring')\n",
    "axarr[0, 0].set_xticks([-0.25,0.5,1.5,2.5,3.5,4.5,5.25])\n",
    "axarr[0, 0].set_xticklabels(('12am','6am','9am','12pm','15pm','6pm','12am'))\n",
    "axarr[0, 0].set_ylabel('Ventas')\n",
    "axarr[0, 0].axis('tight')\n",
    "\n",
    "axarr[0, 1].bar(np.arange(0,6,1), summer_vals, width  = 0.5, align = \"center\", color = 'r')\n",
    "axarr[0, 1].set_title('Summer')\n",
    "axarr[0, 1].set_xticks([-0.25,0.5,1.5,2.5,3.5,4.5,5.25])\n",
    "axarr[0, 1].set_xticklabels(('6am','9am','12pm','15pm','6pm','12am'))\n",
    "axarr[0, 1].set_ylabel('Ventas')\n",
    "\n",
    "axarr[1, 0].bar(np.arange(0,6,1), fall_vals, width  = 0.5, align = \"center\", color = 'g')\n",
    "axarr[1, 0].set_title('Fall')\n",
    "axarr[1, 0].set_xticks([-0.25,0.5,1.5,2.5,3.5,4.5,5.25])\n",
    "axarr[1, 0].set_xticklabels(('6am','9am','12pm','15pm','6pm','12am'))\n",
    "axarr[1, 0].set_ylabel('Ventas')\n",
    "\n",
    "axarr[1, 1].bar(np.arange(0,6,1), winter_vals, width  = 0.5, align = \"center\", color = 'y')\n",
    "axarr[1, 1].set_title('Winter')\n",
    "axarr[1, 1].set_xticks([-0.25,0.5,1.5,2.5,3.5,4.5,5.25])\n",
    "axarr[1, 1].set_xticklabels(('6am','9am','12pm','15pm','6pm','12am'))\n",
    "axarr[1, 1].set_ylabel('Ventas')\n",
    "\n",
    "\n",
    "f.tight_layout() #separar los subplot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE TEST=0.703388\n",
      "[ 0.16430305  0.          0.         ...,  0.          0.          0.        ]\n",
      "[ 0.23767165 -0.72391884  1.69734978 ...,  0.52324814 -0.69314718\n",
      " -0.42030218]\n",
      "[ 1.29392104  1.86321843  0.86561644 ...,  0.0250013   0.12984815\n",
      "  0.10577365]\n",
      "KAGG EVAL TRAIN =0.028516\n",
      "KAGG EVAL VAL =0.554511\n",
      "KAGG EVAL TEST =0.574239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 275 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as Tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eval_bikemodel(y_predict,y_true):\n",
    "    diff = np.log(y_predict+1.0) - np.log(y_true+1.0)\n",
    "    print diff\n",
    "    return np.sqrt(np.sum(np.square(diff))/len(y_predict))\n",
    "\n",
    "\n",
    "Xdf=df.ix[:,['season','holiday','workingday','weather','temp','atemp',\n",
    "'humidity','windspeed','hour']]\n",
    "Ydf=df.ix[:,'count']\n",
    "\n",
    "X_train = Xdf[0:ntrain].values\n",
    "X_val = Xdf[ntrain:nval].values\n",
    "X_test = Xdf[nval:].values\n",
    "\n",
    "Y_train = Ydf[0:ntrain].values\n",
    "Y_val = Ydf[ntrain:nval].values\n",
    "Y_test = Ydf[nval:].values\n",
    "\n",
    "#Modelo\n",
    "model = Tree(random_state=0)\n",
    "model.fit(X_train,Y_train)\n",
    "score_test = model.score(X_test,Y_test)\n",
    "print \"SCORE TEST=%f\"%score_test\n",
    "\n",
    "Y_pred_train = model.predict(X_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "kagg_train = eval_bikemodel(Y_pred_train,Y_train)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "\n",
    "print \"KAGG EVAL TRAIN =%f\"%kagg_train\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "print \"KAGG EVAL TEST =%f\"%kagg_test\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(Y_test,Y_pred_test,'.')\n",
    "plt.xlabel('Valor Real')\n",
    "plt.ylabel('Prediccion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk.py:253: Warning: Source ID 180 was not found when attempting to remove it\n",
      "  gobject.source_remove(self._idle_event_id)\n"
     ]
    }
   ],
   "source": [
    "kaggs = []\n",
    "N_ts = np.arange(2,30)\n",
    "for n_t in N_ts:\n",
    "    model = Tree(random_state=0,max_depth=n_t)\n",
    "    model.fit(X_train,Y_train)\n",
    "\n",
    "    Y_pred_val = model.predict(X_val)\n",
    "    kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "    kaggs.append(kagg_val)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14,5))    \n",
    "plt.plot(N_ts,kaggs)\n",
    "plt.xticks(N_ts)\n",
    "plt.xlabel('Numero de niveles')\n",
    "plt.ylabel('KAGG')\n",
    "plt.title('Valor de funcion de evaluacion KAGG para distintos niveles en un arbol de clasificacion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGG EVAL VAL =0.476274\n"
     ]
    }
   ],
   "source": [
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred_val = model.predict(X_val)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fss(x, y, xval,yval, names_x, k = 10000):\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)+1\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = range(0, p+1)\n",
    "    selected = []\n",
    "    current_score = 0.0\n",
    "    best_new_score = 0.0\n",
    "    while remaining and len(selected)<=k :\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = Tree()\n",
    "            indexes = selected + [candidate]\n",
    "            x_train = x[:,indexes]\n",
    "            x_val = xval[:,indexes]\n",
    "            \n",
    "            predictions_train = model.fit(x_train, y).predict(x_val)\n",
    "            residuals_val = predictions_train - yval\n",
    "            mse_candidate = np.mean(np.power(residuals_val, 2))\n",
    "            \n",
    "            score_candidates.append((mse_candidate, candidate))\n",
    "        score_candidates.sort()\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        best_new_score, best_candidate = score_candidates.pop() #el de menor error es el mejor candidato\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        print \"selected = %s ...\"%names_x[best_candidate]\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781979\n",
      "1303497\n",
      "---------------------------------------------\n",
      "representacion normal de las caracteristicas\n",
      "[[  1.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   5.00000000e+00\n",
      "    1.00000000e+00   2.01100000e+03]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   5.00000000e+00\n",
      "    1.00000000e+00   2.01100000e+03]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   5.00000000e+00\n",
      "    1.00000000e+00   2.01100000e+03]\n",
      " ..., \n",
      " [  4.00000000e+00   0.00000000e+00   1.00000000e+00 ...,   2.00000000e+00\n",
      "    1.20000000e+01   2.01200000e+03]\n",
      " [  4.00000000e+00   0.00000000e+00   1.00000000e+00 ...,   2.00000000e+00\n",
      "    1.20000000e+01   2.01200000e+03]\n",
      " [  4.00000000e+00   0.00000000e+00   1.00000000e+00 ...,   2.00000000e+00\n",
      "    1.20000000e+01   2.01200000e+03]] [ 40  32  36 ...,  15   7 678]\n",
      "KAGG EVAL VAL =0.406954\n",
      "representacion con escalamiento de las caracteristicas\n",
      "KAGG EVAL VAL =0.406804\n",
      "---------------------------------------------\n",
      "representacion con extraccion de caracteristicas\n",
      "selected = hour ...\n",
      "selected = workingday ...\n",
      "selected = year ...\n",
      "selected = month ...\n",
      "selected = weather ...\n",
      "selected = holiday ...\n",
      "selected = season ...\n",
      "selected = atemp ...\n",
      "selected = cday ...\n",
      "selected = humidity ...\n",
      "selected = temp ...\n",
      "selected = windspeed ...\n",
      "se eliminaron\n",
      "KAGG EVAL VAL =0.404190\n",
      "---------------------------------------------\n",
      "representacion normal y normalizar la respuesta\n",
      "KAGG EVAL VAL =0.417863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#procesamiento de fecha a numeros\n",
    "df['cday'] = pd.to_datetime(df['datetime']).dt.dayofweek#0:lunes,6:domingo\n",
    "df['cday'] = pd.to_numeric(df['cday'])\n",
    "\n",
    "df['year'] = pd.to_datetime(df['datetime']).dt.year#0:lunes,6:domingo\n",
    "df['year'] = pd.to_numeric(df['year'])\n",
    "\n",
    "df['month'] = pd.to_datetime(df['datetime']).dt.month#0:lunes,6:domingo\n",
    "df['month'] = pd.to_numeric(df['month'])\n",
    "\n",
    "hola = df[ (df['year'] == 2011)]\n",
    "print sum(hola['count'])\n",
    "hola = df[ (df['year'] == 2012)]\n",
    "print sum(hola['count'])\n",
    "\n",
    "df2 = df.drop('datetime', axis=1)\n",
    "\n",
    "#print df2\n",
    "print \"---------------------------------------------\"\n",
    "\n",
    "names_features = ['season','holiday','workingday','weather','temp','atemp',\n",
    "'humidity','windspeed','hour','cday','month','year']\n",
    "\n",
    "df2 = df2.ix[:,names_features+['count']]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "def representacion(df, repre_type):\n",
    "    if repre_type == \"normal\":\n",
    "        Xdf=df.ix[:,names_features]\n",
    "        Ydf=df.ix[:,'count'] #no se normaliza\n",
    "        \n",
    "        X_train = Xdf[0:ntrain].values\n",
    "        X_val = Xdf[ntrain:nval].values\n",
    "        X_test = Xdf[nval:].values\n",
    "        Y_train = Ydf[0:ntrain].values\n",
    "        Y_val = Ydf[ntrain:nval].values\n",
    "        Y_test = Ydf[nval:].values\n",
    "        \n",
    "        return X_train, Y_train, X_val, Y_val\n",
    "    elif repre_type == \"svm\":\n",
    "        #PASO IMPORTANTE MAS ABAJO ...\n",
    "        features = ['season','holiday','workingday','weather','temp','atemp', \n",
    "                    'humidity','windspeed','hour','cday']\n",
    "        categorical_features = ['season', 'weather','hour','cday']\n",
    "        Xdf=df.ix[:,features]\n",
    "        Xdf = pd.get_dummies(Xdf,columns=categorical_features)\n",
    "        Ydf=df.ix[:,'count'] #no se normaliza\n",
    "        \n",
    "        X_train = Xdf[0:ntrain].values\n",
    "        X_val = Xdf[ntrain:nval].values\n",
    "        X_test = Xdf[nval:].values\n",
    "        Y_train = Ydf[0:ntrain].values\n",
    "        Y_val = Ydf[ntrain:nval].values\n",
    "        Y_test = Ydf[nval:].values\n",
    "        \n",
    "        return X_train, Y_train, X_val, Y_val\n",
    "    elif repre_type == \"standar\":\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "        Xdf = df_scaled.ix[:,names_features]\n",
    "        Ydf=df.ix[:,'count'] #no se normaliza\n",
    "\n",
    "        X_train = Xdf[0:ntrain].values\n",
    "        X_val = Xdf[ntrain:nval].values\n",
    "        X_test = Xdf[nval:].values\n",
    "        Y_train = Ydf[0:ntrain].values\n",
    "        Y_val = Ydf[ntrain:nval].values\n",
    "        Y_test = Ydf[nval:].values\n",
    "        \n",
    "        return X_train,Y_train,X_val,Y_val\n",
    "        \n",
    "    elif repre_type == \"extract\":\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "        Xdf=df_scaled.ix[:,names_features]\n",
    "        Ydf=df.ix[:,'count'] #no se normaliza\n",
    "\n",
    "        X_train = Xdf[0:ntrain].values\n",
    "        X_val = Xdf[ntrain:nval].values\n",
    "        Y_train = Ydf[0:ntrain].values\n",
    "        Y_val = Ydf[ntrain:nval].values\n",
    "        \n",
    "        #print fss(X_train,Y_train,X_val,Y_val,names_features)\n",
    "        new_names_features = fss(X_train,Y_train,X_val,Y_val,names_features)[:8]\n",
    "        new_names_features = np.array(names_features)[new_names_features]\n",
    "        print \"se eliminaron\"\n",
    "        x = set(names_features)\n",
    "        y = x - set(new_names_features)\n",
    "        \n",
    "        Xdf=df.ix[:,new_names_features]\n",
    "        scaler = StandardScaler()\n",
    "        Xdf = pd.DataFrame(scaler.fit_transform(Xdf), columns=Xdf.columns)\n",
    "        \n",
    "        X_train = Xdf[0:ntrain].values\n",
    "        X_val = Xdf[ntrain:nval].values\n",
    "        Y_train = Ydf[0:ntrain].values\n",
    "        Y_val = Ydf[ntrain:nval].values\n",
    "        return X_train,Y_train,X_val,Y_val\n",
    "    \n",
    "#print df_scaled\n",
    "print \"representacion normal de las caracteristicas\"\n",
    "X_train,Y_train,X_val,Y_val = representacion(df2,\"normal\")\n",
    "print X_train, Y_val\n",
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "print \"representacion con escalamiento de las caracteristicas\"\n",
    "X_train,Y_train,X_val,Y_val = representacion(df2,\"standar\")\n",
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "print \"---------------------------------------------\"\n",
    "print \"representacion con extraccion de caracteristicas\"\n",
    "X_train,Y_train,X_val,Y_val = representacion(df2,\"extract\")\n",
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "print \"---------------------------------------------\"\n",
    "print \"representacion normal y normalizar la respuesta\"\n",
    "X_train,Y_train,X_val,Y_val = representacion(df2,\"normal\")\n",
    "\n",
    "Ydf=df.ix[:,'count'] \n",
    "scaler = StandardScaler()\n",
    "#Ydf = pd.DataFrame(scaler.fit_transform(Ydf))#normalize(Ydf, norm='l2', axis=1, copy=True)\n",
    "Y = scaler.fit_transform(Ydf)\n",
    "        \n",
    "Y_train = Y[0:ntrain]\n",
    "Y_train = np.exp(Y_train) -1\n",
    "Y_val = Y[ntrain:nval]\n",
    "Y_val = np.exp(Y_val) -1\n",
    "        \n",
    "model = Tree(random_state=0,max_depth=10)\n",
    "model.fit(X_train,Y_train) #ajusta el modelo con target normalizado\n",
    "Y_pred_val = model.predict(X_val)\n",
    "\n",
    "#volver a la variable original\n",
    "Y_val = np.log(Y_val +1)\n",
    "Y_pred_val = np.log(Y_pred_val +1)\n",
    "\n",
    "Y_val = scaler.inverse_transform(Y_val)\n",
    "Y_pred_val = scaler.inverse_transform(Y_pred_val)\n",
    "\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  17.89986927   10.92876511   19.74929073 ...,  145.16276107  122.73003052\n",
      "   88.09981943]\n",
      "[ 13   1   1 ..., 168 129  88]\n",
      "[-0.06274585 -0.41619922  1.19130691 ...,  1.29220763  1.15822066\n",
      " -1.5084876 ]\n",
      "KAGG EVAL VAL =0.970464\n",
      "[  3.00097675e-01   1.78580554e+00   2.33936488e+00 ...,  -1.45177912e-01\n",
      "  -4.94324316e-02   1.12093809e-03]\n",
      "KAGG EVAL TRAIN =nan\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_val,Y_val = representacion(df2,\"svm\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#min_max_scaler = MinMaxScaler()\n",
    "#X_train = min_max_scaler.fit_transform(X_train)\n",
    "#X_val = min_max_scaler.fit_transform(X_val)\n",
    "\n",
    "scalerX = StandardScaler()\n",
    "scalerX = scalerX.fit(X_train)\n",
    "X_train = scalerX.transform(X_train)\n",
    "X_val = scalerX.transform(X_val)\n",
    "#X_test = scalerX.transform(X_test)\n",
    "\n",
    "\n",
    "# Aca explota porque la SVM deja valores negativos para los logaritmos\n",
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_train = model.predict(X_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "#Y_pred_test = model.predict(X_test)\n",
    "\n",
    "print Y_pred_train\n",
    "print Y_train\n",
    "\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "kagg_val = eval_bikemodel(Y_pred_train,Y_train)\n",
    "print \"KAGG EVAL TRAIN =%f\"%kagg_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGG EVAL TRAIN =nan\n",
      "KAGG EVAL VAL =nan\n"
     ]
    }
   ],
   "source": [
    "model = SVR(C=1,epsilon=0.01)\n",
    "kagg_train = eval_bikemodel(Y_pred_train,Y_train)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL TRAIN =%f\"%kagg_train\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.47308922266\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "def cross_validation_fun(X_train,Y_train):\n",
    "    k_fold = cross_validation.KFold(len(X_train),10)\n",
    "    score_cv = 0\n",
    "    for k, (train, val) in enumerate(k_fold):\n",
    "        model = SVR(C=1)\n",
    "        model.fit(X_train[train], Y_train[train])\n",
    "        Ypred_val = model.predict(X_train[val])\n",
    "        Ytrue_val = Y_train[val]\n",
    "        score_fold = eval_bikemodel(Ypred_val,Ytrue_val)\n",
    "        score_cv += score_fold\n",
    "    score_cv = score_cv / 10\n",
    "    return score_cv\n",
    "\n",
    "# score_cv SVM:\n",
    "# score_cv Tree:\n",
    "        \n",
    "        \n",
    "print cross_validation_fun(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGG EVAL VAL =1.402873\n",
      "KAGG EVAL VAL =2.554753\n"
     ]
    }
   ],
   "source": [
    "Ydf=df.ix[:,'count'] #demanda total\n",
    "\n",
    "Ydf=df.ix[:,'registered'] #demanda registrada\n",
    "X_train = Xdf[0:ntrain].values\n",
    "X_val = Xdf[ntrain:nval].values\n",
    "X_test = Xdf[nval:].values\n",
    "Y_train = Ydf[0:ntrain].values\n",
    "Y_val = Ydf[ntrain:nval].values\n",
    "Y_test = Ydf[nval:].values\n",
    "\n",
    "model = Tree(random_state=0,max_depth=20)\n",
    "model.fit(X_train,Y_train)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "\n",
    "\n",
    "Ydf=df.ix[:,'casual'] #demanda casual\n",
    "X_train = Xdf[0:ntrain].values\n",
    "X_val = Xdf[ntrain:nval].values\n",
    "X_test = Xdf[nval:].values\n",
    "Y_train = Ydf[0:ntrain].values\n",
    "Y_val = Ydf[ntrain:nval].values\n",
    "Y_test = Ydf[nval:].values\n",
    "\n",
    "model = SVR(C=1,epsilon=0.01)\n",
    "model.fit(X_train,Y_train)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=10,max_depth=max_depth,random_state=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
